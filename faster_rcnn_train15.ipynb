{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Dataset\n",
    "try: # register_coco_instances 함수를 사용해 COCO 형식의 데이터셋을 등록\n",
    "    register_coco_instances('coco_trash_train', {}, '../../dataset/train_15.json', '../../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "try: # \n",
    "    register_coco_instances('coco_trash_test', {}, '../../dataset/test.json', '../../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "# MetadataCatalog.get()를 통해 coco_trash_train 데이터셋의 클래스 이름을 지정\n",
    "MetadataCatalog.get('coco_trash_train').thing_classes = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "                                                         \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 불러오기\n",
    "'''\n",
    "1. get_cfg()를 호출해 기본 설정을 가져오기\n",
    "\n",
    "2. model_zoo.get_config_file()을 사용해 미리 정의된 Faster R-CNN의 R101 FPN 3x 구성 파일을 로드(이 부분은 변경 가능)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 수정하기\n",
    "'''\n",
    "1. 데이터를 학습(TRAIN)과 테스트(TEST)로 설정하고, Dataloader의 worker 수를 지정\n",
    "\n",
    "2. cfg.MODEL.WEIGHTS를 통해 사전 학습된 모델의 가중치를 설정\n",
    "\n",
    "3. 학습 배치 크기, 학습률, 최대 반복 횟수, 스케줄러 단계 및 감마값을 조정\n",
    "\n",
    "4. cfg.OUTPUT_DIR를 설정하여 모델 출력 파일을 저장할 디렉터리를 지정\n",
    "\n",
    "5. cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE와 cfg.MODEL.ROI_HEADS.NUM_CLASSES를 설정하여 이미지당 ROI의 배치 크기와 클래스 수를 설정\n",
    "\n",
    "6. cfg.TEST.EVAL_PERIOD를 통해 모델 평가 주기를 설정\n",
    "\n",
    "'''\n",
    "\n",
    "cfg.DATASETS.TRAIN = ('coco_trash_train',)\n",
    "cfg.DATASETS.TEST = ('coco_trash_test',)\n",
    "\n",
    "cfg.DATALOADER.NUM_WOREKRS = 2\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml')\n",
    "\n",
    "# 한 번의 학습 배치에서 처리할 이미지 수를 4로 설정\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "\n",
    "# 학습률(Learning Rate)을 0.001로 설정\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "\n",
    "# 학습 반복(iteration)을 최대 5,000으로 줄여서 대충 5에폭 정도의 학습을 갖게 합니다.\n",
    "cfg.SOLVER.MAX_ITER = 5000\n",
    "\n",
    "# 8000번째와 12000번째 반복(iteration)에서 학습률을 감소시키도록 설정\n",
    "cfg.SOLVER.STEPS = (2500, 4000)\n",
    "\n",
    "# 학습률 감소 비율을 0.005로 설정\n",
    "cfg.SOLVER.GAMMA = 0.005\n",
    "\n",
    "# 체크포인트 저장 주기를 3000번 반복마다 저장하도록 설정\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 1000\n",
    "\n",
    "# 모델의 출력(결과) 파일을 저장할 디렉토리를 './output'으로 설정\n",
    "cfg.OUTPUT_DIR = './output/NMS0_4'\n",
    "\n",
    "# 이미지당 ROI(Region of Interest) 샘플 수를 128로 설정 (RoI Head의 배치 크기)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "\n",
    "# 모델의 클래스 수를 10개로 설정 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
    "\n",
    "# 평가 주기를 3000번 반복마다 평가하도록 설정 (TEST 단계)\n",
    "cfg.TEST.EVAL_PERIOD = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper - input data를 어떤 형식으로 return할지 (따라서 augmnentation 등 데이터 전처리 포함 됨)\n",
    "'''\n",
    "데이터 매퍼 (전처리) 설정:\n",
    "\n",
    "MyMapper 함수는 입력 데이터에 대한 전처리 방법을 정의\n",
    "\n",
    "이미지에 랜덤으로 수직 뒤집기, 밝기 및 대비 변환을 적용\n",
    "\n",
    "변환된 이미지를 텐서로 변환하고 어노테이션을 조정하여 dataset_dict에 추가\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "import detectron2.data.transforms as T\n",
    "\n",
    "def MyMapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    transform_list = [\n",
    "        T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "        T.RandomBrightness(0.8, 1.8),\n",
    "        T.RandomContrast(0.6, 1.3)\n",
    "    ]\n",
    "    \n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    \n",
    "    dataset_dict['image'] = torch.as_tensor(image.transpose(2,0,1).astype('float32'))\n",
    "    \n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop('annotations')\n",
    "        if obj.get('iscrowd', 0) == 0\n",
    "    ]\n",
    "    \n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict['instances'] = utils.filter_empty_instances(instances)\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer - DefaultTrainer를 상속\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg, sampler=None):\n",
    "        return build_detection_train_loader(\n",
    "        cfg, mapper = MyMapper, sampler = sampler\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs('./output_eval', exist_ok = True)\n",
    "            output_folder = './output_eval'\n",
    "            \n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wandb\n",
    "from detectron2.engine import DefaultTrainer\n",
    "\n",
    "# wandb 설정\n",
    "wandb.init(project=\"my-detectron2-project\", config=cfg, name=\"experiment_name\")\n",
    "\n",
    "# 필요한 경우 cfg 값 로그\n",
    "wandb.config.update(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 종료 시 로그\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

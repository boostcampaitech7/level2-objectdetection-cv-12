{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys.platform: linux\n",
      "Python: 3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]\n",
      "CUDA available: True\n",
      "MUSA available: False\n",
      "numpy_random_seed: 2147483648\n",
      "GPU 0: NVIDIA GeForce RTX 3090\n",
      "CUDA_HOME: /usr/local/cuda\n",
      "NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
      "GCC: gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
      "PyTorch: 2.0.0+cu118\n",
      "PyTorch compiling details: PyTorch built with:\n",
      "  - GCC 9.3\n",
      "  - C++ Version: 201703\n",
      "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
      "  - Intel(R) MKL-DNN v2.7.3 (Git Hash 6dbeffbae1f23cbbeae17adb7b5b13f1f37c080e)\n",
      "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
      "  - LAPACK is enabled (usually provided by MKL)\n",
      "  - NNPACK is enabled\n",
      "  - CPU capability usage: AVX2\n",
      "  - CUDA Runtime 11.8\n",
      "  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
      "  - CuDNN 8.7\n",
      "  - Magma 2.6.1\n",
      "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wunused-local-typedefs -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.0.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
      "\n",
      "TorchVision: 0.15.1+cu118\n",
      "OpenCV: 4.10.0\n",
      "MMEngine: 0.10.5\n",
      "MMDetection: 3.3.0+\n"
     ]
    }
   ],
   "source": [
    "from mmengine.utils import get_git_hash\n",
    "from mmengine.utils.dl_utils import collect_env as collect_base_env\n",
    "\n",
    "import mmdet\n",
    "\n",
    "\n",
    "def collect_env():\n",
    "    \"\"\"Collect the information of the running environments.\"\"\"\n",
    "    env_info = collect_base_env()\n",
    "    env_info['MMDetection'] = f'{mmdet.__version__}+{get_git_hash()[:7]}'\n",
    "    return env_info\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for name, val in collect_env().items():\n",
    "        print(f'{name}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-09-30 14:45:40--  https://download.openmmlab.com/mmdetection/v3.0/codetr/co_dino_5scale_swin_large_16e_o365tococo-614254c9.pth\n",
      "Resolving download.openmmlab.com (download.openmmlab.com)... 163.181.22.237, 163.181.22.206, 163.181.22.205, ...\n",
      "Connecting to download.openmmlab.com (download.openmmlab.com)|163.181.22.237|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 946099183 (902M) [application/octet-stream]\n",
      "Saving to: ‘co_dino_5scale_swin_large_16e_o365tococo-614254c9.pth’\n",
      "\n",
      "co_dino_5scale_swin 100%[===================>] 902.27M  11.5MB/s    in 79s     \n",
      "\n",
      "2024-09-30 14:46:59 (11.5 MB/s) - ‘co_dino_5scale_swin_large_16e_o365tococo-614254c9.pth’ saved [946099183/946099183]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://download.openmmlab.com/mmdetection/v3.0/codetr/co_dino_5scale_swin_large_16e_o365tococo-614254c9.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "0\n",
      "NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # True가 나와야 정상\n",
    "print(torch.cuda.device_count())  # 사용 가능한 GPU 수 확인\n",
    "print(torch.cuda.current_device())  # 현재 사용 중인 GPU 확인\n",
    "print(torch.cuda.get_device_name(0))  # GPU 이름 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ./co_dino_5scale_swin_large_16e_o365tococo-614254c9.pth\n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_conv.bias - torch.Size([256]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_cls.weight - torch.Size([9, 256, 1, 1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_cls.bias - torch.Size([9]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_reg.weight - torch.Size([36, 256, 1, 1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "rpn_reg.bias - torch.Size([36]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.fc_cls.weight - torch.Size([81, 1024]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.fc_cls.bias - torch.Size([81]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.fc_reg.weight - torch.Size([320, 1024]): \n",
      "NormalInit: mean=0, std=0.001, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.fc_reg.bias - torch.Size([320]): \n",
      "NormalInit: mean=0, std=0.001, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.shared_fcs.0.bias - torch.Size([1024]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "bbox_head.shared_fcs.1.bias - torch.Size([1024]): \n",
      "XavierInit: gain=1, distribution=uniform, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "cls_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "cls_convs.0.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "cls_convs.0.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "reg_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "reg_convs.0.gn.weight - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "reg_convs.0.gn.bias - torch.Size([256]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_cls.weight - torch.Size([80, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_cls.bias - torch.Size([80]): \n",
      "NormalInit: mean=0, std=0.01, bias=-4.59511985013459 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_reg.weight - torch.Size([4, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_reg.bias - torch.Size([4]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_centerness.weight - torch.Size([1, 256, 3, 3]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "atss_centerness.bias - torch.Size([1]): \n",
      "NormalInit: mean=0, std=0.01, bias=0 \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.0.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.1.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.2.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.3.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.4.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n",
      "09/30 15:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
      "scales.5.scale - torch.Size([]): \n",
      "The value is the same before and after calling `init_weights` of CoATSSHead  \n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/data/aicontest/OD/mmdetection/projects/CO-DETR/codetr/transformer.py:1325: UserWarning: If you want to reduce GPU memory usage,                               please install fairscale by executing the                               following command: pip install fairscale.\n",
      "  warnings.warn('If you want to reduce GPU memory usage, \\\n",
      "/ssd/data/aicontest/OD/mmdetection/mmdet/models/dense_heads/anchor_head.py:108: UserWarning: DeprecationWarning: `num_anchors` is deprecated, for consistency or also use `num_base_priors` instead\n",
      "  warnings.warn('DeprecationWarning: `num_anchors` is deprecated, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "unexpected key in source state_dict: query_head.label_embedding.weight\n",
      "\n",
      "missing keys in source state_dict: query_head.dn_generator.label_embedding.weight\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/aicontest/anaconda3/envs/od/lib/python3.8/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/aicontest/anaconda3/envs/od/lib/python3.8/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" \n",
       "for Jupyter support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ssd/data/aicontest/OD/mmdetection/mmdet/apis/det_inferencer.py:130: UserWarning: dataset_meta or class names are not saved in the checkpoint's meta data, use COCO classes by default.\n",
      "  warnings.warn(\n",
      "/home/aicontest/anaconda3/envs/od/lib/python3.8/site-packages/mmengine/visualization/visualizer.py:196: UserWarning: Failed to add <class 'mmengine.visualization.vis_backend.LocalVisBackend'>, please provide the `save_dir` argument.\n",
      "  warnings.warn(f'Failed to add {vis_backend.__class__}, '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/aicontest/anaconda3/envs/od/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid:\n",
       "in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at \n",
       "../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
       "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/aicontest/anaconda3/envs/od/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid:\n",
       "in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at \n",
       "../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
       "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from mmdet.apis import DetInferencer\n",
    "\n",
    "# Choose to use a config\n",
    "model_name = '../mmdetection/projects/CO-DETR/configs/codino/co_dino_5scale_swin_l_16xb1_16e_o365tococo.py'\n",
    "# Setup a checkpoint file to load\n",
    "checkpoint = './co_dino_5scale_swin_large_16e_o365tococo-614254c9.pth'\n",
    "\n",
    "# Set the device to be used for evaluation\n",
    "device = 'cuda:0'\n",
    "\n",
    "# Initialize the DetInferencer\n",
    "inferencer = DetInferencer(model_name, checkpoint, device)\n",
    "\n",
    "# Use the detector to do inference\n",
    "img = '../mmdetection/demo/demo.jpg'\n",
    "result = inferencer(img, out_dir='./output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('../dataset/train/0000.jpg')\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    PredictionString       image_id\n",
      "0  7 0.9155679941177368 595.6181640625 512.554138...  test/0000.jpg\n",
      "1  3 0.859074056148529 338.64093017578125 250.363...  test/0001.jpg\n",
      "2  1 0.7509492039680481 771.3590698242188 457.373...  test/0002.jpg\n",
      "3  9 0.8799391984939575 153.57791137695312 260.83...  test/0003.jpg\n",
      "4  1 0.9069875478744507 194.627685546875 254.7870...  test/0004.jpg\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 입력 JSON 파일 경로\n",
    "input_json_file = '/home/aicontest/OD/mmdetection/work_dirs/coco_detection/test.bbox.json'\n",
    "\n",
    "# 변환할 점수 임계값 설정\n",
    "score_threshold = 0.035\n",
    "\n",
    "# 출력할 CSV 파일 경로\n",
    "output_csv_file = f'./submission_{score_threshold}.csv'\n",
    "\n",
    "# JSON 파일 읽기\n",
    "with open(input_json_file, 'r') as json_file:\n",
    "    outputs = json.load(json_file)\n",
    "\n",
    "# 이미지 별로 결과를 저장하기 위한 딕셔너리\n",
    "results = {}\n",
    "\n",
    "# 변환 코드\n",
    "for output in outputs:\n",
    "    image_id = output['image_id']\n",
    "    \n",
    "    # bbox, score, category_id를 기반으로 PredictionString 작성\n",
    "    bbox = output['bbox']\n",
    "    score = output['score']\n",
    "    category_id = output['category_id']\n",
    "    \n",
    "    # score 임계값 이상만 변환\n",
    "    if score > score_threshold:\n",
    "        prediction = f\"{category_id} {score} {bbox[0]} {bbox[1]} {bbox[0]+bbox[2]} {bbox[1]+bbox[3]} \"\n",
    "        \n",
    "        # 동일한 image_id에 대해 PredictionString을 추가\n",
    "        if image_id in results:\n",
    "            results[image_id] += prediction\n",
    "        else:\n",
    "            results[image_id] = prediction\n",
    "\n",
    "# 결과 저장을 위한 리스트\n",
    "prediction_strings = []\n",
    "image_ids = []\n",
    "\n",
    "# 딕셔너리의 결과를 CSV 형식으로 변환\n",
    "for image_id, prediction_string in results.items():\n",
    "    prediction_strings.append(prediction_string.strip())  # 끝 공백 제거\n",
    "    image_ids.append(f\"test/{str(image_id).zfill(4)}.jpg\")  # 파일명 형식 맞추기\n",
    "\n",
    "# DataFrame 생성 및 CSV 저장\n",
    "submission = pd.DataFrame({\n",
    "    'PredictionString': prediction_strings,\n",
    "    'image_id': image_ids\n",
    "})\n",
    "\n",
    "# CSV로 저장\n",
    "submission.to_csv(output_csv_file, index=False)\n",
    "\n",
    "# 결과 확인\n",
    "print(submission.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 출력 완료. 결과는 ./output에 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# 경로 설정\n",
    "json_file_path = '/home/aicontest/OD/mmdetection/work_dirs/coco_detection/test.bbox.json'\n",
    "test_image_dir = '/home/aicontest/OD/dataset/test'\n",
    "output_dir = './output'\n",
    "\n",
    "# 출력 디렉토리 없으면 생성\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 변환할 점수 임계값 설정\n",
    "score_threshold = 0.5\n",
    "\n",
    "# JSON 파일 읽기\n",
    "with open(json_file_path, 'r') as f:\n",
    "    outputs = json.load(f)\n",
    "\n",
    "# 이미지를 한 번만 불러오기 위해 image_id를 기준으로 그룹화\n",
    "image_predictions = {}\n",
    "\n",
    "for output in outputs:\n",
    "    image_id = output['image_id']\n",
    "    bbox = output['bbox']  # [x1, y1, width, height]\n",
    "    score = output['score']\n",
    "    category_id = output['category_id']\n",
    "\n",
    "    # score가 임계값 이상인 경우만 처리\n",
    "    if score > score_threshold:\n",
    "        if image_id not in image_predictions:\n",
    "            image_predictions[image_id] = []\n",
    "        image_predictions[image_id].append({\n",
    "            'bbox': bbox,\n",
    "            'score': score,\n",
    "            'category_id': category_id\n",
    "        })\n",
    "\n",
    "# 이미지에 박스 그리기\n",
    "for image_id, predictions in image_predictions.items():\n",
    "    # 이미지 파일 경로 설정 (파일명은 \"image_id.jpg\" 형식으로 가정)\n",
    "    image_file = os.path.join(test_image_dir, f\"{str(image_id).zfill(4)}.jpg\")\n",
    "    output_image_file = os.path.join(output_dir, f\"{str(image_id).zfill(4)}.jpg\")\n",
    "    \n",
    "    # 이미지 열기\n",
    "    image = cv2.imread(image_file)\n",
    "    \n",
    "    if image is None:\n",
    "        print(f\"이미지 파일을 찾을 수 없습니다: {image_file}\")\n",
    "        continue\n",
    "\n",
    "    # 각 예측에 대해 박스를 그리기\n",
    "    for prediction in predictions:\n",
    "        bbox = prediction['bbox']\n",
    "        score = prediction['score']\n",
    "        category_id = prediction['category_id']\n",
    "        \n",
    "        # bbox 좌표 (x1, y1, x2, y2)\n",
    "        x1, y1 = bbox[0], bbox[1]\n",
    "        x2, y2 = bbox[0] + bbox[2], bbox[1] + bbox[3]\n",
    "        \n",
    "        # 박스 그리기 (빨간색, 두께 2)\n",
    "        cv2.rectangle(image, (int(x1), int(y1)), (int(x2), int(y2)), (0, 0, 255), 2)\n",
    "        \n",
    "        # 카테고리와 점수 추가 (이미지 좌상단에 텍스트로 표시)\n",
    "        label = f\"Class: {category_id}, Score: {score:.2f}\"\n",
    "        cv2.putText(image, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1)\n",
    "\n",
    "    # 결과 이미지 저장\n",
    "    cv2.imwrite(output_image_file, image)\n",
    "\n",
    "print(f\"이미지 출력 완료. 결과는 {output_dir}에 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

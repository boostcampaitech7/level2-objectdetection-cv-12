{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "import logging\n",
    "\n",
    "# 로그 설정 ( output_log 폴더 안에서 output.log 라는 파일이 생성되고 거기서 실시간으로 진행상황이 보이게 된다.)\n",
    "log_output_dir = './output_logs'\n",
    "os.makedirs(log_output_dir, exist_ok=True)\n",
    "log_file = os.path.join(log_output_dir, 'output.log')\n",
    "logger = setup_logger(output=log_file)\n",
    "logger.setLevel(logging.INFO)\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.utils.events import EventWriter, get_event_storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## StratifiedKFold를 통해서 train/val을 8 : 2 비율로 나누는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "# 절대 경로를 사용하여 데이터셋 경로 설정\n",
    "dataset_dir = '/data/ephemeral/home/Lv2.Object_Detection/dataset'\n",
    "train_json_path = os.path.join(dataset_dir, 'train.json')\n",
    "image_dir = os.path.join(dataset_dir,)  # 실제 이미지 경로로 수정\n",
    "\n",
    "# COCO 형식의 train.json 로드\n",
    "with open(train_json_path, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# image_id 별로 annotations를 묶기\n",
    "image_to_annotations = {}\n",
    "image_to_category = {}  # StratifiedKFold를 사용하기 위해 클래스 레이블 필요\n",
    "for anno in coco_data['annotations']:\n",
    "    image_id = anno['image_id']\n",
    "    if image_id not in image_to_annotations:\n",
    "        image_to_annotations[image_id] = []\n",
    "    image_to_annotations[image_id].append(anno)\n",
    "    # 이미지에 속한 클래스 레이블 추가 (첫 번째 어노테이션 기준으로 레이블 설정)\n",
    "    if image_id not in image_to_category:\n",
    "        image_to_category[image_id] = anno['category_id']\n",
    "\n",
    "# 이미지 리스트 및 해당하는 클래스 라벨 추출\n",
    "image_ids = list(image_to_annotations.keys())\n",
    "image_labels = [image_to_category[image_id] for image_id in image_ids]\n",
    "\n",
    "# StratifiedKFold 설정\n",
    "n_splits = 5  # 원하는 K 값을 설정\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# 원하는 fold 선택 (예: fold_idx = 0일 경우 첫 번째 fold를 validation으로 사용)\n",
    "fold_idx = 0\n",
    "\n",
    "# K-fold split 진행\n",
    "for idx, (train_idx, val_idx) in enumerate(skf.split(image_ids, image_labels)):\n",
    "    if idx == fold_idx:\n",
    "        train_image_ids = [image_ids[i] for i in train_idx]\n",
    "        val_image_ids = [image_ids[i] for i in val_idx]\n",
    "        break\n",
    "\n",
    "# Train과 Val에 해당하는 annotations 필터링\n",
    "train_annotations = [anno for image_id in train_image_ids for anno in image_to_annotations[image_id]]\n",
    "val_annotations = [anno for image_id in val_image_ids for anno in image_to_annotations[image_id]]\n",
    "\n",
    "# Train과 Val에 해당하는 이미지 필터링\n",
    "train_images = [img for img in coco_data['images'] if img['id'] in train_image_ids]\n",
    "val_images = [img for img in coco_data['images'] if img['id'] in val_image_ids]\n",
    "\n",
    "# train.json과 val.json 생성\n",
    "train_split_path = os.path.join(dataset_dir, f'train_fold_{fold_idx}.json')\n",
    "val_split_path = os.path.join(dataset_dir, f'val_fold_{fold_idx}.json')\n",
    "\n",
    "train_data = coco_data.copy()\n",
    "train_data['annotations'] = train_annotations\n",
    "train_data['images'] = train_images\n",
    "with open(train_split_path, 'w') as f:\n",
    "    json.dump(train_data, f)\n",
    "\n",
    "val_data = coco_data.copy()\n",
    "val_data['annotations'] = val_annotations\n",
    "val_data['images'] = val_images\n",
    "with open(val_split_path, 'w') as f:\n",
    "    json.dump(val_data, f)\n",
    "\n",
    "# 데이터셋 등록 ( 원하는 폴드를 사용하면 된다 )\n",
    "register_coco_instances(f\"coco_trash_train_fold_{fold_idx}\", {}, train_split_path, image_dir)\n",
    "register_coco_instances(f\"coco_trash_val_fold_{fold_idx}\", {}, val_split_path, image_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg() # detectron2에서 기본 설정을 가지고 오는 함수입니다.\n",
    "cfg.merge_from_file(model_zoo.get_config_file('COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터와 관련된 setting을 진행하는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0부터 4까지 가능, 사용하고자 하는 폴드를 설정\n",
    "fold_idx = 0  \n",
    "\n",
    "# K-fold로 나눈 데이터를 기반으로, 학습 및 검증 데이터셋 설정\n",
    "cfg.DATASETS.TRAIN = (f'coco_trash_train_fold_{fold_idx}',)\n",
    "cfg.DATASETS.TEST = (f'coco_trash_val_fold_{fold_idx}',)\n",
    "\n",
    "# DataLoader에서 사용할 worker 수를 2로 설정 (병렬 데이터 로딩)\n",
    "cfg.DATALOADER.NUM_WORKERS = 2 \n",
    "\n",
    "# # Faster R-CNN R101 FPN 3x 모델의 사전 학습된 가중치 사용\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x.yaml')\n",
    "\n",
    "# 한 번의 학습 배치에서 처리할 이미지 수를 4로 설정\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "\n",
    "# 학습률(Learning Rate)을 0.001로 설정\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "\n",
    "# 학습 반복(iteration)을 최대 15,000으로 줄여서 대충 15에폭 정도의 학습을 갖게 합니다.\n",
    "cfg.SOLVER.MAX_ITER = 5000\n",
    "\n",
    "# 8000번째와 12000번째 반복(iteration)에서 학습률을 감소시키도록 설정\n",
    "cfg.SOLVER.STEPS = (2500, 4000)\n",
    "\n",
    "# 학습률 감소 비율을 0.005로 설정\n",
    "cfg.SOLVER.GAMMA = 0.005\n",
    "\n",
    "# 체크포인트 저장 주기를 3000번 반복마다 저장하도록 설정\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
    "\n",
    "# 모델의 출력(결과) 파일을 저장할 디렉토리를 './output'으로 설정\n",
    "cfg.OUTPUT_DIR = './output/test'\n",
    "\n",
    "# 이미지당 ROI(Region of Interest) 샘플 수를 128로 설정 (RoI Head의 배치 크기)\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "\n",
    "# 모델의 클래스 수를 10개로 설정 \n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
    "\n",
    "# 평가 주기를 3000번 반복마다 평가하도록 설정 (TEST 단계)\n",
    "cfg.TEST.EVAL_PERIOD = 500\n",
    "cfg.TEST.SCORE_THRESH_TEST = 0.5  # AP@50 기준 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper - input data를 어떤 형식으로 return할지 (따라서 augmnentation 등 데이터 전처리 포함 됨)\n",
    "'''\n",
    "데이터 매퍼 (전처리) 설정:\n",
    "\n",
    "MyMapper 함수는 입력 데이터에 대한 전처리 방법을 정의\n",
    "\n",
    "이미지에 랜덤으로 수직 뒤집기, 밝기 및 대비 변환을 적용\n",
    "\n",
    "변환된 이미지를 텐서로 변환하고 어노테이션을 조정하여 dataset_dict에 추가\n",
    "\n",
    "'''\n",
    "\n",
    "import detectron2.data.transforms as T\n",
    "\n",
    "def MyMapper(dataset_dict):\n",
    "    # 원본 데이터 복사하여 데이터 변형 시 원본 데이터가 손상되지 않도록 함\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    \n",
    "    # 이미지를 'BGR' 형식으로 불러옴 (Detectron2의 기본 설정은 BGR임)\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    # 데이터 증강(transform) 리스트 설정\n",
    "    transform_list = [\n",
    "        T.RandomFlip(prob=0.5, horizontal=False, vertical=True),  # 50% 확률로 이미지를 수직으로 뒤집음\n",
    "        T.RandomBrightness(0.8, 1.8),  # 이미지 밝기를 랜덤으로 조정 (0.8배 ~ 1.8배)\n",
    "        T.RandomContrast(0.6, 1.3)  # 이미지 대비를 랜덤으로 조정 (0.6배 ~ 1.3배)\n",
    "    ]\n",
    "    \n",
    "    # 설정한 transform 리스트를 적용하여 이미지를 변환\n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    \n",
    "    # 변환된 이미지를 텐서(tensor) 형식으로 변환하여 dataset_dict에 저장 (Detectron2의 입력 형식에 맞춤)\n",
    "    dataset_dict['image'] = torch.as_tensor(image.transpose(2,0,1).astype('float32'))\n",
    "    \n",
    "    # 어노테이션(annotations)을 변환된 이미지에 맞춰 적용 (변형된 이미지 좌표계에 맞게 재조정)\n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop('annotations')  # 'annotations'에서 하나씩 가져와 변환 수행\n",
    "        if obj.get('iscrowd', 0) == 0  # 'iscrowd'가 0인 객체만 선택 (crowd 객체 제외)\n",
    "    ]\n",
    "    \n",
    "    # 변환된 어노테이션을 바탕으로 'instances' 생성 (Detectron2에서 인스턴스 예측을 위한 포맷)\n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    \n",
    "    # 유효하지 않은 인스턴스(빈 인스턴스)를 필터링하여 제거\n",
    "    dataset_dict['instances'] = utils.filter_empty_instances(instances)\n",
    "    \n",
    "    # 최종적으로 변형된 dataset_dict 반환\n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer - DefaultTrainer를 상속\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg, sampler=None):\n",
    "        return build_detection_train_loader(\n",
    "        cfg, mapper = MyMapper, sampler = sampler\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs('./output_eval', exist_ok = True)\n",
    "            output_folder = './output_eval'\n",
    "            \n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from detectron2.utils.events import EventWriter, get_event_storage\n",
    "\n",
    "class WandbWriter(EventWriter):\n",
    "    def __init__(self, cfg, project=None, name=None):\n",
    "        self.cfg = cfg\n",
    "        self.run = wandb.init(project=project, name=name, config=cfg)\n",
    "    \n",
    "    def write(self):\n",
    "        storage = get_event_storage()\n",
    "        stats = {}\n",
    "        # storage.histories()를 사용하여 메트릭 가져오기\n",
    "        for k in storage.histories():\n",
    "            v = storage.histories()[k].latest()\n",
    "            if isinstance(v, (int, float)):\n",
    "                stats[k] = v\n",
    "        # 현재 학습 iteration 추가\n",
    "        stats['iteration'] = storage.iter\n",
    "        wandb.log(stats)\n",
    "    \n",
    "    def close(self):\n",
    "        self.run.finish()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyTrainer(DefaultTrainer):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__(cfg)\n",
    "        self.best_AP = 0  # 최고 성능을 저장할 변수\n",
    "\n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg, sampler=None):\n",
    "        return build_detection_train_loader(cfg, mapper=MyMapper, sampler=sampler)\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs('./output_eval', exist_ok=True)\n",
    "            output_folder = './output_eval'\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_dir=output_folder)\n",
    "    \n",
    "    # build_writers 메서드 오버라이드\n",
    "    def build_writers(self):\n",
    "        # 기본 writers 가져오기\n",
    "        writers = super().build_writers()\n",
    "        # WandbWriter 추가\n",
    "        writers.append(WandbWriter(self.cfg, \n",
    "            project=\"detectron2\", \n",
    "            name=\"wandb_test\"))\n",
    "        return writers\n",
    "\n",
    "    def after_step(self):\n",
    "        super().after_step()\n",
    "        # 평가 주기에 도달하면 평가 수행\n",
    "        next_iter = self.iter + 1\n",
    "        if next_iter % self.cfg.TEST.EVAL_PERIOD == 0:\n",
    "            results = self.test(self.cfg, self.model)\n",
    "            # mAP 가져오기 (여기서는 bbox mAP를 사용)\n",
    "            bbox_AP = results['bbox']['AP']\n",
    "            # best_AP 갱신 및 모델 저장\n",
    "            if bbox_AP > self.best_AP:\n",
    "                self.best_AP = bbox_AP\n",
    "                self.checkpointer.save(\"model_best\")\n",
    "                # wandb에 best mAP 기록\n",
    "                wandb.log({'best_bbox_AP': self.best_AP, 'iteration': next_iter})\n",
    "            \n",
    "            # 예측 결과 시각화하여 wandb에 업로드\n",
    "            self.visualize_predictions()\n",
    "\n",
    "    def visualize_predictions(self):\n",
    "        # 데이터셋에서 일부 이미지 선택\n",
    "        val_loader = build_detection_test_loader(self.cfg, self.cfg.DATASETS.TEST[0])\n",
    "        data = next(iter(val_loader))\n",
    "        with torch.no_grad():\n",
    "            # 모델을 평가 모드로 설정\n",
    "            self.model.eval()\n",
    "            predictions = self.model(data)\n",
    "            # 다시 학습 모드로 복귀\n",
    "            self.model.train()\n",
    "        # 이미지와 예측 결과 시각화\n",
    "        from detectron2.utils.visualizer import Visualizer\n",
    "        import cv2\n",
    "        v = Visualizer(data[0]['image'].cpu().numpy().transpose(1, 2, 0)[:, :, ::-1],\n",
    "                       MetadataCatalog.get(self.cfg.DATASETS.TEST[0]), scale=1.2)\n",
    "        v = v.draw_instance_predictions(predictions[0]['instances'].to('cpu'))\n",
    "        result_image = v.get_image()\n",
    "        # wandb에 이미지 업로드\n",
    "        wandb.log({\"Prediction Examples\": [wandb.Image(result_image, caption=\"Prediction\")]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 10:30:12 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=11, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/12 10:30:12 d2.data.datasets.coco]: \u001b[0mLoaded 3906 images in COCO format from /data/ephemeral/home/Lv2.Object_Detection/dataset/train_fold_0.json\n",
      "\u001b[32m[10/12 10:30:12 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 3906 images left.\n",
      "\u001b[32m[10/12 10:30:12 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/12 10:30:12 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/12 10:30:12 d2.data.common]: \u001b[0mSerializing 3906 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 10:30:12 d2.data.common]: \u001b[0mSerialized dataset takes 1.87 MiB\n",
      "\u001b[32m[10/12 10:30:12 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/Lv2.Object_Detection/baseline/detectron2/wandb/run-20241012_103012-hcmfnm7z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yujihwan-yonsei-university/detectron2/runs/hcmfnm7z' target=\"_blank\">wandb_test</a></strong> to <a href='https://wandb.ai/yujihwan-yonsei-university/detectron2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yujihwan-yonsei-university/detectron2' target=\"_blank\">https://wandb.ai/yujihwan-yonsei-university/detectron2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yujihwan-yonsei-university/detectron2/runs/hcmfnm7z' target=\"_blank\">https://wandb.ai/yujihwan-yonsei-university/detectron2/runs/hcmfnm7z</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 10:30:13 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_X_101_32x8d_FPN_3x/139173657/model_final_68b088.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/12 10:30:13 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n",
      "\u001b[32m[10/12 10:30:34 d2.utils.events]: \u001b[0m eta: 1:23:55  iter: 19  total_loss: 2.78  loss_cls: 2.271  loss_box_reg: 0.3198  loss_rpn_cls: 0.1782  loss_rpn_loc: 0.03969    time: 1.0107  last_time: 1.0161  data_time: 0.0303  last_data_time: 0.0151   lr: 1.9981e-05  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:30:54 d2.utils.events]: \u001b[0m eta: 1:23:48  iter: 39  total_loss: 1.989  loss_cls: 1.633  loss_box_reg: 0.2579  loss_rpn_cls: 0.09136  loss_rpn_loc: 0.0303    time: 1.0152  last_time: 1.0240  data_time: 0.0152  last_data_time: 0.0141   lr: 3.9961e-05  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:31:14 d2.utils.events]: \u001b[0m eta: 1:23:46  iter: 59  total_loss: 1.137  loss_cls: 0.707  loss_box_reg: 0.2673  loss_rpn_cls: 0.1292  loss_rpn_loc: 0.02631    time: 1.0168  last_time: 1.0145  data_time: 0.0153  last_data_time: 0.0146   lr: 5.9941e-05  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:31:35 d2.utils.events]: \u001b[0m eta: 1:23:25  iter: 79  total_loss: 0.6602  loss_cls: 0.3488  loss_box_reg: 0.1852  loss_rpn_cls: 0.08973  loss_rpn_loc: 0.01958    time: 1.0169  last_time: 1.0160  data_time: 0.0151  last_data_time: 0.0135   lr: 7.9921e-05  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:31:55 d2.utils.events]: \u001b[0m eta: 1:23:05  iter: 99  total_loss: 0.7978  loss_cls: 0.408  loss_box_reg: 0.2478  loss_rpn_cls: 0.07492  loss_rpn_loc: 0.02811    time: 1.0175  last_time: 1.0241  data_time: 0.0160  last_data_time: 0.0193   lr: 9.9901e-05  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:32:16 d2.utils.events]: \u001b[0m eta: 1:22:49  iter: 119  total_loss: 0.8338  loss_cls: 0.4396  loss_box_reg: 0.2833  loss_rpn_cls: 0.05307  loss_rpn_loc: 0.04507    time: 1.0180  last_time: 1.0212  data_time: 0.0163  last_data_time: 0.0153   lr: 0.00011988  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:32:36 d2.utils.events]: \u001b[0m eta: 1:22:30  iter: 139  total_loss: 0.9729  loss_cls: 0.5121  loss_box_reg: 0.356  loss_rpn_cls: 0.03794  loss_rpn_loc: 0.04396    time: 1.0183  last_time: 1.0248  data_time: 0.0165  last_data_time: 0.0203   lr: 0.00013986  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:32:57 d2.utils.events]: \u001b[0m eta: 1:22:11  iter: 159  total_loss: 0.7649  loss_cls: 0.4067  loss_box_reg: 0.2618  loss_rpn_cls: 0.03761  loss_rpn_loc: 0.02648    time: 1.0188  last_time: 1.0245  data_time: 0.0166  last_data_time: 0.0146   lr: 0.00015984  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:33:17 d2.utils.events]: \u001b[0m eta: 1:21:52  iter: 179  total_loss: 0.7149  loss_cls: 0.3559  loss_box_reg: 0.2596  loss_rpn_cls: 0.03103  loss_rpn_loc: 0.03501    time: 1.0195  last_time: 1.0280  data_time: 0.0156  last_data_time: 0.0166   lr: 0.00017982  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:33:37 d2.utils.events]: \u001b[0m eta: 1:21:32  iter: 199  total_loss: 0.6374  loss_cls: 0.3365  loss_box_reg: 0.2255  loss_rpn_cls: 0.03866  loss_rpn_loc: 0.01738    time: 1.0197  last_time: 1.0192  data_time: 0.0153  last_data_time: 0.0162   lr: 0.0001998  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:33:58 d2.utils.events]: \u001b[0m eta: 1:21:11  iter: 219  total_loss: 0.6725  loss_cls: 0.3524  loss_box_reg: 0.2579  loss_rpn_cls: 0.03064  loss_rpn_loc: 0.02641    time: 1.0197  last_time: 1.0195  data_time: 0.0160  last_data_time: 0.0144   lr: 0.00021978  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:34:18 d2.utils.events]: \u001b[0m eta: 1:20:51  iter: 239  total_loss: 0.7227  loss_cls: 0.3569  loss_box_reg: 0.2804  loss_rpn_cls: 0.02844  loss_rpn_loc: 0.02291    time: 1.0198  last_time: 1.0199  data_time: 0.0167  last_data_time: 0.0173   lr: 0.00023976  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:34:39 d2.utils.events]: \u001b[0m eta: 1:20:31  iter: 259  total_loss: 0.5251  loss_cls: 0.2961  loss_box_reg: 0.1907  loss_rpn_cls: 0.02508  loss_rpn_loc: 0.02614    time: 1.0198  last_time: 1.0179  data_time: 0.0159  last_data_time: 0.0142   lr: 0.00025974  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:34:59 d2.utils.events]: \u001b[0m eta: 1:20:10  iter: 279  total_loss: 0.6812  loss_cls: 0.3598  loss_box_reg: 0.2451  loss_rpn_cls: 0.03154  loss_rpn_loc: 0.03697    time: 1.0196  last_time: 1.0174  data_time: 0.0154  last_data_time: 0.0154   lr: 0.00027972  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:35:19 d2.utils.events]: \u001b[0m eta: 1:19:49  iter: 299  total_loss: 0.6137  loss_cls: 0.3018  loss_box_reg: 0.2324  loss_rpn_cls: 0.02425  loss_rpn_loc: 0.03125    time: 1.0196  last_time: 1.0205  data_time: 0.0162  last_data_time: 0.0161   lr: 0.0002997  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:35:40 d2.utils.events]: \u001b[0m eta: 1:19:29  iter: 319  total_loss: 0.5999  loss_cls: 0.2946  loss_box_reg: 0.2537  loss_rpn_cls: 0.02915  loss_rpn_loc: 0.02309    time: 1.0195  last_time: 1.0153  data_time: 0.0159  last_data_time: 0.0164   lr: 0.00031968  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:36:00 d2.utils.events]: \u001b[0m eta: 1:19:09  iter: 339  total_loss: 0.6172  loss_cls: 0.3234  loss_box_reg: 0.2271  loss_rpn_cls: 0.02191  loss_rpn_loc: 0.02477    time: 1.0195  last_time: 1.0198  data_time: 0.0162  last_data_time: 0.0177   lr: 0.00033966  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:36:21 d2.utils.events]: \u001b[0m eta: 1:18:48  iter: 359  total_loss: 0.6495  loss_cls: 0.2742  loss_box_reg: 0.2351  loss_rpn_cls: 0.03002  loss_rpn_loc: 0.03147    time: 1.0196  last_time: 1.0287  data_time: 0.0163  last_data_time: 0.0157   lr: 0.00035964  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:36:41 d2.utils.events]: \u001b[0m eta: 1:18:28  iter: 379  total_loss: 0.6474  loss_cls: 0.3122  loss_box_reg: 0.2435  loss_rpn_cls: 0.03082  loss_rpn_loc: 0.02509    time: 1.0197  last_time: 1.0192  data_time: 0.0163  last_data_time: 0.0149   lr: 0.00037962  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:37:02 d2.utils.events]: \u001b[0m eta: 1:18:08  iter: 399  total_loss: 0.6055  loss_cls: 0.2972  loss_box_reg: 0.2667  loss_rpn_cls: 0.04057  loss_rpn_loc: 0.02128    time: 1.0197  last_time: 1.0206  data_time: 0.0154  last_data_time: 0.0169   lr: 0.0003996  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:37:22 d2.utils.events]: \u001b[0m eta: 1:17:47  iter: 419  total_loss: 0.6331  loss_cls: 0.3261  loss_box_reg: 0.2475  loss_rpn_cls: 0.03408  loss_rpn_loc: 0.03804    time: 1.0197  last_time: 1.0179  data_time: 0.0163  last_data_time: 0.0148   lr: 0.00041958  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:37:42 d2.utils.events]: \u001b[0m eta: 1:17:27  iter: 439  total_loss: 0.6454  loss_cls: 0.3033  loss_box_reg: 0.2498  loss_rpn_cls: 0.02567  loss_rpn_loc: 0.02916    time: 1.0197  last_time: 1.0143  data_time: 0.0155  last_data_time: 0.0136   lr: 0.00043956  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:38:03 d2.utils.events]: \u001b[0m eta: 1:17:07  iter: 459  total_loss: 0.7198  loss_cls: 0.3589  loss_box_reg: 0.2755  loss_rpn_cls: 0.03167  loss_rpn_loc: 0.03494    time: 1.0198  last_time: 1.0188  data_time: 0.0158  last_data_time: 0.0158   lr: 0.00045954  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:38:23 d2.utils.events]: \u001b[0m eta: 1:16:47  iter: 479  total_loss: 0.5727  loss_cls: 0.265  loss_box_reg: 0.2569  loss_rpn_cls: 0.0191  loss_rpn_loc: 0.01808    time: 1.0199  last_time: 1.0193  data_time: 0.0164  last_data_time: 0.0163   lr: 0.00047952  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:38:44 d2.data.datasets.coco]: \u001b[0mLoaded 977 images in COCO format from /data/ephemeral/home/Lv2.Object_Detection/dataset/val_fold_0.json\n",
      "\u001b[32m[10/12 10:38:44 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 868          |    Paper    | 1405         | Paper pack | 186          |\n",
      "|     Metal     | 175          |    Glass    | 206          |  Plastic   | 590          |\n",
      "|   Styrofoam   | 247          | Plastic bag | 1141         |  Battery   | 20           |\n",
      "|   Clothing    | 91           |             |              |            |              |\n",
      "|     total     | 4929         |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/12 10:38:44 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/12 10:38:44 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/12 10:38:44 d2.data.common]: \u001b[0mSerializing 977 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 10:38:44 d2.data.common]: \u001b[0mSerialized dataset takes 0.49 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/12 10:38:44 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/12 10:38:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 977 batches\n",
      "\u001b[32m[10/12 10:38:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/977. Dataloading: 0.0011 s/iter. Inference: 0.0694 s/iter. Eval: 0.0004 s/iter. Total: 0.0710 s/iter. ETA=0:01:08\n",
      "\u001b[32m[10/12 10:38:50 d2.evaluation.evaluator]: \u001b[0mInference done 83/977. Dataloading: 0.0014 s/iter. Inference: 0.0684 s/iter. Eval: 0.0003 s/iter. Total: 0.0702 s/iter. ETA=0:01:02\n",
      "\u001b[32m[10/12 10:38:55 d2.evaluation.evaluator]: \u001b[0mInference done 155/977. Dataloading: 0.0014 s/iter. Inference: 0.0681 s/iter. Eval: 0.0003 s/iter. Total: 0.0699 s/iter. ETA=0:00:57\n",
      "\u001b[32m[10/12 10:39:00 d2.evaluation.evaluator]: \u001b[0mInference done 228/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:00:51\n",
      "\u001b[32m[10/12 10:39:05 d2.evaluation.evaluator]: \u001b[0mInference done 300/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:00:47\n",
      "\u001b[32m[10/12 10:39:10 d2.evaluation.evaluator]: \u001b[0mInference done 372/977. Dataloading: 0.0013 s/iter. Inference: 0.0679 s/iter. Eval: 0.0003 s/iter. Total: 0.0695 s/iter. ETA=0:00:42\n",
      "\u001b[32m[10/12 10:39:15 d2.evaluation.evaluator]: \u001b[0mInference done 445/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:00:36\n",
      "\u001b[32m[10/12 10:39:20 d2.evaluation.evaluator]: \u001b[0mInference done 518/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0003 s/iter. Total: 0.0693 s/iter. ETA=0:00:31\n",
      "\u001b[32m[10/12 10:39:25 d2.evaluation.evaluator]: \u001b[0mInference done 590/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:00:26\n",
      "\u001b[32m[10/12 10:39:30 d2.evaluation.evaluator]: \u001b[0mInference done 662/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0003 s/iter. Total: 0.0695 s/iter. ETA=0:00:21\n",
      "\u001b[32m[10/12 10:39:35 d2.evaluation.evaluator]: \u001b[0mInference done 731/977. Dataloading: 0.0014 s/iter. Inference: 0.0678 s/iter. Eval: 0.0006 s/iter. Total: 0.0698 s/iter. ETA=0:00:17\n",
      "\u001b[32m[10/12 10:39:40 d2.evaluation.evaluator]: \u001b[0mInference done 804/977. Dataloading: 0.0014 s/iter. Inference: 0.0677 s/iter. Eval: 0.0006 s/iter. Total: 0.0697 s/iter. ETA=0:00:12\n",
      "\u001b[32m[10/12 10:39:45 d2.evaluation.evaluator]: \u001b[0mInference done 878/977. Dataloading: 0.0014 s/iter. Inference: 0.0676 s/iter. Eval: 0.0006 s/iter. Total: 0.0696 s/iter. ETA=0:00:06\n",
      "\u001b[32m[10/12 10:39:50 d2.evaluation.evaluator]: \u001b[0mInference done 952/977. Dataloading: 0.0014 s/iter. Inference: 0.0676 s/iter. Eval: 0.0005 s/iter. Total: 0.0695 s/iter. ETA=0:00:01\n",
      "\u001b[32m[10/12 10:39:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:07.651557 (0.069600 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 10:39:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:05 (0.067555 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 10:39:52 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/12 10:39:52 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/12 10:39:53 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.30s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/12 10:39:53 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/12 10:39:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.57 seconds.\n",
      "\u001b[32m[10/12 10:39:54 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/12 10:39:54 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.21 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.065\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.112\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.064\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.017\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.080\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.116\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.229\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.254\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.004\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.108\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.304\n",
      "\u001b[32m[10/12 10:39:54 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| 6.477 | 11.241 | 6.359  | 0.226 | 1.677 | 7.967 |\n",
      "\u001b[32m[10/12 10:39:54 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP    | category    | AP     | category   | AP    |\n",
      "|:--------------|:------|:------------|:-------|:-----------|:------|\n",
      "| General trash | 3.184 | Paper       | 12.196 | Paper pack | 2.638 |\n",
      "| Metal         | 3.862 | Glass       | 6.879  | Plastic    | 7.229 |\n",
      "| Styrofoam     | 0.780 | Plastic bag | 27.901 | Battery    | 0.000 |\n",
      "| Clothing      | 0.107 |             |        |            |       |\n",
      "\u001b[32m[10/12 10:39:54 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_val_fold_0 in csv format:\n",
      "\u001b[32m[10/12 10:39:54 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/12 10:39:54 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/12 10:39:54 d2.evaluation.testing]: \u001b[0mcopypaste: 6.4774,11.2409,6.3595,0.2263,1.6773,7.9667\n",
      "\u001b[32m[10/12 10:39:54 d2.utils.events]: \u001b[0m eta: 1:16:26  iter: 499  total_loss: 0.6136  loss_cls: 0.2798  loss_box_reg: 0.2598  loss_rpn_cls: 0.02742  loss_rpn_loc: 0.06158    time: 1.0200  last_time: 1.0225  data_time: 0.0158  last_data_time: 0.0189   lr: 0.0004995  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:40:14 d2.utils.events]: \u001b[0m eta: 1:16:06  iter: 519  total_loss: 0.5354  loss_cls: 0.2653  loss_box_reg: 0.2314  loss_rpn_cls: 0.02241  loss_rpn_loc: 0.02342    time: 1.0198  last_time: 1.0195  data_time: 0.0156  last_data_time: 0.0144   lr: 0.00051948  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:40:35 d2.utils.events]: \u001b[0m eta: 1:15:45  iter: 539  total_loss: 0.7131  loss_cls: 0.3638  loss_box_reg: 0.3022  loss_rpn_cls: 0.02575  loss_rpn_loc: 0.03121    time: 1.0198  last_time: 1.0236  data_time: 0.0154  last_data_time: 0.0183   lr: 0.00053946  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:40:55 d2.utils.events]: \u001b[0m eta: 1:15:25  iter: 559  total_loss: 0.7301  loss_cls: 0.3674  loss_box_reg: 0.3147  loss_rpn_cls: 0.04699  loss_rpn_loc: 0.04178    time: 1.0199  last_time: 1.0211  data_time: 0.0167  last_data_time: 0.0165   lr: 0.00055944  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:41:16 d2.utils.events]: \u001b[0m eta: 1:15:05  iter: 579  total_loss: 0.5457  loss_cls: 0.2617  loss_box_reg: 0.2267  loss_rpn_cls: 0.02452  loss_rpn_loc: 0.02567    time: 1.0200  last_time: 1.0222  data_time: 0.0164  last_data_time: 0.0159   lr: 0.00057942  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:41:36 d2.utils.events]: \u001b[0m eta: 1:14:44  iter: 599  total_loss: 0.737  loss_cls: 0.3246  loss_box_reg: 0.3314  loss_rpn_cls: 0.02709  loss_rpn_loc: 0.04569    time: 1.0200  last_time: 1.0242  data_time: 0.0159  last_data_time: 0.0163   lr: 0.0005994  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:41:56 d2.utils.events]: \u001b[0m eta: 1:14:24  iter: 619  total_loss: 0.533  loss_cls: 0.2939  loss_box_reg: 0.2159  loss_rpn_cls: 0.0294  loss_rpn_loc: 0.02211    time: 1.0201  last_time: 1.0214  data_time: 0.0159  last_data_time: 0.0144   lr: 0.00061938  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:42:17 d2.utils.events]: \u001b[0m eta: 1:14:04  iter: 639  total_loss: 0.5393  loss_cls: 0.2704  loss_box_reg: 0.2195  loss_rpn_cls: 0.02761  loss_rpn_loc: 0.02119    time: 1.0202  last_time: 1.0222  data_time: 0.0157  last_data_time: 0.0177   lr: 0.00063936  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:42:37 d2.utils.events]: \u001b[0m eta: 1:13:44  iter: 659  total_loss: 0.656  loss_cls: 0.2827  loss_box_reg: 0.2586  loss_rpn_cls: 0.02376  loss_rpn_loc: 0.03398    time: 1.0203  last_time: 1.0215  data_time: 0.0172  last_data_time: 0.0158   lr: 0.00065934  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:42:58 d2.utils.events]: \u001b[0m eta: 1:13:24  iter: 679  total_loss: 0.5493  loss_cls: 0.2843  loss_box_reg: 0.2211  loss_rpn_cls: 0.02007  loss_rpn_loc: 0.02541    time: 1.0203  last_time: 1.0200  data_time: 0.0162  last_data_time: 0.0155   lr: 0.00067932  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:43:18 d2.utils.events]: \u001b[0m eta: 1:13:04  iter: 699  total_loss: 0.4977  loss_cls: 0.2487  loss_box_reg: 0.2138  loss_rpn_cls: 0.02465  loss_rpn_loc: 0.02315    time: 1.0204  last_time: 1.0207  data_time: 0.0155  last_data_time: 0.0158   lr: 0.0006993  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:43:39 d2.utils.events]: \u001b[0m eta: 1:12:44  iter: 719  total_loss: 0.5216  loss_cls: 0.2695  loss_box_reg: 0.2231  loss_rpn_cls: 0.01899  loss_rpn_loc: 0.02006    time: 1.0204  last_time: 1.0181  data_time: 0.0166  last_data_time: 0.0153   lr: 0.00071928  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:43:59 d2.utils.events]: \u001b[0m eta: 1:12:24  iter: 739  total_loss: 0.5138  loss_cls: 0.2564  loss_box_reg: 0.2048  loss_rpn_cls: 0.02178  loss_rpn_loc: 0.024    time: 1.0205  last_time: 1.0289  data_time: 0.0164  last_data_time: 0.0201   lr: 0.00073926  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:44:20 d2.utils.events]: \u001b[0m eta: 1:12:03  iter: 759  total_loss: 0.5338  loss_cls: 0.2663  loss_box_reg: 0.245  loss_rpn_cls: 0.01411  loss_rpn_loc: 0.02842    time: 1.0205  last_time: 1.0172  data_time: 0.0154  last_data_time: 0.0144   lr: 0.00075924  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:44:40 d2.utils.events]: \u001b[0m eta: 1:11:43  iter: 779  total_loss: 0.7143  loss_cls: 0.323  loss_box_reg: 0.254  loss_rpn_cls: 0.02667  loss_rpn_loc: 0.03689    time: 1.0206  last_time: 1.0188  data_time: 0.0163  last_data_time: 0.0182   lr: 0.00077922  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:45:01 d2.utils.events]: \u001b[0m eta: 1:11:23  iter: 799  total_loss: 0.4749  loss_cls: 0.2364  loss_box_reg: 0.1805  loss_rpn_cls: 0.02238  loss_rpn_loc: 0.02181    time: 1.0207  last_time: 1.0325  data_time: 0.0163  last_data_time: 0.0178   lr: 0.0007992  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:45:21 d2.utils.events]: \u001b[0m eta: 1:11:03  iter: 819  total_loss: 0.5311  loss_cls: 0.2691  loss_box_reg: 0.19  loss_rpn_cls: 0.03061  loss_rpn_loc: 0.03002    time: 1.0207  last_time: 1.0219  data_time: 0.0157  last_data_time: 0.0148   lr: 0.00081918  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:45:42 d2.utils.events]: \u001b[0m eta: 1:10:42  iter: 839  total_loss: 0.621  loss_cls: 0.3095  loss_box_reg: 0.2307  loss_rpn_cls: 0.03441  loss_rpn_loc: 0.02819    time: 1.0207  last_time: 1.0210  data_time: 0.0167  last_data_time: 0.0156   lr: 0.00083916  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:46:02 d2.utils.events]: \u001b[0m eta: 1:10:22  iter: 859  total_loss: 0.6362  loss_cls: 0.2855  loss_box_reg: 0.2335  loss_rpn_cls: 0.03013  loss_rpn_loc: 0.0428    time: 1.0208  last_time: 1.0244  data_time: 0.0158  last_data_time: 0.0163   lr: 0.00085914  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:46:23 d2.utils.events]: \u001b[0m eta: 1:10:02  iter: 879  total_loss: 0.454  loss_cls: 0.2074  loss_box_reg: 0.1892  loss_rpn_cls: 0.0263  loss_rpn_loc: 0.02049    time: 1.0209  last_time: 1.0290  data_time: 0.0168  last_data_time: 0.0153   lr: 0.00087912  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:46:43 d2.utils.events]: \u001b[0m eta: 1:09:42  iter: 899  total_loss: 0.5848  loss_cls: 0.2952  loss_box_reg: 0.1972  loss_rpn_cls: 0.02873  loss_rpn_loc: 0.01287    time: 1.0210  last_time: 1.0236  data_time: 0.0166  last_data_time: 0.0178   lr: 0.0008991  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:47:04 d2.utils.events]: \u001b[0m eta: 1:09:21  iter: 919  total_loss: 0.4208  loss_cls: 0.2099  loss_box_reg: 0.1617  loss_rpn_cls: 0.01625  loss_rpn_loc: 0.02201    time: 1.0210  last_time: 1.0251  data_time: 0.0159  last_data_time: 0.0192   lr: 0.00091908  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:47:24 d2.utils.events]: \u001b[0m eta: 1:09:01  iter: 939  total_loss: 0.5377  loss_cls: 0.2841  loss_box_reg: 0.2035  loss_rpn_cls: 0.02541  loss_rpn_loc: 0.0359    time: 1.0211  last_time: 1.0232  data_time: 0.0168  last_data_time: 0.0157   lr: 0.00093906  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:47:45 d2.utils.events]: \u001b[0m eta: 1:08:41  iter: 959  total_loss: 0.5719  loss_cls: 0.2711  loss_box_reg: 0.2085  loss_rpn_cls: 0.026  loss_rpn_loc: 0.04119    time: 1.0212  last_time: 1.0244  data_time: 0.0171  last_data_time: 0.0156   lr: 0.00095904  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:48:05 d2.utils.events]: \u001b[0m eta: 1:08:21  iter: 979  total_loss: 0.4573  loss_cls: 0.2148  loss_box_reg: 0.1927  loss_rpn_cls: 0.02404  loss_rpn_loc: 0.02898    time: 1.0213  last_time: 1.0264  data_time: 0.0161  last_data_time: 0.0147   lr: 0.00097902  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:48:27 d2.data.datasets.coco]: \u001b[0mLoaded 977 images in COCO format from /data/ephemeral/home/Lv2.Object_Detection/dataset/val_fold_0.json\n",
      "\u001b[32m[10/12 10:48:27 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/12 10:48:27 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/12 10:48:27 d2.data.common]: \u001b[0mSerializing 977 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 10:48:27 d2.data.common]: \u001b[0mSerialized dataset takes 0.49 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/12 10:48:27 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/12 10:48:27 d2.evaluation.evaluator]: \u001b[0mStart inference on 977 batches\n",
      "\u001b[32m[10/12 10:48:28 d2.evaluation.evaluator]: \u001b[0mInference done 11/977. Dataloading: 0.0009 s/iter. Inference: 0.0673 s/iter. Eval: 0.0002 s/iter. Total: 0.0685 s/iter. ETA=0:01:06\n",
      "\u001b[32m[10/12 10:48:33 d2.evaluation.evaluator]: \u001b[0mInference done 84/977. Dataloading: 0.0012 s/iter. Inference: 0.0673 s/iter. Eval: 0.0003 s/iter. Total: 0.0689 s/iter. ETA=0:01:01\n",
      "\u001b[32m[10/12 10:48:38 d2.evaluation.evaluator]: \u001b[0mInference done 158/977. Dataloading: 0.0012 s/iter. Inference: 0.0670 s/iter. Eval: 0.0003 s/iter. Total: 0.0687 s/iter. ETA=0:00:56\n",
      "\u001b[32m[10/12 10:48:43 d2.evaluation.evaluator]: \u001b[0mInference done 232/977. Dataloading: 0.0012 s/iter. Inference: 0.0668 s/iter. Eval: 0.0003 s/iter. Total: 0.0683 s/iter. ETA=0:00:50\n",
      "\u001b[32m[10/12 10:48:48 d2.evaluation.evaluator]: \u001b[0mInference done 305/977. Dataloading: 0.0012 s/iter. Inference: 0.0669 s/iter. Eval: 0.0003 s/iter. Total: 0.0684 s/iter. ETA=0:00:45\n",
      "\u001b[32m[10/12 10:48:53 d2.evaluation.evaluator]: \u001b[0mInference done 378/977. Dataloading: 0.0012 s/iter. Inference: 0.0669 s/iter. Eval: 0.0003 s/iter. Total: 0.0685 s/iter. ETA=0:00:41\n",
      "\u001b[32m[10/12 10:48:58 d2.evaluation.evaluator]: \u001b[0mInference done 450/977. Dataloading: 0.0012 s/iter. Inference: 0.0671 s/iter. Eval: 0.0003 s/iter. Total: 0.0686 s/iter. ETA=0:00:36\n",
      "\u001b[32m[10/12 10:49:03 d2.evaluation.evaluator]: \u001b[0mInference done 524/977. Dataloading: 0.0012 s/iter. Inference: 0.0670 s/iter. Eval: 0.0003 s/iter. Total: 0.0686 s/iter. ETA=0:00:31\n",
      "\u001b[32m[10/12 10:49:08 d2.evaluation.evaluator]: \u001b[0mInference done 598/977. Dataloading: 0.0012 s/iter. Inference: 0.0670 s/iter. Eval: 0.0003 s/iter. Total: 0.0685 s/iter. ETA=0:00:25\n",
      "\u001b[32m[10/12 10:49:13 d2.evaluation.evaluator]: \u001b[0mInference done 671/977. Dataloading: 0.0012 s/iter. Inference: 0.0671 s/iter. Eval: 0.0003 s/iter. Total: 0.0686 s/iter. ETA=0:00:20\n",
      "\u001b[32m[10/12 10:49:18 d2.evaluation.evaluator]: \u001b[0mInference done 742/977. Dataloading: 0.0012 s/iter. Inference: 0.0673 s/iter. Eval: 0.0003 s/iter. Total: 0.0688 s/iter. ETA=0:00:16\n",
      "\u001b[32m[10/12 10:49:23 d2.evaluation.evaluator]: \u001b[0mInference done 816/977. Dataloading: 0.0012 s/iter. Inference: 0.0672 s/iter. Eval: 0.0003 s/iter. Total: 0.0687 s/iter. ETA=0:00:11\n",
      "\u001b[32m[10/12 10:49:28 d2.evaluation.evaluator]: \u001b[0mInference done 890/977. Dataloading: 0.0012 s/iter. Inference: 0.0672 s/iter. Eval: 0.0003 s/iter. Total: 0.0687 s/iter. ETA=0:00:05\n",
      "\u001b[32m[10/12 10:49:34 d2.evaluation.evaluator]: \u001b[0mInference done 962/977. Dataloading: 0.0012 s/iter. Inference: 0.0673 s/iter. Eval: 0.0003 s/iter. Total: 0.0688 s/iter. ETA=0:00:01\n",
      "\u001b[32m[10/12 10:49:35 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:06.944935 (0.068873 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 10:49:35 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:05 (0.067267 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 10:49:35 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/12 10:49:35 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/12 10:49:35 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.06s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/12 10:49:35 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/12 10:49:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.72 seconds.\n",
      "\u001b[32m[10/12 10:49:36 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/12 10:49:36 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.16 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.133\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.224\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.140\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.024\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.161\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.165\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.323\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.356\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.018\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.157\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.412\n",
      "\u001b[32m[10/12 10:49:36 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 13.269 | 22.414 | 13.962 | 0.171 | 2.352 | 16.060 |\n",
      "\u001b[32m[10/12 10:49:36 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 5.512  | Paper       | 17.413 | Paper pack | 9.679  |\n",
      "| Metal         | 16.447 | Glass       | 21.284 | Plastic    | 10.849 |\n",
      "| Styrofoam     | 9.749  | Plastic bag | 36.051 | Battery    | 0.000  |\n",
      "| Clothing      | 5.703  |             |        |            |        |\n",
      "\u001b[32m[10/12 10:49:36 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_val_fold_0 in csv format:\n",
      "\u001b[32m[10/12 10:49:36 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/12 10:49:36 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/12 10:49:36 d2.evaluation.testing]: \u001b[0mcopypaste: 13.2689,22.4144,13.9619,0.1709,2.3518,16.0603\n",
      "\u001b[32m[10/12 10:49:36 d2.utils.events]: \u001b[0m eta: 1:08:01  iter: 999  total_loss: 0.533  loss_cls: 0.2495  loss_box_reg: 0.1893  loss_rpn_cls: 0.02007  loss_rpn_loc: 0.02791    time: 1.0213  last_time: 1.0217  data_time: 0.0166  last_data_time: 0.0159   lr: 0.000999  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:49:57 d2.utils.events]: \u001b[0m eta: 1:07:41  iter: 1019  total_loss: 0.5875  loss_cls: 0.2768  loss_box_reg: 0.203  loss_rpn_cls: 0.03089  loss_rpn_loc: 0.03067    time: 1.0212  last_time: 1.0235  data_time: 0.0161  last_data_time: 0.0172   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:50:17 d2.utils.events]: \u001b[0m eta: 1:07:20  iter: 1039  total_loss: 0.496  loss_cls: 0.2447  loss_box_reg: 0.1972  loss_rpn_cls: 0.02157  loss_rpn_loc: 0.02306    time: 1.0212  last_time: 1.0200  data_time: 0.0165  last_data_time: 0.0171   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:50:37 d2.utils.events]: \u001b[0m eta: 1:07:00  iter: 1059  total_loss: 0.5202  loss_cls: 0.2636  loss_box_reg: 0.2028  loss_rpn_cls: 0.02167  loss_rpn_loc: 0.02264    time: 1.0212  last_time: 1.0201  data_time: 0.0159  last_data_time: 0.0187   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:50:58 d2.utils.events]: \u001b[0m eta: 1:06:40  iter: 1079  total_loss: 0.479  loss_cls: 0.2219  loss_box_reg: 0.1791  loss_rpn_cls: 0.02017  loss_rpn_loc: 0.02581    time: 1.0212  last_time: 1.0214  data_time: 0.0153  last_data_time: 0.0149   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:51:18 d2.utils.events]: \u001b[0m eta: 1:06:19  iter: 1099  total_loss: 0.4904  loss_cls: 0.2517  loss_box_reg: 0.176  loss_rpn_cls: 0.02568  loss_rpn_loc: 0.03107    time: 1.0212  last_time: 1.0187  data_time: 0.0161  last_data_time: 0.0151   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:51:39 d2.utils.events]: \u001b[0m eta: 1:05:59  iter: 1119  total_loss: 0.5691  loss_cls: 0.274  loss_box_reg: 0.2306  loss_rpn_cls: 0.02576  loss_rpn_loc: 0.04129    time: 1.0212  last_time: 1.0207  data_time: 0.0158  last_data_time: 0.0154   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:51:59 d2.utils.events]: \u001b[0m eta: 1:05:39  iter: 1139  total_loss: 0.5055  loss_cls: 0.2382  loss_box_reg: 0.1766  loss_rpn_cls: 0.02013  loss_rpn_loc: 0.01375    time: 1.0213  last_time: 1.0225  data_time: 0.0163  last_data_time: 0.0168   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:52:20 d2.utils.events]: \u001b[0m eta: 1:05:19  iter: 1159  total_loss: 0.4411  loss_cls: 0.2298  loss_box_reg: 0.1726  loss_rpn_cls: 0.02174  loss_rpn_loc: 0.02511    time: 1.0213  last_time: 1.0211  data_time: 0.0162  last_data_time: 0.0151   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:52:40 d2.utils.events]: \u001b[0m eta: 1:04:58  iter: 1179  total_loss: 0.4595  loss_cls: 0.2202  loss_box_reg: 0.1578  loss_rpn_cls: 0.02187  loss_rpn_loc: 0.01641    time: 1.0213  last_time: 1.0235  data_time: 0.0169  last_data_time: 0.0187   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:53:01 d2.utils.events]: \u001b[0m eta: 1:04:38  iter: 1199  total_loss: 0.496  loss_cls: 0.2329  loss_box_reg: 0.1742  loss_rpn_cls: 0.01559  loss_rpn_loc: 0.02722    time: 1.0213  last_time: 1.0214  data_time: 0.0154  last_data_time: 0.0145   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:53:21 d2.utils.events]: \u001b[0m eta: 1:04:18  iter: 1219  total_loss: 0.5708  loss_cls: 0.2959  loss_box_reg: 0.1927  loss_rpn_cls: 0.02161  loss_rpn_loc: 0.02786    time: 1.0213  last_time: 1.0213  data_time: 0.0161  last_data_time: 0.0150   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:53:42 d2.utils.events]: \u001b[0m eta: 1:03:58  iter: 1239  total_loss: 0.4848  loss_cls: 0.2426  loss_box_reg: 0.1762  loss_rpn_cls: 0.02845  loss_rpn_loc: 0.02918    time: 1.0213  last_time: 1.0184  data_time: 0.0153  last_data_time: 0.0145   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:54:02 d2.utils.events]: \u001b[0m eta: 1:03:37  iter: 1259  total_loss: 0.3883  loss_cls: 0.2078  loss_box_reg: 0.1525  loss_rpn_cls: 0.01595  loss_rpn_loc: 0.01714    time: 1.0214  last_time: 1.0244  data_time: 0.0170  last_data_time: 0.0181   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:54:22 d2.utils.events]: \u001b[0m eta: 1:03:17  iter: 1279  total_loss: 0.4502  loss_cls: 0.2122  loss_box_reg: 0.1715  loss_rpn_cls: 0.01862  loss_rpn_loc: 0.02435    time: 1.0214  last_time: 1.0206  data_time: 0.0158  last_data_time: 0.0160   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:54:43 d2.utils.events]: \u001b[0m eta: 1:02:57  iter: 1299  total_loss: 0.4958  loss_cls: 0.228  loss_box_reg: 0.1988  loss_rpn_cls: 0.02091  loss_rpn_loc: 0.03076    time: 1.0214  last_time: 1.0210  data_time: 0.0161  last_data_time: 0.0147   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:55:03 d2.utils.events]: \u001b[0m eta: 1:02:37  iter: 1319  total_loss: 0.5054  loss_cls: 0.2422  loss_box_reg: 0.1813  loss_rpn_cls: 0.03011  loss_rpn_loc: 0.02843    time: 1.0214  last_time: 1.0197  data_time: 0.0162  last_data_time: 0.0143   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:55:24 d2.utils.events]: \u001b[0m eta: 1:02:17  iter: 1339  total_loss: 0.4034  loss_cls: 0.185  loss_box_reg: 0.1661  loss_rpn_cls: 0.01343  loss_rpn_loc: 0.0152    time: 1.0214  last_time: 1.0247  data_time: 0.0162  last_data_time: 0.0160   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:55:44 d2.utils.events]: \u001b[0m eta: 1:01:56  iter: 1359  total_loss: 0.3923  loss_cls: 0.2239  loss_box_reg: 0.1512  loss_rpn_cls: 0.01278  loss_rpn_loc: 0.02263    time: 1.0214  last_time: 1.0212  data_time: 0.0166  last_data_time: 0.0157   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:56:05 d2.utils.events]: \u001b[0m eta: 1:01:36  iter: 1379  total_loss: 0.5279  loss_cls: 0.2464  loss_box_reg: 0.1708  loss_rpn_cls: 0.03429  loss_rpn_loc: 0.04104    time: 1.0214  last_time: 1.0175  data_time: 0.0158  last_data_time: 0.0143   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:56:25 d2.utils.events]: \u001b[0m eta: 1:01:16  iter: 1399  total_loss: 0.4496  loss_cls: 0.2501  loss_box_reg: 0.1582  loss_rpn_cls: 0.01745  loss_rpn_loc: 0.02673    time: 1.0214  last_time: 1.0215  data_time: 0.0165  last_data_time: 0.0161   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:56:46 d2.utils.events]: \u001b[0m eta: 1:00:56  iter: 1419  total_loss: 0.4571  loss_cls: 0.2346  loss_box_reg: 0.172  loss_rpn_cls: 0.02632  loss_rpn_loc: 0.03078    time: 1.0215  last_time: 1.0250  data_time: 0.0156  last_data_time: 0.0152   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:57:06 d2.utils.events]: \u001b[0m eta: 1:00:36  iter: 1439  total_loss: 0.4722  loss_cls: 0.2533  loss_box_reg: 0.179  loss_rpn_cls: 0.01882  loss_rpn_loc: 0.02169    time: 1.0215  last_time: 1.0165  data_time: 0.0163  last_data_time: 0.0141   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:57:27 d2.utils.events]: \u001b[0m eta: 1:00:15  iter: 1459  total_loss: 0.4947  loss_cls: 0.2332  loss_box_reg: 0.1832  loss_rpn_cls: 0.02627  loss_rpn_loc: 0.02793    time: 1.0215  last_time: 1.0223  data_time: 0.0167  last_data_time: 0.0160   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:57:47 d2.utils.events]: \u001b[0m eta: 0:59:55  iter: 1479  total_loss: 0.4947  loss_cls: 0.2699  loss_box_reg: 0.177  loss_rpn_cls: 0.02004  loss_rpn_loc: 0.02344    time: 1.0215  last_time: 1.0298  data_time: 0.0171  last_data_time: 0.0157   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:58:08 d2.data.datasets.coco]: \u001b[0mLoaded 977 images in COCO format from /data/ephemeral/home/Lv2.Object_Detection/dataset/val_fold_0.json\n",
      "\u001b[32m[10/12 10:58:08 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/12 10:58:08 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/12 10:58:08 d2.data.common]: \u001b[0mSerializing 977 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 10:58:08 d2.data.common]: \u001b[0mSerialized dataset takes 0.49 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/12 10:58:08 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/12 10:58:08 d2.evaluation.evaluator]: \u001b[0mStart inference on 977 batches\n",
      "\u001b[32m[10/12 10:58:09 d2.evaluation.evaluator]: \u001b[0mInference done 11/977. Dataloading: 0.0014 s/iter. Inference: 0.0669 s/iter. Eval: 0.0003 s/iter. Total: 0.0686 s/iter. ETA=0:01:06\n",
      "\u001b[32m[10/12 10:58:14 d2.evaluation.evaluator]: \u001b[0mInference done 85/977. Dataloading: 0.0012 s/iter. Inference: 0.0665 s/iter. Eval: 0.0002 s/iter. Total: 0.0680 s/iter. ETA=0:01:00\n",
      "\u001b[32m[10/12 10:58:19 d2.evaluation.evaluator]: \u001b[0mInference done 159/977. Dataloading: 0.0012 s/iter. Inference: 0.0665 s/iter. Eval: 0.0002 s/iter. Total: 0.0680 s/iter. ETA=0:00:55\n",
      "\u001b[32m[10/12 10:58:24 d2.evaluation.evaluator]: \u001b[0mInference done 234/977. Dataloading: 0.0011 s/iter. Inference: 0.0664 s/iter. Eval: 0.0002 s/iter. Total: 0.0678 s/iter. ETA=0:00:50\n",
      "\u001b[32m[10/12 10:58:29 d2.evaluation.evaluator]: \u001b[0mInference done 305/977. Dataloading: 0.0012 s/iter. Inference: 0.0670 s/iter. Eval: 0.0002 s/iter. Total: 0.0685 s/iter. ETA=0:00:46\n",
      "\u001b[32m[10/12 10:58:34 d2.evaluation.evaluator]: \u001b[0mInference done 377/977. Dataloading: 0.0012 s/iter. Inference: 0.0672 s/iter. Eval: 0.0002 s/iter. Total: 0.0687 s/iter. ETA=0:00:41\n",
      "\u001b[32m[10/12 10:58:39 d2.evaluation.evaluator]: \u001b[0mInference done 450/977. Dataloading: 0.0012 s/iter. Inference: 0.0672 s/iter. Eval: 0.0002 s/iter. Total: 0.0687 s/iter. ETA=0:00:36\n",
      "\u001b[32m[10/12 10:58:44 d2.evaluation.evaluator]: \u001b[0mInference done 521/977. Dataloading: 0.0013 s/iter. Inference: 0.0674 s/iter. Eval: 0.0002 s/iter. Total: 0.0690 s/iter. ETA=0:00:31\n",
      "\u001b[32m[10/12 10:58:49 d2.evaluation.evaluator]: \u001b[0mInference done 593/977. Dataloading: 0.0013 s/iter. Inference: 0.0675 s/iter. Eval: 0.0002 s/iter. Total: 0.0691 s/iter. ETA=0:00:26\n",
      "\u001b[32m[10/12 10:58:54 d2.evaluation.evaluator]: \u001b[0mInference done 666/977. Dataloading: 0.0013 s/iter. Inference: 0.0675 s/iter. Eval: 0.0002 s/iter. Total: 0.0691 s/iter. ETA=0:00:21\n",
      "\u001b[32m[10/12 10:58:59 d2.evaluation.evaluator]: \u001b[0mInference done 739/977. Dataloading: 0.0013 s/iter. Inference: 0.0675 s/iter. Eval: 0.0002 s/iter. Total: 0.0691 s/iter. ETA=0:00:16\n",
      "\u001b[32m[10/12 10:59:04 d2.evaluation.evaluator]: \u001b[0mInference done 812/977. Dataloading: 0.0013 s/iter. Inference: 0.0674 s/iter. Eval: 0.0002 s/iter. Total: 0.0690 s/iter. ETA=0:00:11\n",
      "\u001b[32m[10/12 10:59:09 d2.evaluation.evaluator]: \u001b[0mInference done 883/977. Dataloading: 0.0013 s/iter. Inference: 0.0675 s/iter. Eval: 0.0002 s/iter. Total: 0.0692 s/iter. ETA=0:00:06\n",
      "\u001b[32m[10/12 10:59:14 d2.evaluation.evaluator]: \u001b[0mInference done 957/977. Dataloading: 0.0013 s/iter. Inference: 0.0675 s/iter. Eval: 0.0002 s/iter. Total: 0.0691 s/iter. ETA=0:00:01\n",
      "\u001b[32m[10/12 10:59:15 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:07.232346 (0.069169 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 10:59:15 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:05 (0.067453 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 10:59:16 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/12 10:59:16 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/12 10:59:16 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/12 10:59:16 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/12 10:59:16 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "\u001b[32m[10/12 10:59:16 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/12 10:59:17 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.210\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.312\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.227\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.247\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.447\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.473\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.011\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.179\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.541\n",
      "\u001b[32m[10/12 10:59:17 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 21.008 | 31.172 | 22.736 | 0.083 | 3.233 | 24.955 |\n",
      "\u001b[32m[10/12 10:59:17 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 8.338  | Paper       | 21.647 | Paper pack | 18.171 |\n",
      "| Metal         | 24.815 | Glass       | 26.216 | Plastic    | 16.774 |\n",
      "| Styrofoam     | 17.063 | Plastic bag | 45.253 | Battery    | 16.954 |\n",
      "| Clothing      | 14.853 |             |        |            |        |\n",
      "\u001b[32m[10/12 10:59:17 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_val_fold_0 in csv format:\n",
      "\u001b[32m[10/12 10:59:17 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/12 10:59:17 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/12 10:59:17 d2.evaluation.testing]: \u001b[0mcopypaste: 21.0083,31.1719,22.7356,0.0826,3.2330,24.9545\n",
      "\u001b[32m[10/12 10:59:17 d2.utils.events]: \u001b[0m eta: 0:59:34  iter: 1499  total_loss: 0.3521  loss_cls: 0.2074  loss_box_reg: 0.1391  loss_rpn_cls: 0.01124  loss_rpn_loc: 0.01276    time: 1.0215  last_time: 1.0238  data_time: 0.0169  last_data_time: 0.0184   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:59:37 d2.utils.events]: \u001b[0m eta: 0:59:14  iter: 1519  total_loss: 0.4416  loss_cls: 0.2183  loss_box_reg: 0.1607  loss_rpn_cls: 0.02421  loss_rpn_loc: 0.03101    time: 1.0215  last_time: 1.0209  data_time: 0.0172  last_data_time: 0.0170   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 10:59:57 d2.utils.events]: \u001b[0m eta: 0:58:54  iter: 1539  total_loss: 0.3765  loss_cls: 0.1926  loss_box_reg: 0.1428  loss_rpn_cls: 0.01927  loss_rpn_loc: 0.01429    time: 1.0215  last_time: 1.0191  data_time: 0.0156  last_data_time: 0.0155   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:00:18 d2.utils.events]: \u001b[0m eta: 0:58:33  iter: 1559  total_loss: 0.4174  loss_cls: 0.2352  loss_box_reg: 0.1398  loss_rpn_cls: 0.01312  loss_rpn_loc: 0.02035    time: 1.0215  last_time: 1.0224  data_time: 0.0167  last_data_time: 0.0208   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:00:38 d2.utils.events]: \u001b[0m eta: 0:58:13  iter: 1579  total_loss: 0.4004  loss_cls: 0.1817  loss_box_reg: 0.157  loss_rpn_cls: 0.01374  loss_rpn_loc: 0.01432    time: 1.0215  last_time: 1.0231  data_time: 0.0168  last_data_time: 0.0166   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:00:59 d2.utils.events]: \u001b[0m eta: 0:57:52  iter: 1599  total_loss: 0.4421  loss_cls: 0.2317  loss_box_reg: 0.1607  loss_rpn_cls: 0.01486  loss_rpn_loc: 0.02024    time: 1.0215  last_time: 1.0196  data_time: 0.0165  last_data_time: 0.0158   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:01:19 d2.utils.events]: \u001b[0m eta: 0:57:32  iter: 1619  total_loss: 0.4349  loss_cls: 0.2076  loss_box_reg: 0.1564  loss_rpn_cls: 0.0143  loss_rpn_loc: 0.01989    time: 1.0215  last_time: 1.0168  data_time: 0.0160  last_data_time: 0.0149   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:01:40 d2.utils.events]: \u001b[0m eta: 0:57:11  iter: 1639  total_loss: 0.41  loss_cls: 0.2112  loss_box_reg: 0.1675  loss_rpn_cls: 0.02244  loss_rpn_loc: 0.01589    time: 1.0215  last_time: 1.0195  data_time: 0.0164  last_data_time: 0.0168   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:02:00 d2.utils.events]: \u001b[0m eta: 0:56:51  iter: 1659  total_loss: 0.472  loss_cls: 0.236  loss_box_reg: 0.1728  loss_rpn_cls: 0.02207  loss_rpn_loc: 0.01877    time: 1.0215  last_time: 1.0189  data_time: 0.0148  last_data_time: 0.0147   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:02:21 d2.utils.events]: \u001b[0m eta: 0:56:31  iter: 1679  total_loss: 0.5167  loss_cls: 0.2536  loss_box_reg: 0.1735  loss_rpn_cls: 0.02808  loss_rpn_loc: 0.04159    time: 1.0215  last_time: 1.0289  data_time: 0.0168  last_data_time: 0.0223   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:02:41 d2.utils.events]: \u001b[0m eta: 0:56:10  iter: 1699  total_loss: 0.4067  loss_cls: 0.2306  loss_box_reg: 0.1631  loss_rpn_cls: 0.02167  loss_rpn_loc: 0.02102    time: 1.0215  last_time: 1.0204  data_time: 0.0167  last_data_time: 0.0168   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:03:01 d2.utils.events]: \u001b[0m eta: 0:55:49  iter: 1719  total_loss: 0.3637  loss_cls: 0.1716  loss_box_reg: 0.142  loss_rpn_cls: 0.01724  loss_rpn_loc: 0.016    time: 1.0215  last_time: 1.0201  data_time: 0.0167  last_data_time: 0.0146   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:03:22 d2.utils.events]: \u001b[0m eta: 0:55:29  iter: 1739  total_loss: 0.5102  loss_cls: 0.2482  loss_box_reg: 0.2005  loss_rpn_cls: 0.0238  loss_rpn_loc: 0.03776    time: 1.0215  last_time: 1.0215  data_time: 0.0156  last_data_time: 0.0148   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:03:42 d2.utils.events]: \u001b[0m eta: 0:55:08  iter: 1759  total_loss: 0.3926  loss_cls: 0.174  loss_box_reg: 0.1475  loss_rpn_cls: 0.02327  loss_rpn_loc: 0.02115    time: 1.0215  last_time: 1.0192  data_time: 0.0156  last_data_time: 0.0163   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:04:03 d2.utils.events]: \u001b[0m eta: 0:54:48  iter: 1779  total_loss: 0.5905  loss_cls: 0.2781  loss_box_reg: 0.2311  loss_rpn_cls: 0.02431  loss_rpn_loc: 0.03485    time: 1.0215  last_time: 1.0203  data_time: 0.0163  last_data_time: 0.0187   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:04:23 d2.utils.events]: \u001b[0m eta: 0:54:28  iter: 1799  total_loss: 0.6642  loss_cls: 0.2808  loss_box_reg: 0.2465  loss_rpn_cls: 0.02565  loss_rpn_loc: 0.03902    time: 1.0215  last_time: 1.0226  data_time: 0.0171  last_data_time: 0.0155   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:04:44 d2.utils.events]: \u001b[0m eta: 0:54:07  iter: 1819  total_loss: 0.4813  loss_cls: 0.2537  loss_box_reg: 0.1789  loss_rpn_cls: 0.02003  loss_rpn_loc: 0.03529    time: 1.0215  last_time: 1.0197  data_time: 0.0170  last_data_time: 0.0165   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:05:04 d2.utils.events]: \u001b[0m eta: 0:53:47  iter: 1839  total_loss: 0.51  loss_cls: 0.2483  loss_box_reg: 0.194  loss_rpn_cls: 0.02046  loss_rpn_loc: 0.02704    time: 1.0215  last_time: 1.0216  data_time: 0.0160  last_data_time: 0.0163   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:05:25 d2.utils.events]: \u001b[0m eta: 0:53:26  iter: 1859  total_loss: 0.3849  loss_cls: 0.1888  loss_box_reg: 0.1528  loss_rpn_cls: 0.02025  loss_rpn_loc: 0.02676    time: 1.0215  last_time: 1.0211  data_time: 0.0166  last_data_time: 0.0158   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:05:45 d2.utils.events]: \u001b[0m eta: 0:53:06  iter: 1879  total_loss: 0.427  loss_cls: 0.2113  loss_box_reg: 0.1411  loss_rpn_cls: 0.01896  loss_rpn_loc: 0.01995    time: 1.0215  last_time: 1.0177  data_time: 0.0157  last_data_time: 0.0144   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:06:05 d2.utils.events]: \u001b[0m eta: 0:52:45  iter: 1899  total_loss: 0.6158  loss_cls: 0.2832  loss_box_reg: 0.2231  loss_rpn_cls: 0.02885  loss_rpn_loc: 0.02968    time: 1.0215  last_time: 1.0286  data_time: 0.0163  last_data_time: 0.0162   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:06:26 d2.utils.events]: \u001b[0m eta: 0:52:25  iter: 1919  total_loss: 0.5661  loss_cls: 0.2395  loss_box_reg: 0.1951  loss_rpn_cls: 0.02675  loss_rpn_loc: 0.02972    time: 1.0216  last_time: 1.0193  data_time: 0.0172  last_data_time: 0.0144   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:06:46 d2.utils.events]: \u001b[0m eta: 0:52:04  iter: 1939  total_loss: 0.45  loss_cls: 0.2402  loss_box_reg: 0.1621  loss_rpn_cls: 0.02486  loss_rpn_loc: 0.02312    time: 1.0216  last_time: 1.0167  data_time: 0.0168  last_data_time: 0.0145   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:07:07 d2.utils.events]: \u001b[0m eta: 0:51:44  iter: 1959  total_loss: 0.3892  loss_cls: 0.2064  loss_box_reg: 0.133  loss_rpn_cls: 0.01195  loss_rpn_loc: 0.01942    time: 1.0216  last_time: 1.0183  data_time: 0.0166  last_data_time: 0.0155   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:07:27 d2.utils.events]: \u001b[0m eta: 0:51:23  iter: 1979  total_loss: 0.4105  loss_cls: 0.2051  loss_box_reg: 0.1541  loss_rpn_cls: 0.01694  loss_rpn_loc: 0.0241    time: 1.0216  last_time: 1.0199  data_time: 0.0160  last_data_time: 0.0150   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:07:49 d2.data.datasets.coco]: \u001b[0mLoaded 977 images in COCO format from /data/ephemeral/home/Lv2.Object_Detection/dataset/val_fold_0.json\n",
      "\u001b[32m[10/12 11:07:49 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/12 11:07:49 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/12 11:07:49 d2.data.common]: \u001b[0mSerializing 977 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 11:07:49 d2.data.common]: \u001b[0mSerialized dataset takes 0.49 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/12 11:07:49 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/12 11:07:49 d2.evaluation.evaluator]: \u001b[0mStart inference on 977 batches\n",
      "\u001b[32m[10/12 11:07:50 d2.evaluation.evaluator]: \u001b[0mInference done 11/977. Dataloading: 0.0009 s/iter. Inference: 0.0666 s/iter. Eval: 0.0002 s/iter. Total: 0.0677 s/iter. ETA=0:01:05\n",
      "\u001b[32m[10/12 11:07:55 d2.evaluation.evaluator]: \u001b[0mInference done 85/977. Dataloading: 0.0012 s/iter. Inference: 0.0667 s/iter. Eval: 0.0002 s/iter. Total: 0.0683 s/iter. ETA=0:01:00\n",
      "\u001b[32m[10/12 11:08:00 d2.evaluation.evaluator]: \u001b[0mInference done 158/977. Dataloading: 0.0012 s/iter. Inference: 0.0671 s/iter. Eval: 0.0002 s/iter. Total: 0.0686 s/iter. ETA=0:00:56\n",
      "\u001b[32m[10/12 11:08:06 d2.evaluation.evaluator]: \u001b[0mInference done 230/977. Dataloading: 0.0013 s/iter. Inference: 0.0675 s/iter. Eval: 0.0002 s/iter. Total: 0.0691 s/iter. ETA=0:00:51\n",
      "\u001b[32m[10/12 11:08:11 d2.evaluation.evaluator]: \u001b[0mInference done 303/977. Dataloading: 0.0013 s/iter. Inference: 0.0675 s/iter. Eval: 0.0002 s/iter. Total: 0.0691 s/iter. ETA=0:00:46\n",
      "\u001b[32m[10/12 11:08:16 d2.evaluation.evaluator]: \u001b[0mInference done 374/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0002 s/iter. Total: 0.0694 s/iter. ETA=0:00:41\n",
      "\u001b[32m[10/12 11:08:21 d2.evaluation.evaluator]: \u001b[0mInference done 446/977. Dataloading: 0.0013 s/iter. Inference: 0.0679 s/iter. Eval: 0.0003 s/iter. Total: 0.0695 s/iter. ETA=0:00:36\n",
      "\u001b[32m[10/12 11:08:26 d2.evaluation.evaluator]: \u001b[0mInference done 517/977. Dataloading: 0.0014 s/iter. Inference: 0.0680 s/iter. Eval: 0.0002 s/iter. Total: 0.0697 s/iter. ETA=0:00:32\n",
      "\u001b[32m[10/12 11:08:31 d2.evaluation.evaluator]: \u001b[0mInference done 586/977. Dataloading: 0.0014 s/iter. Inference: 0.0684 s/iter. Eval: 0.0003 s/iter. Total: 0.0701 s/iter. ETA=0:00:27\n",
      "\u001b[32m[10/12 11:08:36 d2.evaluation.evaluator]: \u001b[0mInference done 658/977. Dataloading: 0.0014 s/iter. Inference: 0.0684 s/iter. Eval: 0.0002 s/iter. Total: 0.0701 s/iter. ETA=0:00:22\n",
      "\u001b[32m[10/12 11:08:41 d2.evaluation.evaluator]: \u001b[0mInference done 730/977. Dataloading: 0.0014 s/iter. Inference: 0.0683 s/iter. Eval: 0.0002 s/iter. Total: 0.0700 s/iter. ETA=0:00:17\n",
      "\u001b[32m[10/12 11:08:46 d2.evaluation.evaluator]: \u001b[0mInference done 803/977. Dataloading: 0.0013 s/iter. Inference: 0.0682 s/iter. Eval: 0.0002 s/iter. Total: 0.0699 s/iter. ETA=0:00:12\n",
      "\u001b[32m[10/12 11:08:51 d2.evaluation.evaluator]: \u001b[0mInference done 877/977. Dataloading: 0.0013 s/iter. Inference: 0.0681 s/iter. Eval: 0.0002 s/iter. Total: 0.0697 s/iter. ETA=0:00:06\n",
      "\u001b[32m[10/12 11:08:56 d2.evaluation.evaluator]: \u001b[0mInference done 951/977. Dataloading: 0.0013 s/iter. Inference: 0.0680 s/iter. Eval: 0.0002 s/iter. Total: 0.0696 s/iter. ETA=0:00:01\n",
      "\u001b[32m[10/12 11:08:58 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:07.745820 (0.069697 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 11:08:58 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:06 (0.067961 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 11:08:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/12 11:08:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/12 11:08:58 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/12 11:08:58 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/12 11:08:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.63 seconds.\n",
      "\u001b[32m[10/12 11:08:59 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/12 11:08:59 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.12 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.214\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.316\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.235\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.039\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.255\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.421\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.448\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.017\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.166\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.514\n",
      "\u001b[32m[10/12 11:08:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 21.402 | 31.604 | 23.461 | 0.133 | 3.860 | 25.508 |\n",
      "\u001b[32m[10/12 11:08:59 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 9.350  | Paper       | 23.490 | Paper pack | 17.945 |\n",
      "| Metal         | 24.419 | Glass       | 27.794 | Plastic    | 17.172 |\n",
      "| Styrofoam     | 16.645 | Plastic bag | 46.232 | Battery    | 17.850 |\n",
      "| Clothing      | 13.125 |             |        |            |        |\n",
      "\u001b[32m[10/12 11:08:59 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_val_fold_0 in csv format:\n",
      "\u001b[32m[10/12 11:08:59 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/12 11:08:59 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/12 11:08:59 d2.evaluation.testing]: \u001b[0mcopypaste: 21.4023,31.6038,23.4614,0.1332,3.8605,25.5080\n",
      "\u001b[32m[10/12 11:08:59 d2.utils.events]: \u001b[0m eta: 0:51:03  iter: 1999  total_loss: 0.4259  loss_cls: 0.1941  loss_box_reg: 0.2064  loss_rpn_cls: 0.01189  loss_rpn_loc: 0.0161    time: 1.0216  last_time: 1.0193  data_time: 0.0154  last_data_time: 0.0138   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:09:19 d2.utils.events]: \u001b[0m eta: 0:50:42  iter: 2019  total_loss: 0.4922  loss_cls: 0.2564  loss_box_reg: 0.18  loss_rpn_cls: 0.01595  loss_rpn_loc: 0.04452    time: 1.0216  last_time: 1.0176  data_time: 0.0166  last_data_time: 0.0159   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:09:40 d2.utils.events]: \u001b[0m eta: 0:50:22  iter: 2039  total_loss: 0.444  loss_cls: 0.2142  loss_box_reg: 0.1347  loss_rpn_cls: 0.01771  loss_rpn_loc: 0.02817    time: 1.0216  last_time: 1.0239  data_time: 0.0171  last_data_time: 0.0189   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:10:00 d2.utils.events]: \u001b[0m eta: 0:50:02  iter: 2059  total_loss: 0.3394  loss_cls: 0.1889  loss_box_reg: 0.1318  loss_rpn_cls: 0.01496  loss_rpn_loc: 0.02218    time: 1.0216  last_time: 1.0319  data_time: 0.0160  last_data_time: 0.0180   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:10:21 d2.utils.events]: \u001b[0m eta: 0:49:41  iter: 2079  total_loss: 0.4664  loss_cls: 0.2317  loss_box_reg: 0.1782  loss_rpn_cls: 0.01506  loss_rpn_loc: 0.02293    time: 1.0216  last_time: 1.0190  data_time: 0.0158  last_data_time: 0.0143   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:10:41 d2.utils.events]: \u001b[0m eta: 0:49:21  iter: 2099  total_loss: 0.3508  loss_cls: 0.202  loss_box_reg: 0.1431  loss_rpn_cls: 0.01152  loss_rpn_loc: 0.01586    time: 1.0216  last_time: 1.0229  data_time: 0.0157  last_data_time: 0.0196   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:11:02 d2.utils.events]: \u001b[0m eta: 0:49:00  iter: 2119  total_loss: 0.4859  loss_cls: 0.2505  loss_box_reg: 0.1642  loss_rpn_cls: 0.01746  loss_rpn_loc: 0.02405    time: 1.0216  last_time: 1.0203  data_time: 0.0157  last_data_time: 0.0147   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:11:22 d2.utils.events]: \u001b[0m eta: 0:48:40  iter: 2139  total_loss: 0.5193  loss_cls: 0.236  loss_box_reg: 0.1744  loss_rpn_cls: 0.02267  loss_rpn_loc: 0.03605    time: 1.0216  last_time: 1.0195  data_time: 0.0164  last_data_time: 0.0145   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:11:42 d2.utils.events]: \u001b[0m eta: 0:48:19  iter: 2159  total_loss: 0.4334  loss_cls: 0.2095  loss_box_reg: 0.1587  loss_rpn_cls: 0.0153  loss_rpn_loc: 0.01885    time: 1.0216  last_time: 1.0203  data_time: 0.0168  last_data_time: 0.0157   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:12:03 d2.utils.events]: \u001b[0m eta: 0:47:59  iter: 2179  total_loss: 0.4403  loss_cls: 0.2138  loss_box_reg: 0.1664  loss_rpn_cls: 0.02086  loss_rpn_loc: 0.02783    time: 1.0216  last_time: 1.0202  data_time: 0.0155  last_data_time: 0.0148   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:12:23 d2.utils.events]: \u001b[0m eta: 0:47:39  iter: 2199  total_loss: 0.3828  loss_cls: 0.2089  loss_box_reg: 0.1515  loss_rpn_cls: 0.009364  loss_rpn_loc: 0.0169    time: 1.0216  last_time: 1.0181  data_time: 0.0162  last_data_time: 0.0153   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:12:44 d2.utils.events]: \u001b[0m eta: 0:47:18  iter: 2219  total_loss: 0.3582  loss_cls: 0.1866  loss_box_reg: 0.1177  loss_rpn_cls: 0.01702  loss_rpn_loc: 0.02817    time: 1.0216  last_time: 1.0209  data_time: 0.0165  last_data_time: 0.0157   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:13:04 d2.utils.events]: \u001b[0m eta: 0:46:58  iter: 2239  total_loss: 0.4207  loss_cls: 0.2234  loss_box_reg: 0.1605  loss_rpn_cls: 0.02014  loss_rpn_loc: 0.02482    time: 1.0216  last_time: 1.0225  data_time: 0.0164  last_data_time: 0.0180   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:13:25 d2.utils.events]: \u001b[0m eta: 0:46:37  iter: 2259  total_loss: 0.472  loss_cls: 0.2539  loss_box_reg: 0.1656  loss_rpn_cls: 0.01761  loss_rpn_loc: 0.02403    time: 1.0216  last_time: 1.0204  data_time: 0.0158  last_data_time: 0.0151   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:13:45 d2.utils.events]: \u001b[0m eta: 0:46:17  iter: 2279  total_loss: 0.3718  loss_cls: 0.2009  loss_box_reg: 0.1443  loss_rpn_cls: 0.01353  loss_rpn_loc: 0.01608    time: 1.0216  last_time: 1.0286  data_time: 0.0166  last_data_time: 0.0166   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:14:06 d2.utils.events]: \u001b[0m eta: 0:45:57  iter: 2299  total_loss: 0.2689  loss_cls: 0.1435  loss_box_reg: 0.09834  loss_rpn_cls: 0.01224  loss_rpn_loc: 0.01157    time: 1.0217  last_time: 1.0194  data_time: 0.0168  last_data_time: 0.0158   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:14:26 d2.utils.events]: \u001b[0m eta: 0:45:36  iter: 2319  total_loss: 0.3279  loss_cls: 0.1736  loss_box_reg: 0.1389  loss_rpn_cls: 0.00957  loss_rpn_loc: 0.028    time: 1.0216  last_time: 1.0240  data_time: 0.0165  last_data_time: 0.0167   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:14:47 d2.utils.events]: \u001b[0m eta: 0:45:16  iter: 2339  total_loss: 0.4098  loss_cls: 0.2054  loss_box_reg: 0.1551  loss_rpn_cls: 0.01475  loss_rpn_loc: 0.015    time: 1.0216  last_time: 1.0258  data_time: 0.0164  last_data_time: 0.0214   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:15:07 d2.utils.events]: \u001b[0m eta: 0:44:55  iter: 2359  total_loss: 0.3625  loss_cls: 0.186  loss_box_reg: 0.1226  loss_rpn_cls: 0.01486  loss_rpn_loc: 0.01615    time: 1.0216  last_time: 1.0182  data_time: 0.0162  last_data_time: 0.0144   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:15:27 d2.utils.events]: \u001b[0m eta: 0:44:35  iter: 2379  total_loss: 0.4239  loss_cls: 0.1863  loss_box_reg: 0.1697  loss_rpn_cls: 0.01456  loss_rpn_loc: 0.02184    time: 1.0216  last_time: 1.0189  data_time: 0.0164  last_data_time: 0.0152   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:15:48 d2.utils.events]: \u001b[0m eta: 0:44:14  iter: 2399  total_loss: 0.4015  loss_cls: 0.1874  loss_box_reg: 0.1518  loss_rpn_cls: 0.01535  loss_rpn_loc: 0.02037    time: 1.0216  last_time: 1.0278  data_time: 0.0146  last_data_time: 0.0185   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:16:08 d2.utils.events]: \u001b[0m eta: 0:43:53  iter: 2419  total_loss: 0.4101  loss_cls: 0.1892  loss_box_reg: 0.1631  loss_rpn_cls: 0.01647  loss_rpn_loc: 0.02626    time: 1.0216  last_time: 1.0242  data_time: 0.0161  last_data_time: 0.0169   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:16:29 d2.utils.events]: \u001b[0m eta: 0:43:33  iter: 2439  total_loss: 0.3689  loss_cls: 0.1868  loss_box_reg: 0.1217  loss_rpn_cls: 0.01534  loss_rpn_loc: 0.01314    time: 1.0216  last_time: 1.0238  data_time: 0.0153  last_data_time: 0.0162   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:16:49 d2.utils.events]: \u001b[0m eta: 0:43:12  iter: 2459  total_loss: 0.3345  loss_cls: 0.2103  loss_box_reg: 0.1196  loss_rpn_cls: 0.01601  loss_rpn_loc: 0.01677    time: 1.0216  last_time: 1.0176  data_time: 0.0158  last_data_time: 0.0147   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:17:10 d2.utils.events]: \u001b[0m eta: 0:42:52  iter: 2479  total_loss: 0.4942  loss_cls: 0.2508  loss_box_reg: 0.1909  loss_rpn_cls: 0.02531  loss_rpn_loc: 0.03008    time: 1.0216  last_time: 1.0230  data_time: 0.0167  last_data_time: 0.0206   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:17:30 d2.data.datasets.coco]: \u001b[0mLoaded 977 images in COCO format from /data/ephemeral/home/Lv2.Object_Detection/dataset/val_fold_0.json\n",
      "\u001b[32m[10/12 11:17:30 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/12 11:17:30 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/12 11:17:30 d2.data.common]: \u001b[0mSerializing 977 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 11:17:30 d2.data.common]: \u001b[0mSerialized dataset takes 0.49 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/12 11:17:30 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/12 11:17:30 d2.evaluation.evaluator]: \u001b[0mStart inference on 977 batches\n",
      "\u001b[32m[10/12 11:17:31 d2.evaluation.evaluator]: \u001b[0mInference done 11/977. Dataloading: 0.0013 s/iter. Inference: 0.0676 s/iter. Eval: 0.0003 s/iter. Total: 0.0691 s/iter. ETA=0:01:06\n",
      "\u001b[32m[10/12 11:17:36 d2.evaluation.evaluator]: \u001b[0mInference done 84/977. Dataloading: 0.0013 s/iter. Inference: 0.0675 s/iter. Eval: 0.0003 s/iter. Total: 0.0691 s/iter. ETA=0:01:01\n",
      "\u001b[32m[10/12 11:17:41 d2.evaluation.evaluator]: \u001b[0mInference done 157/977. Dataloading: 0.0013 s/iter. Inference: 0.0674 s/iter. Eval: 0.0002 s/iter. Total: 0.0690 s/iter. ETA=0:00:56\n",
      "\u001b[32m[10/12 11:17:46 d2.evaluation.evaluator]: \u001b[0mInference done 228/977. Dataloading: 0.0013 s/iter. Inference: 0.0679 s/iter. Eval: 0.0003 s/iter. Total: 0.0695 s/iter. ETA=0:00:52\n",
      "\u001b[32m[10/12 11:17:51 d2.evaluation.evaluator]: \u001b[0mInference done 301/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:00:46\n",
      "\u001b[32m[10/12 11:17:56 d2.evaluation.evaluator]: \u001b[0mInference done 373/977. Dataloading: 0.0013 s/iter. Inference: 0.0679 s/iter. Eval: 0.0003 s/iter. Total: 0.0696 s/iter. ETA=0:00:42\n",
      "\u001b[32m[10/12 11:18:01 d2.evaluation.evaluator]: \u001b[0mInference done 446/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0003 s/iter. Total: 0.0695 s/iter. ETA=0:00:36\n",
      "\u001b[32m[10/12 11:18:06 d2.evaluation.evaluator]: \u001b[0mInference done 519/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0002 s/iter. Total: 0.0694 s/iter. ETA=0:00:31\n",
      "\u001b[32m[10/12 11:18:11 d2.evaluation.evaluator]: \u001b[0mInference done 592/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0002 s/iter. Total: 0.0693 s/iter. ETA=0:00:26\n",
      "\u001b[32m[10/12 11:18:16 d2.evaluation.evaluator]: \u001b[0mInference done 665/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0002 s/iter. Total: 0.0693 s/iter. ETA=0:00:21\n",
      "\u001b[32m[10/12 11:18:21 d2.evaluation.evaluator]: \u001b[0mInference done 738/977. Dataloading: 0.0013 s/iter. Inference: 0.0676 s/iter. Eval: 0.0002 s/iter. Total: 0.0692 s/iter. ETA=0:00:16\n",
      "\u001b[32m[10/12 11:18:26 d2.evaluation.evaluator]: \u001b[0mInference done 811/977. Dataloading: 0.0013 s/iter. Inference: 0.0676 s/iter. Eval: 0.0002 s/iter. Total: 0.0692 s/iter. ETA=0:00:11\n",
      "\u001b[32m[10/12 11:18:31 d2.evaluation.evaluator]: \u001b[0mInference done 885/977. Dataloading: 0.0013 s/iter. Inference: 0.0675 s/iter. Eval: 0.0002 s/iter. Total: 0.0691 s/iter. ETA=0:00:06\n",
      "\u001b[32m[10/12 11:18:37 d2.evaluation.evaluator]: \u001b[0mInference done 958/977. Dataloading: 0.0013 s/iter. Inference: 0.0675 s/iter. Eval: 0.0002 s/iter. Total: 0.0691 s/iter. ETA=0:00:01\n",
      "\u001b[32m[10/12 11:18:38 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:07.275904 (0.069214 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 11:18:38 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:05 (0.067517 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 11:18:38 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/12 11:18:38 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/12 11:18:38 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.25s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/12 11:18:39 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/12 11:18:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.41 seconds.\n",
      "\u001b[32m[10/12 11:18:39 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/12 11:18:39 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.12 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.257\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.371\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.272\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.304\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.265\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.478\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.505\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.016\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.171\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.580\n",
      "\u001b[32m[10/12 11:18:39 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 25.683 | 37.061 | 27.182 | 0.196 | 4.380 | 30.439 |\n",
      "\u001b[32m[10/12 11:18:39 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 11.763 | Paper       | 21.801 | Paper pack | 27.794 |\n",
      "| Metal         | 29.525 | Glass       | 27.091 | Plastic    | 19.225 |\n",
      "| Styrofoam     | 23.706 | Plastic bag | 46.609 | Battery    | 31.885 |\n",
      "| Clothing      | 17.430 |             |        |            |        |\n",
      "\u001b[32m[10/12 11:18:39 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_val_fold_0 in csv format:\n",
      "\u001b[32m[10/12 11:18:39 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/12 11:18:39 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/12 11:18:39 d2.evaluation.testing]: \u001b[0mcopypaste: 25.6829,37.0608,27.1820,0.1963,4.3800,30.4392\n",
      "\u001b[32m[10/12 11:18:39 d2.utils.events]: \u001b[0m eta: 0:42:31  iter: 2499  total_loss: 0.346  loss_cls: 0.173  loss_box_reg: 0.1302  loss_rpn_cls: 0.01298  loss_rpn_loc: 0.01884    time: 1.0216  last_time: 1.0208  data_time: 0.0174  last_data_time: 0.0158   lr: 0.001  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:19:00 d2.utils.events]: \u001b[0m eta: 0:42:11  iter: 2519  total_loss: 0.4004  loss_cls: 0.1889  loss_box_reg: 0.1477  loss_rpn_cls: 0.01473  loss_rpn_loc: 0.02559    time: 1.0216  last_time: 1.0207  data_time: 0.0164  last_data_time: 0.0149   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:19:20 d2.utils.events]: \u001b[0m eta: 0:41:50  iter: 2539  total_loss: 0.4719  loss_cls: 0.2196  loss_box_reg: 0.1763  loss_rpn_cls: 0.01514  loss_rpn_loc: 0.03898    time: 1.0216  last_time: 1.0220  data_time: 0.0173  last_data_time: 0.0172   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:19:41 d2.utils.events]: \u001b[0m eta: 0:41:30  iter: 2559  total_loss: 0.4669  loss_cls: 0.2339  loss_box_reg: 0.1685  loss_rpn_cls: 0.01879  loss_rpn_loc: 0.02813    time: 1.0216  last_time: 1.0217  data_time: 0.0166  last_data_time: 0.0159   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:20:01 d2.utils.events]: \u001b[0m eta: 0:41:10  iter: 2579  total_loss: 0.3538  loss_cls: 0.2044  loss_box_reg: 0.1417  loss_rpn_cls: 0.02171  loss_rpn_loc: 0.01699    time: 1.0216  last_time: 1.0215  data_time: 0.0167  last_data_time: 0.0164   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:20:21 d2.utils.events]: \u001b[0m eta: 0:40:49  iter: 2599  total_loss: 0.4577  loss_cls: 0.2353  loss_box_reg: 0.1841  loss_rpn_cls: 0.0191  loss_rpn_loc: 0.02217    time: 1.0216  last_time: 1.0206  data_time: 0.0160  last_data_time: 0.0159   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:20:42 d2.utils.events]: \u001b[0m eta: 0:40:29  iter: 2619  total_loss: 0.3833  loss_cls: 0.2302  loss_box_reg: 0.1373  loss_rpn_cls: 0.01975  loss_rpn_loc: 0.0177    time: 1.0216  last_time: 1.0352  data_time: 0.0158  last_data_time: 0.0261   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:21:02 d2.utils.events]: \u001b[0m eta: 0:40:08  iter: 2639  total_loss: 0.4054  loss_cls: 0.2051  loss_box_reg: 0.1553  loss_rpn_cls: 0.01583  loss_rpn_loc: 0.01707    time: 1.0216  last_time: 1.0203  data_time: 0.0166  last_data_time: 0.0150   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:21:23 d2.utils.events]: \u001b[0m eta: 0:39:48  iter: 2659  total_loss: 0.4706  loss_cls: 0.2266  loss_box_reg: 0.1641  loss_rpn_cls: 0.02518  loss_rpn_loc: 0.031    time: 1.0216  last_time: 1.0238  data_time: 0.0163  last_data_time: 0.0154   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:21:43 d2.utils.events]: \u001b[0m eta: 0:39:28  iter: 2679  total_loss: 0.4234  loss_cls: 0.2092  loss_box_reg: 0.165  loss_rpn_cls: 0.01732  loss_rpn_loc: 0.02278    time: 1.0216  last_time: 1.0228  data_time: 0.0174  last_data_time: 0.0163   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:22:04 d2.utils.events]: \u001b[0m eta: 0:39:07  iter: 2699  total_loss: 0.3798  loss_cls: 0.2028  loss_box_reg: 0.1389  loss_rpn_cls: 0.01149  loss_rpn_loc: 0.02219    time: 1.0216  last_time: 1.0153  data_time: 0.0171  last_data_time: 0.0150   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:22:24 d2.utils.events]: \u001b[0m eta: 0:38:47  iter: 2719  total_loss: 0.3864  loss_cls: 0.1833  loss_box_reg: 0.1749  loss_rpn_cls: 0.01369  loss_rpn_loc: 0.02339    time: 1.0216  last_time: 1.0208  data_time: 0.0156  last_data_time: 0.0152   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:22:45 d2.utils.events]: \u001b[0m eta: 0:38:26  iter: 2739  total_loss: 0.5546  loss_cls: 0.2609  loss_box_reg: 0.1772  loss_rpn_cls: 0.02602  loss_rpn_loc: 0.0323    time: 1.0216  last_time: 1.0213  data_time: 0.0160  last_data_time: 0.0158   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:23:05 d2.utils.events]: \u001b[0m eta: 0:38:06  iter: 2759  total_loss: 0.4083  loss_cls: 0.2108  loss_box_reg: 0.1572  loss_rpn_cls: 0.02123  loss_rpn_loc: 0.02666    time: 1.0216  last_time: 1.0176  data_time: 0.0165  last_data_time: 0.0148   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:23:26 d2.utils.events]: \u001b[0m eta: 0:37:46  iter: 2779  total_loss: 0.3928  loss_cls: 0.2005  loss_box_reg: 0.1481  loss_rpn_cls: 0.01172  loss_rpn_loc: 0.03054    time: 1.0216  last_time: 1.0202  data_time: 0.0164  last_data_time: 0.0155   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:23:46 d2.utils.events]: \u001b[0m eta: 0:37:25  iter: 2799  total_loss: 0.5096  loss_cls: 0.2577  loss_box_reg: 0.1606  loss_rpn_cls: 0.02445  loss_rpn_loc: 0.02868    time: 1.0216  last_time: 1.0211  data_time: 0.0159  last_data_time: 0.0177   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:24:06 d2.utils.events]: \u001b[0m eta: 0:37:05  iter: 2819  total_loss: 0.4365  loss_cls: 0.2183  loss_box_reg: 0.1725  loss_rpn_cls: 0.01589  loss_rpn_loc: 0.02242    time: 1.0216  last_time: 1.0200  data_time: 0.0162  last_data_time: 0.0161   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:24:27 d2.utils.events]: \u001b[0m eta: 0:36:44  iter: 2839  total_loss: 0.4771  loss_cls: 0.2428  loss_box_reg: 0.1714  loss_rpn_cls: 0.01692  loss_rpn_loc: 0.02628    time: 1.0216  last_time: 1.0226  data_time: 0.0164  last_data_time: 0.0162   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:24:47 d2.utils.events]: \u001b[0m eta: 0:36:24  iter: 2859  total_loss: 0.4339  loss_cls: 0.1918  loss_box_reg: 0.1533  loss_rpn_cls: 0.01513  loss_rpn_loc: 0.03749    time: 1.0216  last_time: 1.0203  data_time: 0.0160  last_data_time: 0.0160   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:25:08 d2.utils.events]: \u001b[0m eta: 0:36:04  iter: 2879  total_loss: 0.4061  loss_cls: 0.1683  loss_box_reg: 0.1669  loss_rpn_cls: 0.009171  loss_rpn_loc: 0.02312    time: 1.0216  last_time: 1.0212  data_time: 0.0160  last_data_time: 0.0151   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:25:28 d2.utils.events]: \u001b[0m eta: 0:35:43  iter: 2899  total_loss: 0.3973  loss_cls: 0.2092  loss_box_reg: 0.154  loss_rpn_cls: 0.01286  loss_rpn_loc: 0.02695    time: 1.0216  last_time: 1.0206  data_time: 0.0162  last_data_time: 0.0165   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:25:49 d2.utils.events]: \u001b[0m eta: 0:35:23  iter: 2919  total_loss: 0.4713  loss_cls: 0.2089  loss_box_reg: 0.1857  loss_rpn_cls: 0.01317  loss_rpn_loc: 0.02328    time: 1.0216  last_time: 1.0209  data_time: 0.0164  last_data_time: 0.0161   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:26:09 d2.utils.events]: \u001b[0m eta: 0:35:02  iter: 2939  total_loss: 0.4918  loss_cls: 0.259  loss_box_reg: 0.1833  loss_rpn_cls: 0.01659  loss_rpn_loc: 0.02957    time: 1.0216  last_time: 1.0241  data_time: 0.0167  last_data_time: 0.0164   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:26:30 d2.utils.events]: \u001b[0m eta: 0:34:42  iter: 2959  total_loss: 0.2903  loss_cls: 0.1723  loss_box_reg: 0.1153  loss_rpn_cls: 0.01013  loss_rpn_loc: 0.01507    time: 1.0216  last_time: 1.0192  data_time: 0.0165  last_data_time: 0.0154   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:26:50 d2.utils.events]: \u001b[0m eta: 0:34:22  iter: 2979  total_loss: 0.4215  loss_cls: 0.2093  loss_box_reg: 0.1521  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.03004    time: 1.0216  last_time: 1.0204  data_time: 0.0166  last_data_time: 0.0155   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:27:12 d2.data.datasets.coco]: \u001b[0mLoaded 977 images in COCO format from /data/ephemeral/home/Lv2.Object_Detection/dataset/val_fold_0.json\n",
      "\u001b[32m[10/12 11:27:12 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/12 11:27:12 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/12 11:27:12 d2.data.common]: \u001b[0mSerializing 977 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 11:27:12 d2.data.common]: \u001b[0mSerialized dataset takes 0.49 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/12 11:27:12 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/12 11:27:12 d2.evaluation.evaluator]: \u001b[0mStart inference on 977 batches\n",
      "\u001b[32m[10/12 11:27:13 d2.evaluation.evaluator]: \u001b[0mInference done 11/977. Dataloading: 0.0010 s/iter. Inference: 0.0687 s/iter. Eval: 0.0002 s/iter. Total: 0.0699 s/iter. ETA=0:01:07\n",
      "\u001b[32m[10/12 11:27:18 d2.evaluation.evaluator]: \u001b[0mInference done 84/977. Dataloading: 0.0013 s/iter. Inference: 0.0673 s/iter. Eval: 0.0003 s/iter. Total: 0.0690 s/iter. ETA=0:01:01\n",
      "\u001b[32m[10/12 11:27:23 d2.evaluation.evaluator]: \u001b[0mInference done 156/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0003 s/iter. Total: 0.0695 s/iter. ETA=0:00:57\n",
      "\u001b[32m[10/12 11:27:28 d2.evaluation.evaluator]: \u001b[0mInference done 229/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:00:51\n",
      "\u001b[32m[10/12 11:27:33 d2.evaluation.evaluator]: \u001b[0mInference done 302/977. Dataloading: 0.0013 s/iter. Inference: 0.0676 s/iter. Eval: 0.0003 s/iter. Total: 0.0692 s/iter. ETA=0:00:46\n",
      "\u001b[32m[10/12 11:27:38 d2.evaluation.evaluator]: \u001b[0mInference done 376/977. Dataloading: 0.0013 s/iter. Inference: 0.0673 s/iter. Eval: 0.0003 s/iter. Total: 0.0689 s/iter. ETA=0:00:41\n",
      "\u001b[32m[10/12 11:27:43 d2.evaluation.evaluator]: \u001b[0mInference done 449/977. Dataloading: 0.0013 s/iter. Inference: 0.0673 s/iter. Eval: 0.0003 s/iter. Total: 0.0689 s/iter. ETA=0:00:36\n",
      "\u001b[32m[10/12 11:27:48 d2.evaluation.evaluator]: \u001b[0mInference done 518/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0002 s/iter. Total: 0.0694 s/iter. ETA=0:00:31\n",
      "\u001b[32m[10/12 11:27:53 d2.evaluation.evaluator]: \u001b[0mInference done 591/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0002 s/iter. Total: 0.0693 s/iter. ETA=0:00:26\n",
      "\u001b[32m[10/12 11:27:58 d2.evaluation.evaluator]: \u001b[0mInference done 664/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0002 s/iter. Total: 0.0693 s/iter. ETA=0:00:21\n",
      "\u001b[32m[10/12 11:28:03 d2.evaluation.evaluator]: \u001b[0mInference done 737/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0002 s/iter. Total: 0.0693 s/iter. ETA=0:00:16\n",
      "\u001b[32m[10/12 11:28:08 d2.evaluation.evaluator]: \u001b[0mInference done 810/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0002 s/iter. Total: 0.0693 s/iter. ETA=0:00:11\n",
      "\u001b[32m[10/12 11:28:13 d2.evaluation.evaluator]: \u001b[0mInference done 883/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0002 s/iter. Total: 0.0693 s/iter. ETA=0:00:06\n",
      "\u001b[32m[10/12 11:28:18 d2.evaluation.evaluator]: \u001b[0mInference done 956/977. Dataloading: 0.0013 s/iter. Inference: 0.0676 s/iter. Eval: 0.0002 s/iter. Total: 0.0693 s/iter. ETA=0:00:01\n",
      "\u001b[32m[10/12 11:28:20 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:07.403494 (0.069345 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 11:28:20 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:05 (0.067629 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 11:28:20 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/12 11:28:20 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/12 11:28:20 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/12 11:28:20 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/12 11:28:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.64 seconds.\n",
      "\u001b[32m[10/12 11:28:21 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/12 11:28:21 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.262\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.373\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.280\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.043\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.310\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.267\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.482\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.511\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.585\n",
      "\u001b[32m[10/12 11:28:21 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 26.227 | 37.340 | 27.950 | 0.186 | 4.307 | 31.018 |\n",
      "\u001b[32m[10/12 11:28:21 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 11.176 | Paper       | 22.195 | Paper pack | 28.396 |\n",
      "| Metal         | 30.977 | Glass       | 27.830 | Plastic    | 18.970 |\n",
      "| Styrofoam     | 23.054 | Plastic bag | 48.757 | Battery    | 33.685 |\n",
      "| Clothing      | 17.231 |             |        |            |        |\n",
      "\u001b[32m[10/12 11:28:21 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_val_fold_0 in csv format:\n",
      "\u001b[32m[10/12 11:28:21 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/12 11:28:21 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/12 11:28:21 d2.evaluation.testing]: \u001b[0mcopypaste: 26.2272,37.3403,27.9505,0.1858,4.3068,31.0176\n",
      "\u001b[32m[10/12 11:28:21 d2.utils.events]: \u001b[0m eta: 0:34:01  iter: 2999  total_loss: 0.49  loss_cls: 0.2135  loss_box_reg: 0.1599  loss_rpn_cls: 0.01629  loss_rpn_loc: 0.03192    time: 1.0216  last_time: 1.0207  data_time: 0.0155  last_data_time: 0.0147   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:28:42 d2.utils.events]: \u001b[0m eta: 0:33:41  iter: 3019  total_loss: 0.3843  loss_cls: 0.2044  loss_box_reg: 0.165  loss_rpn_cls: 0.01366  loss_rpn_loc: 0.02731    time: 1.0216  last_time: 1.0153  data_time: 0.0157  last_data_time: 0.0161   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:29:02 d2.utils.events]: \u001b[0m eta: 0:33:20  iter: 3039  total_loss: 0.3704  loss_cls: 0.1829  loss_box_reg: 0.1434  loss_rpn_cls: 0.01301  loss_rpn_loc: 0.03028    time: 1.0216  last_time: 1.0211  data_time: 0.0156  last_data_time: 0.0166   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:29:22 d2.utils.events]: \u001b[0m eta: 0:33:00  iter: 3059  total_loss: 0.3815  loss_cls: 0.202  loss_box_reg: 0.1513  loss_rpn_cls: 0.01209  loss_rpn_loc: 0.02172    time: 1.0216  last_time: 1.0228  data_time: 0.0158  last_data_time: 0.0175   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:29:43 d2.utils.events]: \u001b[0m eta: 0:32:39  iter: 3079  total_loss: 0.4007  loss_cls: 0.194  loss_box_reg: 0.1713  loss_rpn_cls: 0.01835  loss_rpn_loc: 0.02453    time: 1.0216  last_time: 1.0189  data_time: 0.0167  last_data_time: 0.0151   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:30:03 d2.utils.events]: \u001b[0m eta: 0:32:19  iter: 3099  total_loss: 0.3595  loss_cls: 0.1999  loss_box_reg: 0.1264  loss_rpn_cls: 0.007634  loss_rpn_loc: 0.01807    time: 1.0216  last_time: 1.0248  data_time: 0.0160  last_data_time: 0.0168   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:30:24 d2.utils.events]: \u001b[0m eta: 0:31:59  iter: 3119  total_loss: 0.4326  loss_cls: 0.2127  loss_box_reg: 0.1695  loss_rpn_cls: 0.01574  loss_rpn_loc: 0.01743    time: 1.0216  last_time: 1.0233  data_time: 0.0160  last_data_time: 0.0151   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:30:44 d2.utils.events]: \u001b[0m eta: 0:31:38  iter: 3139  total_loss: 0.3706  loss_cls: 0.1758  loss_box_reg: 0.1311  loss_rpn_cls: 0.01533  loss_rpn_loc: 0.02686    time: 1.0216  last_time: 1.0150  data_time: 0.0159  last_data_time: 0.0149   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:31:05 d2.utils.events]: \u001b[0m eta: 0:31:18  iter: 3159  total_loss: 0.4214  loss_cls: 0.1857  loss_box_reg: 0.1271  loss_rpn_cls: 0.009073  loss_rpn_loc: 0.01396    time: 1.0216  last_time: 1.0192  data_time: 0.0157  last_data_time: 0.0167   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:31:25 d2.utils.events]: \u001b[0m eta: 0:30:57  iter: 3179  total_loss: 0.4877  loss_cls: 0.2222  loss_box_reg: 0.1808  loss_rpn_cls: 0.01634  loss_rpn_loc: 0.02958    time: 1.0215  last_time: 1.0234  data_time: 0.0157  last_data_time: 0.0172   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:31:45 d2.utils.events]: \u001b[0m eta: 0:30:37  iter: 3199  total_loss: 0.3514  loss_cls: 0.1723  loss_box_reg: 0.1292  loss_rpn_cls: 0.01063  loss_rpn_loc: 0.01375    time: 1.0216  last_time: 1.0300  data_time: 0.0182  last_data_time: 0.0156   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:32:06 d2.utils.events]: \u001b[0m eta: 0:30:16  iter: 3219  total_loss: 0.3142  loss_cls: 0.1639  loss_box_reg: 0.1097  loss_rpn_cls: 0.01008  loss_rpn_loc: 0.0141    time: 1.0216  last_time: 1.0270  data_time: 0.0162  last_data_time: 0.0145   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:32:26 d2.utils.events]: \u001b[0m eta: 0:29:56  iter: 3239  total_loss: 0.4057  loss_cls: 0.2145  loss_box_reg: 0.1456  loss_rpn_cls: 0.01722  loss_rpn_loc: 0.02289    time: 1.0216  last_time: 1.0192  data_time: 0.0160  last_data_time: 0.0150   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:32:47 d2.utils.events]: \u001b[0m eta: 0:29:35  iter: 3259  total_loss: 0.387  loss_cls: 0.1923  loss_box_reg: 0.1622  loss_rpn_cls: 0.01181  loss_rpn_loc: 0.01983    time: 1.0216  last_time: 1.0243  data_time: 0.0164  last_data_time: 0.0187   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:33:07 d2.utils.events]: \u001b[0m eta: 0:29:15  iter: 3279  total_loss: 0.4729  loss_cls: 0.2032  loss_box_reg: 0.182  loss_rpn_cls: 0.01456  loss_rpn_loc: 0.02616    time: 1.0216  last_time: 1.0266  data_time: 0.0161  last_data_time: 0.0155   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:33:28 d2.utils.events]: \u001b[0m eta: 0:28:54  iter: 3299  total_loss: 0.2621  loss_cls: 0.1552  loss_box_reg: 0.07336  loss_rpn_cls: 0.01217  loss_rpn_loc: 0.009464    time: 1.0216  last_time: 1.0186  data_time: 0.0167  last_data_time: 0.0154   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:33:48 d2.utils.events]: \u001b[0m eta: 0:28:34  iter: 3319  total_loss: 0.3468  loss_cls: 0.1847  loss_box_reg: 0.1202  loss_rpn_cls: 0.01728  loss_rpn_loc: 0.021    time: 1.0216  last_time: 1.0188  data_time: 0.0158  last_data_time: 0.0159   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:34:09 d2.utils.events]: \u001b[0m eta: 0:28:14  iter: 3339  total_loss: 0.3422  loss_cls: 0.1813  loss_box_reg: 0.1321  loss_rpn_cls: 0.01147  loss_rpn_loc: 0.02024    time: 1.0216  last_time: 1.0198  data_time: 0.0156  last_data_time: 0.0170   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:34:29 d2.utils.events]: \u001b[0m eta: 0:27:53  iter: 3359  total_loss: 0.4718  loss_cls: 0.2235  loss_box_reg: 0.1978  loss_rpn_cls: 0.01987  loss_rpn_loc: 0.02671    time: 1.0216  last_time: 1.0195  data_time: 0.0160  last_data_time: 0.0156   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:34:49 d2.utils.events]: \u001b[0m eta: 0:27:33  iter: 3379  total_loss: 0.3611  loss_cls: 0.1573  loss_box_reg: 0.1427  loss_rpn_cls: 0.009074  loss_rpn_loc: 0.02114    time: 1.0216  last_time: 1.0205  data_time: 0.0163  last_data_time: 0.0155   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:35:10 d2.utils.events]: \u001b[0m eta: 0:27:12  iter: 3399  total_loss: 0.3244  loss_cls: 0.1564  loss_box_reg: 0.1245  loss_rpn_cls: 0.0103  loss_rpn_loc: 0.02185    time: 1.0216  last_time: 1.0169  data_time: 0.0171  last_data_time: 0.0140   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:35:30 d2.utils.events]: \u001b[0m eta: 0:26:52  iter: 3419  total_loss: 0.2752  loss_cls: 0.1348  loss_box_reg: 0.11  loss_rpn_cls: 0.006598  loss_rpn_loc: 0.01023    time: 1.0216  last_time: 1.0163  data_time: 0.0153  last_data_time: 0.0158   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:35:51 d2.utils.events]: \u001b[0m eta: 0:26:32  iter: 3439  total_loss: 0.3731  loss_cls: 0.1901  loss_box_reg: 0.1226  loss_rpn_cls: 0.01088  loss_rpn_loc: 0.02002    time: 1.0216  last_time: 1.0294  data_time: 0.0161  last_data_time: 0.0165   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:36:11 d2.utils.events]: \u001b[0m eta: 0:26:11  iter: 3459  total_loss: 0.4258  loss_cls: 0.2266  loss_box_reg: 0.1646  loss_rpn_cls: 0.01677  loss_rpn_loc: 0.02457    time: 1.0216  last_time: 1.0224  data_time: 0.0164  last_data_time: 0.0150   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:36:32 d2.utils.events]: \u001b[0m eta: 0:25:51  iter: 3479  total_loss: 0.3969  loss_cls: 0.1949  loss_box_reg: 0.1386  loss_rpn_cls: 0.01795  loss_rpn_loc: 0.02307    time: 1.0216  last_time: 1.0207  data_time: 0.0163  last_data_time: 0.0145   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:36:52 d2.data.datasets.coco]: \u001b[0mLoaded 977 images in COCO format from /data/ephemeral/home/Lv2.Object_Detection/dataset/val_fold_0.json\n",
      "\u001b[32m[10/12 11:36:52 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/12 11:36:52 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/12 11:36:52 d2.data.common]: \u001b[0mSerializing 977 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 11:36:52 d2.data.common]: \u001b[0mSerialized dataset takes 0.49 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/12 11:36:52 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/12 11:36:52 d2.evaluation.evaluator]: \u001b[0mStart inference on 977 batches\n",
      "\u001b[32m[10/12 11:36:53 d2.evaluation.evaluator]: \u001b[0mInference done 11/977. Dataloading: 0.0012 s/iter. Inference: 0.0683 s/iter. Eval: 0.0003 s/iter. Total: 0.0699 s/iter. ETA=0:01:07\n",
      "\u001b[32m[10/12 11:36:58 d2.evaluation.evaluator]: \u001b[0mInference done 83/977. Dataloading: 0.0013 s/iter. Inference: 0.0679 s/iter. Eval: 0.0003 s/iter. Total: 0.0695 s/iter. ETA=0:01:02\n",
      "\u001b[32m[10/12 11:37:03 d2.evaluation.evaluator]: \u001b[0mInference done 154/977. Dataloading: 0.0013 s/iter. Inference: 0.0683 s/iter. Eval: 0.0003 s/iter. Total: 0.0700 s/iter. ETA=0:00:57\n",
      "\u001b[32m[10/12 11:37:08 d2.evaluation.evaluator]: \u001b[0mInference done 225/977. Dataloading: 0.0014 s/iter. Inference: 0.0685 s/iter. Eval: 0.0003 s/iter. Total: 0.0702 s/iter. ETA=0:00:52\n",
      "\u001b[32m[10/12 11:37:13 d2.evaluation.evaluator]: \u001b[0mInference done 298/977. Dataloading: 0.0013 s/iter. Inference: 0.0683 s/iter. Eval: 0.0003 s/iter. Total: 0.0700 s/iter. ETA=0:00:47\n",
      "\u001b[32m[10/12 11:37:18 d2.evaluation.evaluator]: \u001b[0mInference done 372/977. Dataloading: 0.0013 s/iter. Inference: 0.0680 s/iter. Eval: 0.0003 s/iter. Total: 0.0696 s/iter. ETA=0:00:42\n",
      "\u001b[32m[10/12 11:37:23 d2.evaluation.evaluator]: \u001b[0mInference done 446/977. Dataloading: 0.0013 s/iter. Inference: 0.0679 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:00:36\n",
      "\u001b[32m[10/12 11:37:28 d2.evaluation.evaluator]: \u001b[0mInference done 518/977. Dataloading: 0.0013 s/iter. Inference: 0.0679 s/iter. Eval: 0.0002 s/iter. Total: 0.0695 s/iter. ETA=0:00:31\n",
      "\u001b[32m[10/12 11:37:34 d2.evaluation.evaluator]: \u001b[0mInference done 592/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0002 s/iter. Total: 0.0694 s/iter. ETA=0:00:26\n",
      "\u001b[32m[10/12 11:37:39 d2.evaluation.evaluator]: \u001b[0mInference done 664/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0002 s/iter. Total: 0.0694 s/iter. ETA=0:00:21\n",
      "\u001b[32m[10/12 11:37:44 d2.evaluation.evaluator]: \u001b[0mInference done 736/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0002 s/iter. Total: 0.0694 s/iter. ETA=0:00:16\n",
      "\u001b[32m[10/12 11:37:49 d2.evaluation.evaluator]: \u001b[0mInference done 809/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0002 s/iter. Total: 0.0694 s/iter. ETA=0:00:11\n",
      "\u001b[32m[10/12 11:37:54 d2.evaluation.evaluator]: \u001b[0mInference done 882/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0002 s/iter. Total: 0.0694 s/iter. ETA=0:00:06\n",
      "\u001b[32m[10/12 11:37:59 d2.evaluation.evaluator]: \u001b[0mInference done 954/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0002 s/iter. Total: 0.0694 s/iter. ETA=0:00:01\n",
      "\u001b[32m[10/12 11:38:00 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:07.518305 (0.069463 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 11:38:00 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:05 (0.067786 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 11:38:01 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/12 11:38:01 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/12 11:38:01 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/12 11:38:01 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/12 11:38:01 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.44 seconds.\n",
      "\u001b[32m[10/12 11:38:01 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/12 11:38:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.376\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.281\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.312\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.265\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.483\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.015\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588\n",
      "\u001b[32m[10/12 11:38:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 26.408 | 37.571 | 28.126 | 0.183 | 4.452 | 31.211 |\n",
      "\u001b[32m[10/12 11:38:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 10.973 | Paper       | 22.458 | Paper pack | 28.356 |\n",
      "| Metal         | 31.534 | Glass       | 28.215 | Plastic    | 18.935 |\n",
      "| Styrofoam     | 23.653 | Plastic bag | 49.090 | Battery    | 33.341 |\n",
      "| Clothing      | 17.527 |             |        |            |        |\n",
      "\u001b[32m[10/12 11:38:02 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_val_fold_0 in csv format:\n",
      "\u001b[32m[10/12 11:38:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/12 11:38:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/12 11:38:02 d2.evaluation.testing]: \u001b[0mcopypaste: 26.4082,37.5706,28.1258,0.1832,4.4519,31.2112\n",
      "\u001b[32m[10/12 11:38:02 d2.utils.events]: \u001b[0m eta: 0:25:30  iter: 3499  total_loss: 0.3489  loss_cls: 0.1741  loss_box_reg: 0.1279  loss_rpn_cls: 0.0114  loss_rpn_loc: 0.0162    time: 1.0216  last_time: 1.0219  data_time: 0.0167  last_data_time: 0.0159   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:38:22 d2.utils.events]: \u001b[0m eta: 0:25:10  iter: 3519  total_loss: 0.3385  loss_cls: 0.2102  loss_box_reg: 0.1213  loss_rpn_cls: 0.01502  loss_rpn_loc: 0.01675    time: 1.0216  last_time: 1.0171  data_time: 0.0162  last_data_time: 0.0146   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:38:42 d2.utils.events]: \u001b[0m eta: 0:24:50  iter: 3539  total_loss: 0.5374  loss_cls: 0.2482  loss_box_reg: 0.2072  loss_rpn_cls: 0.01997  loss_rpn_loc: 0.02692    time: 1.0215  last_time: 1.0242  data_time: 0.0157  last_data_time: 0.0142   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:39:03 d2.utils.events]: \u001b[0m eta: 0:24:29  iter: 3559  total_loss: 0.5402  loss_cls: 0.2212  loss_box_reg: 0.1944  loss_rpn_cls: 0.02406  loss_rpn_loc: 0.03919    time: 1.0215  last_time: 1.0284  data_time: 0.0160  last_data_time: 0.0170   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:39:23 d2.utils.events]: \u001b[0m eta: 0:24:09  iter: 3579  total_loss: 0.4256  loss_cls: 0.227  loss_box_reg: 0.1483  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.02787    time: 1.0215  last_time: 1.0190  data_time: 0.0160  last_data_time: 0.0148   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:39:44 d2.utils.events]: \u001b[0m eta: 0:23:48  iter: 3599  total_loss: 0.3972  loss_cls: 0.2006  loss_box_reg: 0.1559  loss_rpn_cls: 0.01452  loss_rpn_loc: 0.03912    time: 1.0215  last_time: 1.0227  data_time: 0.0164  last_data_time: 0.0163   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:40:04 d2.utils.events]: \u001b[0m eta: 0:23:28  iter: 3619  total_loss: 0.4074  loss_cls: 0.2043  loss_box_reg: 0.1495  loss_rpn_cls: 0.01578  loss_rpn_loc: 0.0181    time: 1.0215  last_time: 1.0193  data_time: 0.0164  last_data_time: 0.0174   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:40:25 d2.utils.events]: \u001b[0m eta: 0:23:07  iter: 3639  total_loss: 0.3535  loss_cls: 0.1794  loss_box_reg: 0.1166  loss_rpn_cls: 0.01128  loss_rpn_loc: 0.0195    time: 1.0215  last_time: 1.0257  data_time: 0.0168  last_data_time: 0.0208   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:40:45 d2.utils.events]: \u001b[0m eta: 0:22:47  iter: 3659  total_loss: 0.3997  loss_cls: 0.2224  loss_box_reg: 0.1502  loss_rpn_cls: 0.01625  loss_rpn_loc: 0.02652    time: 1.0215  last_time: 1.0202  data_time: 0.0167  last_data_time: 0.0163   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:41:05 d2.utils.events]: \u001b[0m eta: 0:22:26  iter: 3679  total_loss: 0.3462  loss_cls: 0.1972  loss_box_reg: 0.1232  loss_rpn_cls: 0.01344  loss_rpn_loc: 0.01795    time: 1.0215  last_time: 1.0194  data_time: 0.0166  last_data_time: 0.0157   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:41:26 d2.utils.events]: \u001b[0m eta: 0:22:06  iter: 3699  total_loss: 0.3623  loss_cls: 0.1544  loss_box_reg: 0.1328  loss_rpn_cls: 0.01392  loss_rpn_loc: 0.02306    time: 1.0215  last_time: 1.0286  data_time: 0.0170  last_data_time: 0.0161   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:41:46 d2.utils.events]: \u001b[0m eta: 0:21:46  iter: 3719  total_loss: 0.2904  loss_cls: 0.1517  loss_box_reg: 0.1138  loss_rpn_cls: 0.01281  loss_rpn_loc: 0.01425    time: 1.0215  last_time: 1.0232  data_time: 0.0159  last_data_time: 0.0184   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:42:07 d2.utils.events]: \u001b[0m eta: 0:21:25  iter: 3739  total_loss: 0.3137  loss_cls: 0.1809  loss_box_reg: 0.1149  loss_rpn_cls: 0.01446  loss_rpn_loc: 0.03115    time: 1.0215  last_time: 1.0206  data_time: 0.0154  last_data_time: 0.0166   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:42:27 d2.utils.events]: \u001b[0m eta: 0:21:05  iter: 3759  total_loss: 0.4819  loss_cls: 0.2362  loss_box_reg: 0.1732  loss_rpn_cls: 0.01358  loss_rpn_loc: 0.03527    time: 1.0215  last_time: 1.0191  data_time: 0.0162  last_data_time: 0.0146   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:42:48 d2.utils.events]: \u001b[0m eta: 0:20:44  iter: 3779  total_loss: 0.3989  loss_cls: 0.191  loss_box_reg: 0.1412  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.0222    time: 1.0215  last_time: 1.0164  data_time: 0.0157  last_data_time: 0.0145   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:43:08 d2.utils.events]: \u001b[0m eta: 0:20:24  iter: 3799  total_loss: 0.3639  loss_cls: 0.198  loss_box_reg: 0.1372  loss_rpn_cls: 0.01512  loss_rpn_loc: 0.01959    time: 1.0215  last_time: 1.0191  data_time: 0.0161  last_data_time: 0.0149   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:43:28 d2.utils.events]: \u001b[0m eta: 0:20:04  iter: 3819  total_loss: 0.3175  loss_cls: 0.1524  loss_box_reg: 0.1198  loss_rpn_cls: 0.01299  loss_rpn_loc: 0.01823    time: 1.0215  last_time: 1.0163  data_time: 0.0165  last_data_time: 0.0149   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:43:49 d2.utils.events]: \u001b[0m eta: 0:19:43  iter: 3839  total_loss: 0.3612  loss_cls: 0.175  loss_box_reg: 0.1518  loss_rpn_cls: 0.009115  loss_rpn_loc: 0.02151    time: 1.0215  last_time: 1.0198  data_time: 0.0172  last_data_time: 0.0175   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:44:09 d2.utils.events]: \u001b[0m eta: 0:19:23  iter: 3859  total_loss: 0.3909  loss_cls: 0.1966  loss_box_reg: 0.148  loss_rpn_cls: 0.01439  loss_rpn_loc: 0.02755    time: 1.0215  last_time: 1.0171  data_time: 0.0160  last_data_time: 0.0161   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:44:30 d2.utils.events]: \u001b[0m eta: 0:19:02  iter: 3879  total_loss: 0.4591  loss_cls: 0.2406  loss_box_reg: 0.1683  loss_rpn_cls: 0.01738  loss_rpn_loc: 0.03135    time: 1.0215  last_time: 1.0195  data_time: 0.0165  last_data_time: 0.0160   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:44:50 d2.utils.events]: \u001b[0m eta: 0:18:42  iter: 3899  total_loss: 0.3622  loss_cls: 0.1648  loss_box_reg: 0.1683  loss_rpn_cls: 0.01065  loss_rpn_loc: 0.01705    time: 1.0215  last_time: 1.0171  data_time: 0.0158  last_data_time: 0.0148   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:45:10 d2.utils.events]: \u001b[0m eta: 0:18:21  iter: 3919  total_loss: 0.4011  loss_cls: 0.1988  loss_box_reg: 0.1486  loss_rpn_cls: 0.01568  loss_rpn_loc: 0.02643    time: 1.0215  last_time: 1.0205  data_time: 0.0165  last_data_time: 0.0169   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:45:31 d2.utils.events]: \u001b[0m eta: 0:18:01  iter: 3939  total_loss: 0.3453  loss_cls: 0.1678  loss_box_reg: 0.1322  loss_rpn_cls: 0.013  loss_rpn_loc: 0.01429    time: 1.0215  last_time: 1.0163  data_time: 0.0163  last_data_time: 0.0150   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:45:51 d2.utils.events]: \u001b[0m eta: 0:17:40  iter: 3959  total_loss: 0.3257  loss_cls: 0.1671  loss_box_reg: 0.1289  loss_rpn_cls: 0.01597  loss_rpn_loc: 0.02677    time: 1.0215  last_time: 1.0185  data_time: 0.0162  last_data_time: 0.0159   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:46:12 d2.utils.events]: \u001b[0m eta: 0:17:20  iter: 3979  total_loss: 0.3784  loss_cls: 0.1806  loss_box_reg: 0.1687  loss_rpn_cls: 0.00896  loss_rpn_loc: 0.02799    time: 1.0214  last_time: 1.0198  data_time: 0.0164  last_data_time: 0.0150   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:46:34 d2.data.datasets.coco]: \u001b[0mLoaded 977 images in COCO format from /data/ephemeral/home/Lv2.Object_Detection/dataset/val_fold_0.json\n",
      "\u001b[32m[10/12 11:46:34 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/12 11:46:34 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/12 11:46:34 d2.data.common]: \u001b[0mSerializing 977 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 11:46:34 d2.data.common]: \u001b[0mSerialized dataset takes 0.49 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/12 11:46:34 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/12 11:46:34 d2.evaluation.evaluator]: \u001b[0mStart inference on 977 batches\n",
      "\u001b[32m[10/12 11:46:35 d2.evaluation.evaluator]: \u001b[0mInference done 11/977. Dataloading: 0.0011 s/iter. Inference: 0.0671 s/iter. Eval: 0.0003 s/iter. Total: 0.0685 s/iter. ETA=0:01:06\n",
      "\u001b[32m[10/12 11:46:40 d2.evaluation.evaluator]: \u001b[0mInference done 84/977. Dataloading: 0.0014 s/iter. Inference: 0.0673 s/iter. Eval: 0.0003 s/iter. Total: 0.0690 s/iter. ETA=0:01:01\n",
      "\u001b[32m[10/12 11:46:45 d2.evaluation.evaluator]: \u001b[0mInference done 157/977. Dataloading: 0.0013 s/iter. Inference: 0.0675 s/iter. Eval: 0.0003 s/iter. Total: 0.0691 s/iter. ETA=0:00:56\n",
      "\u001b[32m[10/12 11:46:50 d2.evaluation.evaluator]: \u001b[0mInference done 228/977. Dataloading: 0.0013 s/iter. Inference: 0.0681 s/iter. Eval: 0.0002 s/iter. Total: 0.0697 s/iter. ETA=0:00:52\n",
      "\u001b[32m[10/12 11:46:55 d2.evaluation.evaluator]: \u001b[0mInference done 300/977. Dataloading: 0.0013 s/iter. Inference: 0.0680 s/iter. Eval: 0.0003 s/iter. Total: 0.0697 s/iter. ETA=0:00:47\n",
      "\u001b[32m[10/12 11:47:00 d2.evaluation.evaluator]: \u001b[0mInference done 374/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:00:41\n",
      "\u001b[32m[10/12 11:47:05 d2.evaluation.evaluator]: \u001b[0mInference done 447/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:00:36\n",
      "\u001b[32m[10/12 11:47:10 d2.evaluation.evaluator]: \u001b[0mInference done 520/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0002 s/iter. Total: 0.0693 s/iter. ETA=0:00:31\n",
      "\u001b[32m[10/12 11:47:15 d2.evaluation.evaluator]: \u001b[0mInference done 593/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0002 s/iter. Total: 0.0693 s/iter. ETA=0:00:26\n",
      "\u001b[32m[10/12 11:47:20 d2.evaluation.evaluator]: \u001b[0mInference done 663/977. Dataloading: 0.0013 s/iter. Inference: 0.0679 s/iter. Eval: 0.0003 s/iter. Total: 0.0695 s/iter. ETA=0:00:21\n",
      "\u001b[32m[10/12 11:47:25 d2.evaluation.evaluator]: \u001b[0mInference done 736/977. Dataloading: 0.0013 s/iter. Inference: 0.0679 s/iter. Eval: 0.0003 s/iter. Total: 0.0695 s/iter. ETA=0:00:16\n",
      "\u001b[32m[10/12 11:47:30 d2.evaluation.evaluator]: \u001b[0mInference done 809/977. Dataloading: 0.0013 s/iter. Inference: 0.0679 s/iter. Eval: 0.0002 s/iter. Total: 0.0695 s/iter. ETA=0:00:11\n",
      "\u001b[32m[10/12 11:47:35 d2.evaluation.evaluator]: \u001b[0mInference done 882/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0003 s/iter. Total: 0.0695 s/iter. ETA=0:00:06\n",
      "\u001b[32m[10/12 11:47:40 d2.evaluation.evaluator]: \u001b[0mInference done 955/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:00:01\n",
      "\u001b[32m[10/12 11:47:42 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:07.582452 (0.069529 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 11:47:42 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:05 (0.067823 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 11:47:42 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/12 11:47:42 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/12 11:47:42 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/12 11:47:43 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/12 11:47:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.43 seconds.\n",
      "\u001b[32m[10/12 11:47:43 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/12 11:47:43 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.378\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.484\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588\n",
      "\u001b[32m[10/12 11:47:43 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 26.586 | 37.775 | 28.242 | 0.165 | 4.418 | 31.429 |\n",
      "\u001b[32m[10/12 11:47:43 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 10.935 | Paper       | 22.528 | Paper pack | 28.706 |\n",
      "| Metal         | 31.803 | Glass       | 28.435 | Plastic    | 19.013 |\n",
      "| Styrofoam     | 23.753 | Plastic bag | 49.421 | Battery    | 33.642 |\n",
      "| Clothing      | 17.627 |             |        |            |        |\n",
      "\u001b[32m[10/12 11:47:43 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_val_fold_0 in csv format:\n",
      "\u001b[32m[10/12 11:47:43 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/12 11:47:43 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/12 11:47:43 d2.evaluation.testing]: \u001b[0mcopypaste: 26.5864,37.7753,28.2423,0.1650,4.4184,31.4292\n",
      "\u001b[32m[10/12 11:47:43 d2.utils.events]: \u001b[0m eta: 0:16:59  iter: 3999  total_loss: 0.3882  loss_cls: 0.1852  loss_box_reg: 0.1447  loss_rpn_cls: 0.01504  loss_rpn_loc: 0.02641    time: 1.0214  last_time: 1.0200  data_time: 0.0154  last_data_time: 0.0142   lr: 5e-06  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:48:04 d2.utils.events]: \u001b[0m eta: 0:16:39  iter: 4019  total_loss: 0.3927  loss_cls: 0.194  loss_box_reg: 0.1294  loss_rpn_cls: 0.01358  loss_rpn_loc: 0.02146    time: 1.0214  last_time: 1.0253  data_time: 0.0160  last_data_time: 0.0203   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:48:24 d2.utils.events]: \u001b[0m eta: 0:16:19  iter: 4039  total_loss: 0.4117  loss_cls: 0.1934  loss_box_reg: 0.1572  loss_rpn_cls: 0.01443  loss_rpn_loc: 0.03183    time: 1.0214  last_time: 1.0239  data_time: 0.0162  last_data_time: 0.0179   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:48:44 d2.utils.events]: \u001b[0m eta: 0:15:58  iter: 4059  total_loss: 0.4281  loss_cls: 0.2221  loss_box_reg: 0.1765  loss_rpn_cls: 0.01887  loss_rpn_loc: 0.01961    time: 1.0214  last_time: 1.0317  data_time: 0.0164  last_data_time: 0.0150   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:49:05 d2.utils.events]: \u001b[0m eta: 0:15:38  iter: 4079  total_loss: 0.342  loss_cls: 0.1766  loss_box_reg: 0.1234  loss_rpn_cls: 0.01379  loss_rpn_loc: 0.01555    time: 1.0214  last_time: 1.0196  data_time: 0.0155  last_data_time: 0.0153   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:49:25 d2.utils.events]: \u001b[0m eta: 0:15:18  iter: 4099  total_loss: 0.353  loss_cls: 0.1725  loss_box_reg: 0.1442  loss_rpn_cls: 0.01371  loss_rpn_loc: 0.01962    time: 1.0214  last_time: 1.0251  data_time: 0.0162  last_data_time: 0.0217   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:49:46 d2.utils.events]: \u001b[0m eta: 0:14:57  iter: 4119  total_loss: 0.3866  loss_cls: 0.1985  loss_box_reg: 0.1288  loss_rpn_cls: 0.01919  loss_rpn_loc: 0.01998    time: 1.0214  last_time: 1.0182  data_time: 0.0173  last_data_time: 0.0156   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:50:06 d2.utils.events]: \u001b[0m eta: 0:14:37  iter: 4139  total_loss: 0.3837  loss_cls: 0.1957  loss_box_reg: 0.1486  loss_rpn_cls: 0.01313  loss_rpn_loc: 0.01626    time: 1.0214  last_time: 1.0167  data_time: 0.0164  last_data_time: 0.0140   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:50:27 d2.utils.events]: \u001b[0m eta: 0:14:16  iter: 4159  total_loss: 0.3519  loss_cls: 0.1654  loss_box_reg: 0.1258  loss_rpn_cls: 0.01383  loss_rpn_loc: 0.02311    time: 1.0214  last_time: 1.0221  data_time: 0.0170  last_data_time: 0.0170   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:50:47 d2.utils.events]: \u001b[0m eta: 0:13:56  iter: 4179  total_loss: 0.3108  loss_cls: 0.1542  loss_box_reg: 0.1169  loss_rpn_cls: 0.009039  loss_rpn_loc: 0.01606    time: 1.0214  last_time: 1.0191  data_time: 0.0160  last_data_time: 0.0150   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:51:07 d2.utils.events]: \u001b[0m eta: 0:13:36  iter: 4199  total_loss: 0.3734  loss_cls: 0.1797  loss_box_reg: 0.1488  loss_rpn_cls: 0.01073  loss_rpn_loc: 0.01797    time: 1.0214  last_time: 1.0207  data_time: 0.0160  last_data_time: 0.0159   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:51:28 d2.utils.events]: \u001b[0m eta: 0:13:15  iter: 4219  total_loss: 0.3447  loss_cls: 0.1731  loss_box_reg: 0.1356  loss_rpn_cls: 0.0187  loss_rpn_loc: 0.02217    time: 1.0214  last_time: 1.0215  data_time: 0.0168  last_data_time: 0.0167   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:51:48 d2.utils.events]: \u001b[0m eta: 0:12:55  iter: 4239  total_loss: 0.3858  loss_cls: 0.2013  loss_box_reg: 0.1653  loss_rpn_cls: 0.01125  loss_rpn_loc: 0.02591    time: 1.0214  last_time: 1.0208  data_time: 0.0164  last_data_time: 0.0162   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:52:09 d2.utils.events]: \u001b[0m eta: 0:12:34  iter: 4259  total_loss: 0.4633  loss_cls: 0.2534  loss_box_reg: 0.1804  loss_rpn_cls: 0.01591  loss_rpn_loc: 0.02223    time: 1.0214  last_time: 1.0183  data_time: 0.0159  last_data_time: 0.0157   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:52:29 d2.utils.events]: \u001b[0m eta: 0:12:14  iter: 4279  total_loss: 0.4005  loss_cls: 0.1854  loss_box_reg: 0.1437  loss_rpn_cls: 0.01259  loss_rpn_loc: 0.01756    time: 1.0214  last_time: 1.0192  data_time: 0.0177  last_data_time: 0.0163   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:52:50 d2.utils.events]: \u001b[0m eta: 0:11:53  iter: 4299  total_loss: 0.351  loss_cls: 0.1829  loss_box_reg: 0.1307  loss_rpn_cls: 0.01582  loss_rpn_loc: 0.02073    time: 1.0214  last_time: 1.0197  data_time: 0.0165  last_data_time: 0.0162   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:53:10 d2.utils.events]: \u001b[0m eta: 0:11:33  iter: 4319  total_loss: 0.4297  loss_cls: 0.2088  loss_box_reg: 0.158  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.02225    time: 1.0214  last_time: 1.0246  data_time: 0.0176  last_data_time: 0.0223   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:53:30 d2.utils.events]: \u001b[0m eta: 0:11:13  iter: 4339  total_loss: 0.4031  loss_cls: 0.2051  loss_box_reg: 0.1671  loss_rpn_cls: 0.01269  loss_rpn_loc: 0.01944    time: 1.0214  last_time: 1.0164  data_time: 0.0160  last_data_time: 0.0153   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:53:51 d2.utils.events]: \u001b[0m eta: 0:10:52  iter: 4359  total_loss: 0.4309  loss_cls: 0.2068  loss_box_reg: 0.163  loss_rpn_cls: 0.0217  loss_rpn_loc: 0.0237    time: 1.0214  last_time: 1.0236  data_time: 0.0165  last_data_time: 0.0161   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:54:11 d2.utils.events]: \u001b[0m eta: 0:10:32  iter: 4379  total_loss: 0.4232  loss_cls: 0.2152  loss_box_reg: 0.1492  loss_rpn_cls: 0.01602  loss_rpn_loc: 0.02904    time: 1.0214  last_time: 1.0286  data_time: 0.0163  last_data_time: 0.0149   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:54:32 d2.utils.events]: \u001b[0m eta: 0:10:12  iter: 4399  total_loss: 0.4231  loss_cls: 0.2276  loss_box_reg: 0.1437  loss_rpn_cls: 0.01788  loss_rpn_loc: 0.03373    time: 1.0214  last_time: 1.0216  data_time: 0.0159  last_data_time: 0.0157   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:54:52 d2.utils.events]: \u001b[0m eta: 0:09:51  iter: 4419  total_loss: 0.4801  loss_cls: 0.2258  loss_box_reg: 0.1754  loss_rpn_cls: 0.01844  loss_rpn_loc: 0.03977    time: 1.0214  last_time: 1.0316  data_time: 0.0180  last_data_time: 0.0175   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:55:13 d2.utils.events]: \u001b[0m eta: 0:09:31  iter: 4439  total_loss: 0.332  loss_cls: 0.1821  loss_box_reg: 0.1311  loss_rpn_cls: 0.01533  loss_rpn_loc: 0.02601    time: 1.0214  last_time: 1.0212  data_time: 0.0161  last_data_time: 0.0167   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:55:33 d2.utils.events]: \u001b[0m eta: 0:09:10  iter: 4459  total_loss: 0.4334  loss_cls: 0.2188  loss_box_reg: 0.1623  loss_rpn_cls: 0.01394  loss_rpn_loc: 0.03707    time: 1.0214  last_time: 1.0246  data_time: 0.0178  last_data_time: 0.0182   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:55:54 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 4479  total_loss: 0.397  loss_cls: 0.1852  loss_box_reg: 0.1247  loss_rpn_cls: 0.01619  loss_rpn_loc: 0.02258    time: 1.0214  last_time: 1.0215  data_time: 0.0160  last_data_time: 0.0159   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:56:14 d2.data.datasets.coco]: \u001b[0mLoaded 977 images in COCO format from /data/ephemeral/home/Lv2.Object_Detection/dataset/val_fold_0.json\n",
      "\u001b[32m[10/12 11:56:14 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/12 11:56:14 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/12 11:56:14 d2.data.common]: \u001b[0mSerializing 977 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 11:56:14 d2.data.common]: \u001b[0mSerialized dataset takes 0.49 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/12 11:56:14 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/12 11:56:14 d2.evaluation.evaluator]: \u001b[0mStart inference on 977 batches\n",
      "\u001b[32m[10/12 11:56:15 d2.evaluation.evaluator]: \u001b[0mInference done 11/977. Dataloading: 0.0011 s/iter. Inference: 0.0693 s/iter. Eval: 0.0003 s/iter. Total: 0.0707 s/iter. ETA=0:01:08\n",
      "\u001b[32m[10/12 11:56:20 d2.evaluation.evaluator]: \u001b[0mInference done 84/977. Dataloading: 0.0014 s/iter. Inference: 0.0677 s/iter. Eval: 0.0003 s/iter. Total: 0.0695 s/iter. ETA=0:01:02\n",
      "\u001b[32m[10/12 11:56:25 d2.evaluation.evaluator]: \u001b[0mInference done 157/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:00:56\n",
      "\u001b[32m[10/12 11:56:30 d2.evaluation.evaluator]: \u001b[0mInference done 228/977. Dataloading: 0.0013 s/iter. Inference: 0.0681 s/iter. Eval: 0.0003 s/iter. Total: 0.0697 s/iter. ETA=0:00:52\n",
      "\u001b[32m[10/12 11:56:35 d2.evaluation.evaluator]: \u001b[0mInference done 300/977. Dataloading: 0.0013 s/iter. Inference: 0.0681 s/iter. Eval: 0.0003 s/iter. Total: 0.0698 s/iter. ETA=0:00:47\n",
      "\u001b[32m[10/12 11:56:40 d2.evaluation.evaluator]: \u001b[0mInference done 373/977. Dataloading: 0.0013 s/iter. Inference: 0.0680 s/iter. Eval: 0.0003 s/iter. Total: 0.0696 s/iter. ETA=0:00:42\n",
      "\u001b[32m[10/12 11:56:45 d2.evaluation.evaluator]: \u001b[0mInference done 446/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:00:36\n",
      "\u001b[32m[10/12 11:56:50 d2.evaluation.evaluator]: \u001b[0mInference done 519/977. Dataloading: 0.0012 s/iter. Inference: 0.0677 s/iter. Eval: 0.0003 s/iter. Total: 0.0693 s/iter. ETA=0:00:31\n",
      "\u001b[32m[10/12 11:56:55 d2.evaluation.evaluator]: \u001b[0mInference done 590/977. Dataloading: 0.0013 s/iter. Inference: 0.0679 s/iter. Eval: 0.0003 s/iter. Total: 0.0695 s/iter. ETA=0:00:26\n",
      "\u001b[32m[10/12 11:57:01 d2.evaluation.evaluator]: \u001b[0mInference done 663/977. Dataloading: 0.0013 s/iter. Inference: 0.0679 s/iter. Eval: 0.0003 s/iter. Total: 0.0695 s/iter. ETA=0:00:21\n",
      "\u001b[32m[10/12 11:57:06 d2.evaluation.evaluator]: \u001b[0mInference done 736/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:00:16\n",
      "\u001b[32m[10/12 11:57:11 d2.evaluation.evaluator]: \u001b[0mInference done 809/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0003 s/iter. Total: 0.0693 s/iter. ETA=0:00:11\n",
      "\u001b[32m[10/12 11:57:16 d2.evaluation.evaluator]: \u001b[0mInference done 881/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0003 s/iter. Total: 0.0693 s/iter. ETA=0:00:06\n",
      "\u001b[32m[10/12 11:57:21 d2.evaluation.evaluator]: \u001b[0mInference done 955/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0002 s/iter. Total: 0.0692 s/iter. ETA=0:00:01\n",
      "\u001b[32m[10/12 11:57:22 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:07.601335 (0.069549 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 11:57:22 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:05 (0.067623 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 11:57:23 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/12 11:57:23 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/12 11:57:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/12 11:57:23 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/12 11:57:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.44 seconds.\n",
      "\u001b[32m[10/12 11:57:23 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/12 11:57:23 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.378\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.484\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588\n",
      "\u001b[32m[10/12 11:57:23 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 26.586 | 37.775 | 28.242 | 0.165 | 4.418 | 31.429 |\n",
      "\u001b[32m[10/12 11:57:23 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 10.935 | Paper       | 22.528 | Paper pack | 28.706 |\n",
      "| Metal         | 31.804 | Glass       | 28.435 | Plastic    | 19.013 |\n",
      "| Styrofoam     | 23.753 | Plastic bag | 49.421 | Battery    | 33.641 |\n",
      "| Clothing      | 17.627 |             |        |            |        |\n",
      "\u001b[32m[10/12 11:57:24 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_val_fold_0 in csv format:\n",
      "\u001b[32m[10/12 11:57:24 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/12 11:57:24 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/12 11:57:24 d2.evaluation.testing]: \u001b[0mcopypaste: 26.5863,37.7753,28.2423,0.1650,4.4184,31.4291\n",
      "\u001b[32m[10/12 11:57:24 d2.utils.events]: \u001b[0m eta: 0:08:30  iter: 4499  total_loss: 0.3469  loss_cls: 0.1847  loss_box_reg: 0.1179  loss_rpn_cls: 0.01222  loss_rpn_loc: 0.01235    time: 1.0214  last_time: 1.0202  data_time: 0.0169  last_data_time: 0.0150   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:57:44 d2.utils.events]: \u001b[0m eta: 0:08:09  iter: 4519  total_loss: 0.3867  loss_cls: 0.1825  loss_box_reg: 0.1708  loss_rpn_cls: 0.01215  loss_rpn_loc: 0.01566    time: 1.0214  last_time: 1.0251  data_time: 0.0164  last_data_time: 0.0162   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:58:04 d2.utils.events]: \u001b[0m eta: 0:07:49  iter: 4539  total_loss: 0.3661  loss_cls: 0.17  loss_box_reg: 0.1402  loss_rpn_cls: 0.01279  loss_rpn_loc: 0.01521    time: 1.0214  last_time: 1.0218  data_time: 0.0173  last_data_time: 0.0159   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:58:25 d2.utils.events]: \u001b[0m eta: 0:07:28  iter: 4559  total_loss: 0.4272  loss_cls: 0.218  loss_box_reg: 0.1671  loss_rpn_cls: 0.01375  loss_rpn_loc: 0.01529    time: 1.0214  last_time: 1.0241  data_time: 0.0161  last_data_time: 0.0149   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:58:45 d2.utils.events]: \u001b[0m eta: 0:07:08  iter: 4579  total_loss: 0.2893  loss_cls: 0.1711  loss_box_reg: 0.09794  loss_rpn_cls: 0.006807  loss_rpn_loc: 0.02246    time: 1.0214  last_time: 1.0195  data_time: 0.0158  last_data_time: 0.0156   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:59:06 d2.utils.events]: \u001b[0m eta: 0:06:48  iter: 4599  total_loss: 0.3307  loss_cls: 0.1717  loss_box_reg: 0.1327  loss_rpn_cls: 0.0109  loss_rpn_loc: 0.02007    time: 1.0214  last_time: 1.0256  data_time: 0.0166  last_data_time: 0.0186   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:59:26 d2.utils.events]: \u001b[0m eta: 0:06:27  iter: 4619  total_loss: 0.3268  loss_cls: 0.1748  loss_box_reg: 0.1226  loss_rpn_cls: 0.00818  loss_rpn_loc: 0.01734    time: 1.0214  last_time: 1.0204  data_time: 0.0162  last_data_time: 0.0166   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 11:59:47 d2.utils.events]: \u001b[0m eta: 0:06:07  iter: 4639  total_loss: 0.3535  loss_cls: 0.173  loss_box_reg: 0.143  loss_rpn_cls: 0.01068  loss_rpn_loc: 0.01474    time: 1.0214  last_time: 1.0189  data_time: 0.0155  last_data_time: 0.0145   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:00:07 d2.utils.events]: \u001b[0m eta: 0:05:46  iter: 4659  total_loss: 0.4309  loss_cls: 0.2218  loss_box_reg: 0.175  loss_rpn_cls: 0.01575  loss_rpn_loc: 0.01944    time: 1.0214  last_time: 1.0220  data_time: 0.0151  last_data_time: 0.0144   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:00:28 d2.utils.events]: \u001b[0m eta: 0:05:26  iter: 4679  total_loss: 0.394  loss_cls: 0.2193  loss_box_reg: 0.1469  loss_rpn_cls: 0.01066  loss_rpn_loc: 0.01716    time: 1.0215  last_time: 1.0221  data_time: 0.0154  last_data_time: 0.0163   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:00:48 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 4699  total_loss: 0.4284  loss_cls: 0.1866  loss_box_reg: 0.1721  loss_rpn_cls: 0.0173  loss_rpn_loc: 0.02412    time: 1.0215  last_time: 1.0183  data_time: 0.0160  last_data_time: 0.0140   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:01:08 d2.utils.events]: \u001b[0m eta: 0:04:45  iter: 4719  total_loss: 0.2328  loss_cls: 0.1233  loss_box_reg: 0.09929  loss_rpn_cls: 0.009751  loss_rpn_loc: 0.01093    time: 1.0215  last_time: 1.0216  data_time: 0.0162  last_data_time: 0.0158   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:01:29 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 4739  total_loss: 0.3368  loss_cls: 0.1716  loss_box_reg: 0.1181  loss_rpn_cls: 0.01402  loss_rpn_loc: 0.01807    time: 1.0215  last_time: 1.0223  data_time: 0.0162  last_data_time: 0.0148   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:01:49 d2.utils.events]: \u001b[0m eta: 0:04:04  iter: 4759  total_loss: 0.3603  loss_cls: 0.1773  loss_box_reg: 0.1289  loss_rpn_cls: 0.01221  loss_rpn_loc: 0.02229    time: 1.0215  last_time: 1.0241  data_time: 0.0168  last_data_time: 0.0175   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:02:10 d2.utils.events]: \u001b[0m eta: 0:03:44  iter: 4779  total_loss: 0.3725  loss_cls: 0.1837  loss_box_reg: 0.1446  loss_rpn_cls: 0.01327  loss_rpn_loc: 0.02341    time: 1.0215  last_time: 1.0207  data_time: 0.0159  last_data_time: 0.0158   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:02:30 d2.utils.events]: \u001b[0m eta: 0:03:24  iter: 4799  total_loss: 0.3617  loss_cls: 0.1716  loss_box_reg: 0.1235  loss_rpn_cls: 0.0113  loss_rpn_loc: 0.0172    time: 1.0215  last_time: 1.0219  data_time: 0.0165  last_data_time: 0.0157   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:02:51 d2.utils.events]: \u001b[0m eta: 0:03:03  iter: 4819  total_loss: 0.3108  loss_cls: 0.1723  loss_box_reg: 0.1106  loss_rpn_cls: 0.01228  loss_rpn_loc: 0.01512    time: 1.0215  last_time: 1.0191  data_time: 0.0159  last_data_time: 0.0148   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:03:11 d2.utils.events]: \u001b[0m eta: 0:02:43  iter: 4839  total_loss: 0.3635  loss_cls: 0.1864  loss_box_reg: 0.1703  loss_rpn_cls: 0.01427  loss_rpn_loc: 0.01787    time: 1.0215  last_time: 1.0230  data_time: 0.0168  last_data_time: 0.0183   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:03:32 d2.utils.events]: \u001b[0m eta: 0:02:22  iter: 4859  total_loss: 0.4583  loss_cls: 0.2282  loss_box_reg: 0.1645  loss_rpn_cls: 0.0176  loss_rpn_loc: 0.02288    time: 1.0215  last_time: 1.0227  data_time: 0.0157  last_data_time: 0.0164   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:03:52 d2.utils.events]: \u001b[0m eta: 0:02:02  iter: 4879  total_loss: 0.5142  loss_cls: 0.2376  loss_box_reg: 0.1614  loss_rpn_cls: 0.0203  loss_rpn_loc: 0.03843    time: 1.0215  last_time: 1.0245  data_time: 0.0168  last_data_time: 0.0163   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:04:13 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 4899  total_loss: 0.4596  loss_cls: 0.2269  loss_box_reg: 0.184  loss_rpn_cls: 0.02104  loss_rpn_loc: 0.03205    time: 1.0215  last_time: 1.0284  data_time: 0.0159  last_data_time: 0.0164   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:04:33 d2.utils.events]: \u001b[0m eta: 0:01:21  iter: 4919  total_loss: 0.3261  loss_cls: 0.1845  loss_box_reg: 0.1231  loss_rpn_cls: 0.009895  loss_rpn_loc: 0.01675    time: 1.0215  last_time: 1.0178  data_time: 0.0158  last_data_time: 0.0150   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:04:54 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 4939  total_loss: 0.3387  loss_cls: 0.1714  loss_box_reg: 0.1338  loss_rpn_cls: 0.01154  loss_rpn_loc: 0.01838    time: 1.0215  last_time: 1.0219  data_time: 0.0161  last_data_time: 0.0144   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:05:14 d2.utils.events]: \u001b[0m eta: 0:00:40  iter: 4959  total_loss: 0.318  loss_cls: 0.1757  loss_box_reg: 0.1111  loss_rpn_cls: 0.008217  loss_rpn_loc: 0.01175    time: 1.0215  last_time: 1.0241  data_time: 0.0162  last_data_time: 0.0181   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:05:34 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 4979  total_loss: 0.3464  loss_cls: 0.1864  loss_box_reg: 0.1252  loss_rpn_cls: 0.01033  loss_rpn_loc: 0.0168    time: 1.0215  last_time: 1.0201  data_time: 0.0158  last_data_time: 0.0163   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:05:58 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 4999  total_loss: 0.438  loss_cls: 0.2067  loss_box_reg: 0.164  loss_rpn_cls: 0.0115  loss_rpn_loc: 0.02447    time: 1.0215  last_time: 1.0201  data_time: 0.0159  last_data_time: 0.0170   lr: 2.5e-08  max_mem: 12194M\n",
      "\u001b[32m[10/12 12:05:58 d2.engine.hooks]: \u001b[0mOverall training speed: 4998 iterations in 1:25:05 (1.0215 s / it)\n",
      "\u001b[32m[10/12 12:05:58 d2.engine.hooks]: \u001b[0mTotal training time: 1:35:42 (0:10:36 on hooks)\n",
      "\u001b[32m[10/12 12:05:58 d2.data.datasets.coco]: \u001b[0mLoaded 977 images in COCO format from /data/ephemeral/home/Lv2.Object_Detection/dataset/val_fold_0.json\n",
      "\u001b[32m[10/12 12:05:58 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/12 12:05:58 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/12 12:05:58 d2.data.common]: \u001b[0mSerializing 977 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/12 12:05:58 d2.data.common]: \u001b[0mSerialized dataset takes 0.49 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/12 12:05:58 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/12 12:05:58 d2.evaluation.evaluator]: \u001b[0mStart inference on 977 batches\n",
      "\u001b[32m[10/12 12:05:59 d2.evaluation.evaluator]: \u001b[0mInference done 11/977. Dataloading: 0.0010 s/iter. Inference: 0.0669 s/iter. Eval: 0.0002 s/iter. Total: 0.0682 s/iter. ETA=0:01:05\n",
      "\u001b[32m[10/12 12:06:04 d2.evaluation.evaluator]: \u001b[0mInference done 83/977. Dataloading: 0.0013 s/iter. Inference: 0.0678 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:01:02\n",
      "\u001b[32m[10/12 12:06:09 d2.evaluation.evaluator]: \u001b[0mInference done 156/977. Dataloading: 0.0013 s/iter. Inference: 0.0677 s/iter. Eval: 0.0003 s/iter. Total: 0.0694 s/iter. ETA=0:00:56\n",
      "\u001b[32m[10/12 12:06:14 d2.evaluation.evaluator]: \u001b[0mInference done 228/977. Dataloading: 0.0013 s/iter. Inference: 0.0681 s/iter. Eval: 0.0003 s/iter. Total: 0.0697 s/iter. ETA=0:00:52\n",
      "\u001b[32m[10/12 12:06:19 d2.evaluation.evaluator]: \u001b[0mInference done 300/977. Dataloading: 0.0013 s/iter. Inference: 0.0681 s/iter. Eval: 0.0003 s/iter. Total: 0.0697 s/iter. ETA=0:00:47\n",
      "\u001b[32m[10/12 12:06:24 d2.evaluation.evaluator]: \u001b[0mInference done 373/977. Dataloading: 0.0013 s/iter. Inference: 0.0680 s/iter. Eval: 0.0003 s/iter. Total: 0.0697 s/iter. ETA=0:00:42\n",
      "\u001b[32m[10/12 12:06:29 d2.evaluation.evaluator]: \u001b[0mInference done 446/977. Dataloading: 0.0013 s/iter. Inference: 0.0679 s/iter. Eval: 0.0003 s/iter. Total: 0.0695 s/iter. ETA=0:00:36\n",
      "\u001b[32m[10/12 12:06:34 d2.evaluation.evaluator]: \u001b[0mInference done 517/977. Dataloading: 0.0013 s/iter. Inference: 0.0681 s/iter. Eval: 0.0003 s/iter. Total: 0.0697 s/iter. ETA=0:00:32\n",
      "\u001b[32m[10/12 12:06:39 d2.evaluation.evaluator]: \u001b[0mInference done 589/977. Dataloading: 0.0013 s/iter. Inference: 0.0681 s/iter. Eval: 0.0003 s/iter. Total: 0.0697 s/iter. ETA=0:00:27\n",
      "\u001b[32m[10/12 12:06:44 d2.evaluation.evaluator]: \u001b[0mInference done 661/977. Dataloading: 0.0013 s/iter. Inference: 0.0681 s/iter. Eval: 0.0003 s/iter. Total: 0.0697 s/iter. ETA=0:00:22\n",
      "\u001b[32m[10/12 12:06:49 d2.evaluation.evaluator]: \u001b[0mInference done 732/977. Dataloading: 0.0013 s/iter. Inference: 0.0682 s/iter. Eval: 0.0003 s/iter. Total: 0.0698 s/iter. ETA=0:00:17\n",
      "\u001b[32m[10/12 12:06:54 d2.evaluation.evaluator]: \u001b[0mInference done 804/977. Dataloading: 0.0013 s/iter. Inference: 0.0682 s/iter. Eval: 0.0003 s/iter. Total: 0.0698 s/iter. ETA=0:00:12\n",
      "\u001b[32m[10/12 12:07:00 d2.evaluation.evaluator]: \u001b[0mInference done 878/977. Dataloading: 0.0013 s/iter. Inference: 0.0681 s/iter. Eval: 0.0003 s/iter. Total: 0.0697 s/iter. ETA=0:00:06\n",
      "\u001b[32m[10/12 12:07:05 d2.evaluation.evaluator]: \u001b[0mInference done 951/977. Dataloading: 0.0013 s/iter. Inference: 0.0680 s/iter. Eval: 0.0003 s/iter. Total: 0.0696 s/iter. ETA=0:00:01\n",
      "\u001b[32m[10/12 12:07:06 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:01:07.794384 (0.069747 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 12:07:06 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:01:06 (0.068032 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/12 12:07:07 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/12 12:07:07 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/12 12:07:07 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.26s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/12 12:07:07 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/12 12:07:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 0.44 seconds.\n",
      "\u001b[32m[10/12 12:07:08 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/12 12:07:08 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.13 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.266\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.378\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.282\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.002\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.044\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.314\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.269\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.484\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.514\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.184\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.588\n",
      "\u001b[32m[10/12 12:07:08 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:------:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 26.586 | 37.775 | 28.242 | 0.165 | 4.415 | 31.430 |\n",
      "\u001b[32m[10/12 12:07:08 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP     | category    | AP     | category   | AP     |\n",
      "|:--------------|:-------|:------------|:-------|:-----------|:-------|\n",
      "| General trash | 10.936 | Paper       | 22.529 | Paper pack | 28.707 |\n",
      "| Metal         | 31.804 | Glass       | 28.435 | Plastic    | 19.013 |\n",
      "| Styrofoam     | 23.753 | Plastic bag | 49.415 | Battery    | 33.641 |\n",
      "| Clothing      | 17.627 |             |        |            |        |\n",
      "\u001b[32m[10/12 12:07:08 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_val_fold_0 in csv format:\n",
      "\u001b[32m[10/12 12:07:08 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/12 12:07:08 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/12 12:07:08 d2.evaluation.testing]: \u001b[0mcopypaste: 26.5860,37.7750,28.2425,0.1650,4.4145,31.4295\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">wandb_test</strong> at: <a href='https://wandb.ai/yujihwan-yonsei-university/detectron2/runs/hcmfnm7z' target=\"_blank\">https://wandb.ai/yujihwan-yonsei-university/detectron2/runs/hcmfnm7z</a><br/> View project at: <a href='https://wandb.ai/yujihwan-yonsei-university/detectron2' target=\"_blank\">https://wandb.ai/yujihwan-yonsei-university/detectron2</a><br/>Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20241012_103012-hcmfnm7z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습 시작\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

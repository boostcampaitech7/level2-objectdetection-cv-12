{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import detectron2\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.evaluation import COCOEvaluator\n",
    "from detectron2.data import build_detection_test_loader, build_detection_train_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register Dataset\n",
    "try: # register_coco_instances 함수를 사용해 COCO 형식의 데이터셋을 등록\n",
    "    register_coco_instances('coco_trash_train', {}, '../../dataset/train.json', '../../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "try: # \n",
    "    register_coco_instances('coco_trash_test', {}, '../../dataset/test.json', '../../dataset/')\n",
    "except AssertionError:\n",
    "    pass\n",
    "\n",
    "# MetadataCatalog.get()를 통해 coco_trash_train 데이터셋의 클래스 이름을 지정\n",
    "MetadataCatalog.get('coco_trash_train').thing_classes = [\"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \n",
    "                                                         \"Glass\", \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 불러오기\n",
    "'''\n",
    "1. get_cfg()를 호출해 기본 설정을 가져오기\n",
    "\n",
    "2. model_zoo.get_config_file()을 사용해 미리 정의된 Faster R-CNN의 R101 FPN 3x 구성 파일을 로드(이 부분은 변경 가능)\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file('Misc/cascade_mask_rcnn_R_50_FPN_1x.yaml'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config 수정하기\n",
    "'''\n",
    "1. 데이터를 학습(TRAIN)과 테스트(TEST)로 설정하고, Dataloader의 worker 수를 지정\n",
    "\n",
    "2. cfg.MODEL.WEIGHTS를 통해 사전 학습된 모델의 가중치를 설정\n",
    "\n",
    "3. 학습 배치 크기, 학습률, 최대 반복 횟수, 스케줄러 단계 및 감마값을 조정\n",
    "\n",
    "4. cfg.OUTPUT_DIR를 설정하여 모델 출력 파일을 저장할 디렉터리를 지정\n",
    "\n",
    "5. cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE와 cfg.MODEL.ROI_HEADS.NUM_CLASSES를 설정하여 이미지당 ROI의 배치 크기와 클래스 수를 설정\n",
    "\n",
    "6. cfg.TEST.EVAL_PERIOD를 통해 모델 평가 주기를 설정\n",
    "\n",
    "'''\n",
    "\n",
    "cfg.DATASETS.TRAIN = ('coco_trash_train',)\n",
    "cfg.DATASETS.TEST = ('coco_trash_test',)\n",
    "\n",
    "cfg.DATALOADER.NUM_WOREKRS = 2\n",
    "\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url('Misc/cascade_mask_rcnn_R_50_FPN_1x.yaml')\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.001\n",
    "cfg.SOLVER.MAX_ITER = 15000\n",
    "cfg.SOLVER.STEPS = (8000,12000)\n",
    "cfg.SOLVER.GAMMA = 0.005\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 3000\n",
    "\n",
    "cfg.OUTPUT_DIR = './output'\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 10\n",
    "\n",
    "cfg.TEST.EVAL_PERIOD = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapper - input data를 어떤 형식으로 return할지 (따라서 augmnentation 등 데이터 전처리 포함 됨)\n",
    "'''\n",
    "데이터 매퍼 (전처리) 설정:\n",
    "\n",
    "MyMapper 함수는 입력 데이터에 대한 전처리 방법을 정의\n",
    "\n",
    "이미지에 랜덤으로 수직 뒤집기, 밝기 및 대비 변환을 적용\n",
    "\n",
    "변환된 이미지를 텐서로 변환하고 어노테이션을 조정하여 dataset_dict에 추가\n",
    "\n",
    "'''\n",
    "import detectron2.data.transforms as T\n",
    "\n",
    "def MyMapper(dataset_dict):\n",
    "    dataset_dict = copy.deepcopy(dataset_dict)\n",
    "    image = utils.read_image(dataset_dict['file_name'], format='BGR')\n",
    "    \n",
    "    transform_list = [\n",
    "        T.RandomFlip(prob=0.5, horizontal=False, vertical=True),\n",
    "        T.RandomBrightness(0.8, 1.8),\n",
    "        T.RandomContrast(0.6, 1.3)\n",
    "    ]\n",
    "    \n",
    "    image, transforms = T.apply_transform_gens(transform_list, image)\n",
    "    \n",
    "    dataset_dict['image'] = torch.as_tensor(image.transpose(2,0,1).astype('float32'))\n",
    "    \n",
    "    annos = [\n",
    "        utils.transform_instance_annotations(obj, transforms, image.shape[:2])\n",
    "        for obj in dataset_dict.pop('annotations')\n",
    "        if obj.get('iscrowd', 0) == 0\n",
    "    ]\n",
    "    \n",
    "    instances = utils.annotations_to_instances(annos, image.shape[:2])\n",
    "    dataset_dict['instances'] = utils.filter_empty_instances(instances)\n",
    "    \n",
    "    return dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer - DefaultTrainer를 상속\n",
    "'''\n",
    "커스텀 트레이너 정의:\n",
    "\n",
    "MyTrainer 클래스는 DefaultTrainer를 상속하고 build_train_loader 및 build_evaluator 메서드를 overwrite\n",
    "\n",
    "build_train_loader: 데이터 로더를 생성할 때 커스텀 매퍼를 사용하도록 함\n",
    "\n",
    "build_evaluator: 평가를 위해 COCO 평가기를 생성\n",
    "\n",
    "'''\n",
    "\n",
    "class MyTrainer(DefaultTrainer):\n",
    "    \n",
    "    @classmethod\n",
    "    def build_train_loader(cls, cfg, sampler=None):\n",
    "        return build_detection_train_loader(\n",
    "        cfg, mapper = MyMapper, sampler = sampler\n",
    "        )\n",
    "    \n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs('./output_eval', exist_ok = True)\n",
    "            output_folder = './output_eval'\n",
    "            \n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/06 00:03:10 d2.engine.defaults]: \u001b[0mModel:\n",
      "GeneralizedRCNN(\n",
      "  (backbone): FPN(\n",
      "    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (top_block): LastLevelMaxPool()\n",
      "    (bottom_up): ResNet(\n",
      "      (stem): BasicStem(\n",
      "        (conv1): Conv2d(\n",
      "          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
      "          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "        )\n",
      "      )\n",
      "      (res2): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res3): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res4): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (3): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (4): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (5): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (6): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (7): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (8): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (9): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (10): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (11): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (12): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (13): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (14): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (15): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (16): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (17): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (18): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (19): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (20): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (21): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (22): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (res5): Sequential(\n",
      "        (0): BottleneckBlock(\n",
      "          (shortcut): Conv2d(\n",
      "            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "          (conv1): Conv2d(\n",
      "            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (1): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "        (2): BottleneckBlock(\n",
      "          (conv1): Conv2d(\n",
      "            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv2): Conv2d(\n",
      "            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)\n",
      "          )\n",
      "          (conv3): Conv2d(\n",
      "            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (proposal_generator): RPN(\n",
      "    (rpn_head): StandardRPNHead(\n",
      "      (conv): Conv2d(\n",
      "        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (anchor_generator): DefaultAnchorGenerator(\n",
      "      (cell_anchors): BufferList()\n",
      "    )\n",
      "  )\n",
      "  (roi_heads): StandardROIHeads(\n",
      "    (box_pooler): ROIPooler(\n",
      "      (level_poolers): ModuleList(\n",
      "        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)\n",
      "        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)\n",
      "        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)\n",
      "        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)\n",
      "      )\n",
      "    )\n",
      "    (box_head): FastRCNNConvFCHead(\n",
      "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      (fc1): Linear(in_features=12544, out_features=1024, bias=True)\n",
      "      (fc_relu1): ReLU()\n",
      "      (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "      (fc_relu2): ReLU()\n",
      "    )\n",
      "    (box_predictor): FastRCNNOutputLayers(\n",
      "      (cls_score): Linear(in_features=1024, out_features=11, bias=True)\n",
      "      (bbox_pred): Linear(in_features=1024, out_features=40, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\u001b[32m[10/06 00:03:10 d2.data.datasets.coco]: \u001b[0mLoaded 4883 images in COCO format from ../../dataset/train.json\n",
      "\u001b[32m[10/06 00:03:10 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 4883 images left.\n",
      "\u001b[32m[10/06 00:03:10 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 3966         |    Paper    | 6352         | Paper pack | 897          |\n",
      "|     Metal     | 936          |    Glass    | 982          |  Plastic   | 2943         |\n",
      "|   Styrofoam   | 1263         | Plastic bag | 5178         |  Battery   | 159          |\n",
      "|   Clothing    | 468          |             |              |            |              |\n",
      "|     total     | 23144        |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/06 00:03:10 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[10/06 00:03:10 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/06 00:03:10 d2.data.common]: \u001b[0mSerializing 4883 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/06 00:03:10 d2.data.common]: \u001b[0mSerialized dataset takes 2.19 MiB\n",
      "\u001b[32m[10/06 00:03:10 d2.data.build]: \u001b[0mMaking batched data loader with batch_size=4\n",
      "\u001b[32m[10/06 00:03:10 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-Detection/faster_rcnn_R_101_FPN_3x/137851257/model_final_f6e8b1.pkl ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_final_f6e8b1.pkl: 243MB [00:03, 77.5MB/s]                              \n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (11, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (11,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (40, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (40,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/06 00:03:13 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/functional.py:478: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2894.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[10/06 00:03:26 d2.utils.events]: \u001b[0m eta: 1:58:49  iter: 19  total_loss: 3.278  loss_cls: 2.479  loss_box_reg: 0.625  loss_rpn_cls: 0.07086  loss_rpn_loc: 0.03456    time: 0.4776  last_time: 0.4821  data_time: 0.0249  last_data_time: 0.0187   lr: 1.9981e-05  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:03:35 d2.utils.events]: \u001b[0m eta: 1:58:13  iter: 39  total_loss: 2.953  loss_cls: 2.048  loss_box_reg: 0.7529  loss_rpn_cls: 0.1068  loss_rpn_loc: 0.05746    time: 0.4758  last_time: 0.4745  data_time: 0.0137  last_data_time: 0.0132   lr: 3.9961e-05  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:03:45 d2.utils.events]: \u001b[0m eta: 1:58:07  iter: 59  total_loss: 2.224  loss_cls: 1.3  loss_box_reg: 0.726  loss_rpn_cls: 0.05599  loss_rpn_loc: 0.03283    time: 0.4761  last_time: 0.4728  data_time: 0.0146  last_data_time: 0.0130   lr: 5.9941e-05  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:03:54 d2.utils.events]: \u001b[0m eta: 1:58:14  iter: 79  total_loss: 1.656  loss_cls: 0.8164  loss_box_reg: 0.6938  loss_rpn_cls: 0.07511  loss_rpn_loc: 0.0427    time: 0.4777  last_time: 0.4743  data_time: 0.0137  last_data_time: 0.0132   lr: 7.9921e-05  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:04:04 d2.utils.events]: \u001b[0m eta: 1:58:14  iter: 99  total_loss: 1.561  loss_cls: 0.7604  loss_box_reg: 0.7079  loss_rpn_cls: 0.07279  loss_rpn_loc: 0.02611    time: 0.4784  last_time: 0.4871  data_time: 0.0144  last_data_time: 0.0135   lr: 9.9901e-05  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:04:14 d2.utils.events]: \u001b[0m eta: 1:58:17  iter: 119  total_loss: 1.527  loss_cls: 0.7224  loss_box_reg: 0.7526  loss_rpn_cls: 0.05155  loss_rpn_loc: 0.01987    time: 0.4786  last_time: 0.4941  data_time: 0.0139  last_data_time: 0.0143   lr: 0.00011988  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:04:23 d2.utils.events]: \u001b[0m eta: 1:58:08  iter: 139  total_loss: 1.438  loss_cls: 0.6788  loss_box_reg: 0.6725  loss_rpn_cls: 0.04055  loss_rpn_loc: 0.02934    time: 0.4787  last_time: 0.4746  data_time: 0.0147  last_data_time: 0.0135   lr: 0.00013986  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:04:33 d2.utils.events]: \u001b[0m eta: 1:57:56  iter: 159  total_loss: 1.547  loss_cls: 0.7087  loss_box_reg: 0.721  loss_rpn_cls: 0.05388  loss_rpn_loc: 0.03724    time: 0.4785  last_time: 0.4751  data_time: 0.0149  last_data_time: 0.0137   lr: 0.00015984  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:04:42 d2.utils.events]: \u001b[0m eta: 1:57:48  iter: 179  total_loss: 1.469  loss_cls: 0.666  loss_box_reg: 0.734  loss_rpn_cls: 0.02726  loss_rpn_loc: 0.02923    time: 0.4787  last_time: 0.4782  data_time: 0.0153  last_data_time: 0.0141   lr: 0.00017982  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:04:52 d2.utils.events]: \u001b[0m eta: 1:57:44  iter: 199  total_loss: 1.456  loss_cls: 0.658  loss_box_reg: 0.7139  loss_rpn_cls: 0.02958  loss_rpn_loc: 0.02726    time: 0.4791  last_time: 0.4870  data_time: 0.0153  last_data_time: 0.0189   lr: 0.0001998  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:05:02 d2.utils.events]: \u001b[0m eta: 1:57:40  iter: 219  total_loss: 1.468  loss_cls: 0.6588  loss_box_reg: 0.746  loss_rpn_cls: 0.03475  loss_rpn_loc: 0.02803    time: 0.4795  last_time: 0.4778  data_time: 0.0143  last_data_time: 0.0139   lr: 0.00021978  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:05:11 d2.utils.events]: \u001b[0m eta: 1:57:31  iter: 239  total_loss: 1.336  loss_cls: 0.6113  loss_box_reg: 0.6523  loss_rpn_cls: 0.02818  loss_rpn_loc: 0.02303    time: 0.4798  last_time: 0.4878  data_time: 0.0144  last_data_time: 0.0142   lr: 0.00023976  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:05:21 d2.utils.events]: \u001b[0m eta: 1:57:26  iter: 259  total_loss: 1.301  loss_cls: 0.5697  loss_box_reg: 0.663  loss_rpn_cls: 0.02855  loss_rpn_loc: 0.0244    time: 0.4801  last_time: 0.4853  data_time: 0.0150  last_data_time: 0.0137   lr: 0.00025974  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:05:31 d2.utils.events]: \u001b[0m eta: 1:57:19  iter: 279  total_loss: 1.326  loss_cls: 0.5994  loss_box_reg: 0.6533  loss_rpn_cls: 0.03406  loss_rpn_loc: 0.03286    time: 0.4803  last_time: 0.4867  data_time: 0.0143  last_data_time: 0.0138   lr: 0.00027972  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:05:40 d2.utils.events]: \u001b[0m eta: 1:57:09  iter: 299  total_loss: 1.362  loss_cls: 0.6132  loss_box_reg: 0.6652  loss_rpn_cls: 0.02889  loss_rpn_loc: 0.03051    time: 0.4802  last_time: 0.4782  data_time: 0.0155  last_data_time: 0.0144   lr: 0.0002997  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:05:50 d2.utils.events]: \u001b[0m eta: 1:56:59  iter: 319  total_loss: 1.289  loss_cls: 0.5991  loss_box_reg: 0.6335  loss_rpn_cls: 0.01669  loss_rpn_loc: 0.01579    time: 0.4801  last_time: 0.4777  data_time: 0.0160  last_data_time: 0.0144   lr: 0.00031968  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:06:00 d2.utils.events]: \u001b[0m eta: 1:56:53  iter: 339  total_loss: 1.173  loss_cls: 0.5543  loss_box_reg: 0.5644  loss_rpn_cls: 0.0243  loss_rpn_loc: 0.0183    time: 0.4805  last_time: 0.4862  data_time: 0.0159  last_data_time: 0.0198   lr: 0.00033966  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:06:09 d2.utils.events]: \u001b[0m eta: 1:56:45  iter: 359  total_loss: 1.243  loss_cls: 0.6197  loss_box_reg: 0.5565  loss_rpn_cls: 0.0357  loss_rpn_loc: 0.02218    time: 0.4806  last_time: 0.4747  data_time: 0.0148  last_data_time: 0.0145   lr: 0.00035964  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:06:19 d2.utils.events]: \u001b[0m eta: 1:56:35  iter: 379  total_loss: 1.161  loss_cls: 0.5492  loss_box_reg: 0.5144  loss_rpn_cls: 0.0367  loss_rpn_loc: 0.04028    time: 0.4805  last_time: 0.4778  data_time: 0.0153  last_data_time: 0.0139   lr: 0.00037962  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:06:29 d2.utils.events]: \u001b[0m eta: 1:56:28  iter: 399  total_loss: 1.173  loss_cls: 0.5684  loss_box_reg: 0.4716  loss_rpn_cls: 0.04275  loss_rpn_loc: 0.05282    time: 0.4805  last_time: 0.4787  data_time: 0.0151  last_data_time: 0.0137   lr: 0.0003996  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:06:38 d2.utils.events]: \u001b[0m eta: 1:56:19  iter: 419  total_loss: 1.002  loss_cls: 0.5159  loss_box_reg: 0.3991  loss_rpn_cls: 0.02973  loss_rpn_loc: 0.0271    time: 0.4805  last_time: 0.4784  data_time: 0.0154  last_data_time: 0.0150   lr: 0.00041958  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:06:48 d2.utils.events]: \u001b[0m eta: 1:56:08  iter: 439  total_loss: 0.9294  loss_cls: 0.491  loss_box_reg: 0.3679  loss_rpn_cls: 0.02984  loss_rpn_loc: 0.02234    time: 0.4805  last_time: 0.4779  data_time: 0.0154  last_data_time: 0.0149   lr: 0.00043956  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:06:57 d2.utils.events]: \u001b[0m eta: 1:55:59  iter: 459  total_loss: 1.089  loss_cls: 0.5531  loss_box_reg: 0.3879  loss_rpn_cls: 0.04387  loss_rpn_loc: 0.05196    time: 0.4804  last_time: 0.4863  data_time: 0.0166  last_data_time: 0.0139   lr: 0.00045954  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:07:07 d2.utils.events]: \u001b[0m eta: 1:55:51  iter: 479  total_loss: 1  loss_cls: 0.5368  loss_box_reg: 0.3402  loss_rpn_cls: 0.03196  loss_rpn_loc: 0.05183    time: 0.4805  last_time: 0.4768  data_time: 0.0161  last_data_time: 0.0143   lr: 0.00047952  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:07:17 d2.utils.events]: \u001b[0m eta: 1:55:43  iter: 499  total_loss: 0.9422  loss_cls: 0.4748  loss_box_reg: 0.3531  loss_rpn_cls: 0.03891  loss_rpn_loc: 0.03492    time: 0.4807  last_time: 0.4887  data_time: 0.0159  last_data_time: 0.0153   lr: 0.0004995  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:07:26 d2.utils.events]: \u001b[0m eta: 1:55:33  iter: 519  total_loss: 0.9823  loss_cls: 0.5076  loss_box_reg: 0.3611  loss_rpn_cls: 0.02438  loss_rpn_loc: 0.0253    time: 0.4807  last_time: 0.4863  data_time: 0.0156  last_data_time: 0.0139   lr: 0.00051948  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:07:36 d2.utils.events]: \u001b[0m eta: 1:55:23  iter: 539  total_loss: 1.05  loss_cls: 0.5593  loss_box_reg: 0.4692  loss_rpn_cls: 0.01894  loss_rpn_loc: 0.02766    time: 0.4806  last_time: 0.4763  data_time: 0.0151  last_data_time: 0.0141   lr: 0.00053946  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:07:46 d2.utils.events]: \u001b[0m eta: 1:55:16  iter: 559  total_loss: 0.9862  loss_cls: 0.5146  loss_box_reg: 0.3767  loss_rpn_cls: 0.02687  loss_rpn_loc: 0.03719    time: 0.4807  last_time: 0.4791  data_time: 0.0158  last_data_time: 0.0145   lr: 0.00055944  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:07:55 d2.utils.events]: \u001b[0m eta: 1:55:09  iter: 579  total_loss: 1.004  loss_cls: 0.5149  loss_box_reg: 0.3868  loss_rpn_cls: 0.02209  loss_rpn_loc: 0.0253    time: 0.4807  last_time: 0.4808  data_time: 0.0164  last_data_time: 0.0137   lr: 0.00057942  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:08:05 d2.utils.events]: \u001b[0m eta: 1:54:56  iter: 599  total_loss: 0.8045  loss_cls: 0.4719  loss_box_reg: 0.3261  loss_rpn_cls: 0.0234  loss_rpn_loc: 0.02048    time: 0.4806  last_time: 0.4775  data_time: 0.0140  last_data_time: 0.0137   lr: 0.0005994  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:08:14 d2.utils.events]: \u001b[0m eta: 1:54:46  iter: 619  total_loss: 0.8549  loss_cls: 0.4866  loss_box_reg: 0.305  loss_rpn_cls: 0.02013  loss_rpn_loc: 0.02392    time: 0.4805  last_time: 0.4732  data_time: 0.0143  last_data_time: 0.0138   lr: 0.00061938  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:08:24 d2.utils.events]: \u001b[0m eta: 1:54:35  iter: 639  total_loss: 1.035  loss_cls: 0.5443  loss_box_reg: 0.4105  loss_rpn_cls: 0.04331  loss_rpn_loc: 0.05664    time: 0.4803  last_time: 0.4730  data_time: 0.0141  last_data_time: 0.0136   lr: 0.00063936  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:08:33 d2.utils.events]: \u001b[0m eta: 1:54:24  iter: 659  total_loss: 0.8909  loss_cls: 0.4929  loss_box_reg: 0.3383  loss_rpn_cls: 0.02723  loss_rpn_loc: 0.03083    time: 0.4802  last_time: 0.4740  data_time: 0.0139  last_data_time: 0.0135   lr: 0.00065934  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:08:43 d2.utils.events]: \u001b[0m eta: 1:54:11  iter: 679  total_loss: 0.8802  loss_cls: 0.4678  loss_box_reg: 0.3384  loss_rpn_cls: 0.03241  loss_rpn_loc: 0.03216    time: 0.4800  last_time: 0.4734  data_time: 0.0138  last_data_time: 0.0139   lr: 0.00067932  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:08:53 d2.utils.events]: \u001b[0m eta: 1:54:01  iter: 699  total_loss: 0.8061  loss_cls: 0.4198  loss_box_reg: 0.3258  loss_rpn_cls: 0.03075  loss_rpn_loc: 0.02035    time: 0.4799  last_time: 0.4740  data_time: 0.0143  last_data_time: 0.0138   lr: 0.0006993  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:09:02 d2.utils.events]: \u001b[0m eta: 1:53:50  iter: 719  total_loss: 0.8805  loss_cls: 0.5001  loss_box_reg: 0.3268  loss_rpn_cls: 0.02112  loss_rpn_loc: 0.02075    time: 0.4799  last_time: 0.4784  data_time: 0.0142  last_data_time: 0.0148   lr: 0.00071928  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:09:12 d2.utils.events]: \u001b[0m eta: 1:53:41  iter: 739  total_loss: 0.9493  loss_cls: 0.555  loss_box_reg: 0.3335  loss_rpn_cls: 0.01785  loss_rpn_loc: 0.0215    time: 0.4799  last_time: 0.4754  data_time: 0.0142  last_data_time: 0.0140   lr: 0.00073926  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:09:21 d2.utils.events]: \u001b[0m eta: 1:53:32  iter: 759  total_loss: 0.9042  loss_cls: 0.4884  loss_box_reg: 0.307  loss_rpn_cls: 0.04545  loss_rpn_loc: 0.03849    time: 0.4799  last_time: 0.4740  data_time: 0.0154  last_data_time: 0.0137   lr: 0.00075924  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:09:31 d2.utils.events]: \u001b[0m eta: 1:53:21  iter: 779  total_loss: 0.9071  loss_cls: 0.4801  loss_box_reg: 0.3352  loss_rpn_cls: 0.02552  loss_rpn_loc: 0.0224    time: 0.4798  last_time: 0.4799  data_time: 0.0144  last_data_time: 0.0149   lr: 0.00077922  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:09:41 d2.utils.events]: \u001b[0m eta: 1:53:13  iter: 799  total_loss: 0.8626  loss_cls: 0.4597  loss_box_reg: 0.3286  loss_rpn_cls: 0.02455  loss_rpn_loc: 0.02183    time: 0.4799  last_time: 0.4866  data_time: 0.0147  last_data_time: 0.0140   lr: 0.0007992  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:09:50 d2.utils.events]: \u001b[0m eta: 1:53:05  iter: 819  total_loss: 0.8126  loss_cls: 0.434  loss_box_reg: 0.2787  loss_rpn_cls: 0.02907  loss_rpn_loc: 0.02115    time: 0.4800  last_time: 0.4781  data_time: 0.0152  last_data_time: 0.0135   lr: 0.00081918  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:10:00 d2.utils.events]: \u001b[0m eta: 1:52:56  iter: 839  total_loss: 0.8246  loss_cls: 0.4325  loss_box_reg: 0.2894  loss_rpn_cls: 0.01516  loss_rpn_loc: 0.02237    time: 0.4800  last_time: 0.4777  data_time: 0.0145  last_data_time: 0.0142   lr: 0.00083916  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:10:09 d2.utils.events]: \u001b[0m eta: 1:52:46  iter: 859  total_loss: 0.8541  loss_cls: 0.4905  loss_box_reg: 0.3161  loss_rpn_cls: 0.01916  loss_rpn_loc: 0.03259    time: 0.4800  last_time: 0.4759  data_time: 0.0155  last_data_time: 0.0138   lr: 0.00085914  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:10:19 d2.utils.events]: \u001b[0m eta: 1:52:38  iter: 879  total_loss: 0.939  loss_cls: 0.5079  loss_box_reg: 0.338  loss_rpn_cls: 0.02764  loss_rpn_loc: 0.03593    time: 0.4800  last_time: 0.4909  data_time: 0.0151  last_data_time: 0.0157   lr: 0.00087912  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:10:29 d2.utils.events]: \u001b[0m eta: 1:52:29  iter: 899  total_loss: 0.7946  loss_cls: 0.43  loss_box_reg: 0.2656  loss_rpn_cls: 0.03564  loss_rpn_loc: 0.03106    time: 0.4801  last_time: 0.4840  data_time: 0.0148  last_data_time: 0.0177   lr: 0.0008991  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:10:38 d2.utils.events]: \u001b[0m eta: 1:52:19  iter: 919  total_loss: 0.9978  loss_cls: 0.5392  loss_box_reg: 0.3372  loss_rpn_cls: 0.03105  loss_rpn_loc: 0.04069    time: 0.4801  last_time: 0.4856  data_time: 0.0156  last_data_time: 0.0144   lr: 0.00091908  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:10:48 d2.utils.events]: \u001b[0m eta: 1:52:10  iter: 939  total_loss: 0.8626  loss_cls: 0.4962  loss_box_reg: 0.3191  loss_rpn_cls: 0.03293  loss_rpn_loc: 0.027    time: 0.4801  last_time: 0.4798  data_time: 0.0155  last_data_time: 0.0147   lr: 0.00093906  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:10:58 d2.utils.events]: \u001b[0m eta: 1:52:00  iter: 959  total_loss: 0.9122  loss_cls: 0.5223  loss_box_reg: 0.3273  loss_rpn_cls: 0.02123  loss_rpn_loc: 0.01978    time: 0.4801  last_time: 0.4758  data_time: 0.0155  last_data_time: 0.0148   lr: 0.00095904  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:11:07 d2.utils.events]: \u001b[0m eta: 1:51:50  iter: 979  total_loss: 0.9201  loss_cls: 0.4953  loss_box_reg: 0.3807  loss_rpn_cls: 0.02509  loss_rpn_loc: 0.0287    time: 0.4801  last_time: 0.4744  data_time: 0.0155  last_data_time: 0.0144   lr: 0.00097902  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:11:17 d2.utils.events]: \u001b[0m eta: 1:51:41  iter: 999  total_loss: 0.8024  loss_cls: 0.4698  loss_box_reg: 0.306  loss_rpn_cls: 0.01602  loss_rpn_loc: 0.01179    time: 0.4801  last_time: 0.4991  data_time: 0.0156  last_data_time: 0.0252   lr: 0.000999  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:11:26 d2.utils.events]: \u001b[0m eta: 1:51:31  iter: 1019  total_loss: 0.8633  loss_cls: 0.4779  loss_box_reg: 0.3175  loss_rpn_cls: 0.01927  loss_rpn_loc: 0.016    time: 0.4801  last_time: 0.4890  data_time: 0.0157  last_data_time: 0.0154   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:11:36 d2.utils.events]: \u001b[0m eta: 1:51:22  iter: 1039  total_loss: 0.8559  loss_cls: 0.4777  loss_box_reg: 0.2852  loss_rpn_cls: 0.02356  loss_rpn_loc: 0.02615    time: 0.4801  last_time: 0.4758  data_time: 0.0157  last_data_time: 0.0136   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:11:46 d2.utils.events]: \u001b[0m eta: 1:51:12  iter: 1059  total_loss: 0.8612  loss_cls: 0.4803  loss_box_reg: 0.318  loss_rpn_cls: 0.02466  loss_rpn_loc: 0.02606    time: 0.4800  last_time: 0.4754  data_time: 0.0140  last_data_time: 0.0137   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:11:55 d2.utils.events]: \u001b[0m eta: 1:51:03  iter: 1079  total_loss: 0.9662  loss_cls: 0.513  loss_box_reg: 0.3567  loss_rpn_cls: 0.02276  loss_rpn_loc: 0.03276    time: 0.4800  last_time: 0.4765  data_time: 0.0140  last_data_time: 0.0138   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:12:05 d2.utils.events]: \u001b[0m eta: 1:50:53  iter: 1099  total_loss: 0.8348  loss_cls: 0.4626  loss_box_reg: 0.334  loss_rpn_cls: 0.02532  loss_rpn_loc: 0.02066    time: 0.4799  last_time: 0.4757  data_time: 0.0138  last_data_time: 0.0137   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:12:14 d2.utils.events]: \u001b[0m eta: 1:50:42  iter: 1119  total_loss: 0.8713  loss_cls: 0.4458  loss_box_reg: 0.3339  loss_rpn_cls: 0.03491  loss_rpn_loc: 0.01971    time: 0.4799  last_time: 0.4805  data_time: 0.0141  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:12:24 d2.utils.events]: \u001b[0m eta: 1:50:34  iter: 1139  total_loss: 0.8415  loss_cls: 0.4677  loss_box_reg: 0.3098  loss_rpn_cls: 0.0244  loss_rpn_loc: 0.028    time: 0.4799  last_time: 0.4819  data_time: 0.0152  last_data_time: 0.0174   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:12:34 d2.utils.events]: \u001b[0m eta: 1:50:25  iter: 1159  total_loss: 0.8196  loss_cls: 0.4604  loss_box_reg: 0.3031  loss_rpn_cls: 0.02839  loss_rpn_loc: 0.02824    time: 0.4799  last_time: 0.4791  data_time: 0.0157  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:12:43 d2.utils.events]: \u001b[0m eta: 1:50:15  iter: 1179  total_loss: 0.7306  loss_cls: 0.3907  loss_box_reg: 0.2723  loss_rpn_cls: 0.01792  loss_rpn_loc: 0.01569    time: 0.4799  last_time: 0.4791  data_time: 0.0158  last_data_time: 0.0134   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:12:53 d2.utils.events]: \u001b[0m eta: 1:50:06  iter: 1199  total_loss: 0.8937  loss_cls: 0.4496  loss_box_reg: 0.3358  loss_rpn_cls: 0.02541  loss_rpn_loc: 0.02533    time: 0.4800  last_time: 0.4758  data_time: 0.0155  last_data_time: 0.0138   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:13:02 d2.utils.events]: \u001b[0m eta: 1:49:56  iter: 1219  total_loss: 0.8666  loss_cls: 0.4923  loss_box_reg: 0.3242  loss_rpn_cls: 0.01898  loss_rpn_loc: 0.02779    time: 0.4799  last_time: 0.4742  data_time: 0.0151  last_data_time: 0.0136   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:13:12 d2.utils.events]: \u001b[0m eta: 1:49:46  iter: 1239  total_loss: 0.9208  loss_cls: 0.4811  loss_box_reg: 0.3433  loss_rpn_cls: 0.02464  loss_rpn_loc: 0.02919    time: 0.4799  last_time: 0.4751  data_time: 0.0162  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:13:22 d2.utils.events]: \u001b[0m eta: 1:49:36  iter: 1259  total_loss: 0.7111  loss_cls: 0.4029  loss_box_reg: 0.2485  loss_rpn_cls: 0.01518  loss_rpn_loc: 0.0177    time: 0.4800  last_time: 0.4773  data_time: 0.0154  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:13:31 d2.utils.events]: \u001b[0m eta: 1:49:27  iter: 1279  total_loss: 0.7945  loss_cls: 0.434  loss_box_reg: 0.2851  loss_rpn_cls: 0.01976  loss_rpn_loc: 0.03396    time: 0.4800  last_time: 0.4780  data_time: 0.0159  last_data_time: 0.0137   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:13:41 d2.utils.events]: \u001b[0m eta: 1:49:17  iter: 1299  total_loss: 0.7856  loss_cls: 0.409  loss_box_reg: 0.3539  loss_rpn_cls: 0.02213  loss_rpn_loc: 0.0311    time: 0.4800  last_time: 0.4924  data_time: 0.0153  last_data_time: 0.0198   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:13:51 d2.utils.events]: \u001b[0m eta: 1:49:08  iter: 1319  total_loss: 0.8091  loss_cls: 0.4465  loss_box_reg: 0.2809  loss_rpn_cls: 0.01743  loss_rpn_loc: 0.02362    time: 0.4800  last_time: 0.4882  data_time: 0.0152  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:14:00 d2.utils.events]: \u001b[0m eta: 1:48:58  iter: 1339  total_loss: 0.7489  loss_cls: 0.4335  loss_box_reg: 0.2975  loss_rpn_cls: 0.01911  loss_rpn_loc: 0.03064    time: 0.4800  last_time: 0.4784  data_time: 0.0156  last_data_time: 0.0149   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:14:10 d2.utils.events]: \u001b[0m eta: 1:48:48  iter: 1359  total_loss: 0.76  loss_cls: 0.4038  loss_box_reg: 0.314  loss_rpn_cls: 0.02588  loss_rpn_loc: 0.02523    time: 0.4800  last_time: 0.4774  data_time: 0.0162  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:14:19 d2.utils.events]: \u001b[0m eta: 1:48:38  iter: 1379  total_loss: 0.7956  loss_cls: 0.4098  loss_box_reg: 0.3079  loss_rpn_cls: 0.0172  loss_rpn_loc: 0.02666    time: 0.4800  last_time: 0.4761  data_time: 0.0161  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:14:29 d2.utils.events]: \u001b[0m eta: 1:48:29  iter: 1399  total_loss: 0.7712  loss_cls: 0.425  loss_box_reg: 0.2959  loss_rpn_cls: 0.01342  loss_rpn_loc: 0.01892    time: 0.4801  last_time: 0.4782  data_time: 0.0162  last_data_time: 0.0137   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:14:39 d2.utils.events]: \u001b[0m eta: 1:48:19  iter: 1419  total_loss: 0.8597  loss_cls: 0.4734  loss_box_reg: 0.2757  loss_rpn_cls: 0.02105  loss_rpn_loc: 0.03012    time: 0.4801  last_time: 0.4771  data_time: 0.0162  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:14:48 d2.utils.events]: \u001b[0m eta: 1:48:10  iter: 1439  total_loss: 0.7545  loss_cls: 0.4149  loss_box_reg: 0.2534  loss_rpn_cls: 0.02383  loss_rpn_loc: 0.03013    time: 0.4801  last_time: 0.4751  data_time: 0.0155  last_data_time: 0.0137   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:14:58 d2.utils.events]: \u001b[0m eta: 1:47:59  iter: 1459  total_loss: 0.805  loss_cls: 0.4373  loss_box_reg: 0.2977  loss_rpn_cls: 0.02188  loss_rpn_loc: 0.02143    time: 0.4801  last_time: 0.4763  data_time: 0.0152  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:15:08 d2.utils.events]: \u001b[0m eta: 1:47:49  iter: 1479  total_loss: 0.8047  loss_cls: 0.4162  loss_box_reg: 0.2911  loss_rpn_cls: 0.02528  loss_rpn_loc: 0.01478    time: 0.4801  last_time: 0.4761  data_time: 0.0165  last_data_time: 0.0161   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:15:17 d2.utils.events]: \u001b[0m eta: 1:47:38  iter: 1499  total_loss: 0.7522  loss_cls: 0.3565  loss_box_reg: 0.2687  loss_rpn_cls: 0.02154  loss_rpn_loc: 0.02834    time: 0.4800  last_time: 0.4771  data_time: 0.0141  last_data_time: 0.0136   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:15:27 d2.utils.events]: \u001b[0m eta: 1:47:29  iter: 1519  total_loss: 0.7099  loss_cls: 0.3929  loss_box_reg: 0.2776  loss_rpn_cls: 0.01671  loss_rpn_loc: 0.01887    time: 0.4800  last_time: 0.4772  data_time: 0.0155  last_data_time: 0.0138   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:15:36 d2.utils.events]: \u001b[0m eta: 1:47:19  iter: 1539  total_loss: 0.7057  loss_cls: 0.433  loss_box_reg: 0.2638  loss_rpn_cls: 0.02194  loss_rpn_loc: 0.02352    time: 0.4800  last_time: 0.4756  data_time: 0.0158  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:15:46 d2.utils.events]: \u001b[0m eta: 1:47:08  iter: 1559  total_loss: 0.771  loss_cls: 0.4045  loss_box_reg: 0.2992  loss_rpn_cls: 0.01605  loss_rpn_loc: 0.01384    time: 0.4800  last_time: 0.4782  data_time: 0.0149  last_data_time: 0.0154   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:15:55 d2.utils.events]: \u001b[0m eta: 1:46:58  iter: 1579  total_loss: 0.8285  loss_cls: 0.4135  loss_box_reg: 0.3005  loss_rpn_cls: 0.03216  loss_rpn_loc: 0.03686    time: 0.4800  last_time: 0.4965  data_time: 0.0152  last_data_time: 0.0214   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:16:05 d2.utils.events]: \u001b[0m eta: 1:46:49  iter: 1599  total_loss: 0.8824  loss_cls: 0.4159  loss_box_reg: 0.3098  loss_rpn_cls: 0.03172  loss_rpn_loc: 0.0281    time: 0.4800  last_time: 0.4748  data_time: 0.0154  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:16:15 d2.utils.events]: \u001b[0m eta: 1:46:40  iter: 1619  total_loss: 0.8115  loss_cls: 0.4204  loss_box_reg: 0.2854  loss_rpn_cls: 0.02361  loss_rpn_loc: 0.04099    time: 0.4800  last_time: 0.4820  data_time: 0.0147  last_data_time: 0.0148   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:16:24 d2.utils.events]: \u001b[0m eta: 1:46:31  iter: 1639  total_loss: 0.9126  loss_cls: 0.4768  loss_box_reg: 0.3406  loss_rpn_cls: 0.03152  loss_rpn_loc: 0.05435    time: 0.4800  last_time: 0.4760  data_time: 0.0141  last_data_time: 0.0137   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:16:34 d2.utils.events]: \u001b[0m eta: 1:46:22  iter: 1659  total_loss: 0.8064  loss_cls: 0.4425  loss_box_reg: 0.3264  loss_rpn_cls: 0.01384  loss_rpn_loc: 0.02785    time: 0.4799  last_time: 0.4777  data_time: 0.0143  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:16:43 d2.utils.events]: \u001b[0m eta: 1:46:12  iter: 1679  total_loss: 0.7838  loss_cls: 0.392  loss_box_reg: 0.262  loss_rpn_cls: 0.02472  loss_rpn_loc: 0.02539    time: 0.4799  last_time: 0.4816  data_time: 0.0145  last_data_time: 0.0137   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:16:53 d2.utils.events]: \u001b[0m eta: 1:46:03  iter: 1699  total_loss: 0.77  loss_cls: 0.4154  loss_box_reg: 0.3118  loss_rpn_cls: 0.01828  loss_rpn_loc: 0.03078    time: 0.4800  last_time: 0.4773  data_time: 0.0153  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:17:03 d2.utils.events]: \u001b[0m eta: 1:45:55  iter: 1719  total_loss: 0.7936  loss_cls: 0.4393  loss_box_reg: 0.3076  loss_rpn_cls: 0.02398  loss_rpn_loc: 0.0252    time: 0.4800  last_time: 0.4864  data_time: 0.0155  last_data_time: 0.0137   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:17:12 d2.utils.events]: \u001b[0m eta: 1:45:46  iter: 1739  total_loss: 0.9011  loss_cls: 0.476  loss_box_reg: 0.3087  loss_rpn_cls: 0.02932  loss_rpn_loc: 0.02771    time: 0.4800  last_time: 0.4828  data_time: 0.0145  last_data_time: 0.0138   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:17:22 d2.utils.events]: \u001b[0m eta: 1:45:37  iter: 1759  total_loss: 0.7924  loss_cls: 0.356  loss_box_reg: 0.3165  loss_rpn_cls: 0.02255  loss_rpn_loc: 0.0273    time: 0.4800  last_time: 0.4888  data_time: 0.0144  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:17:32 d2.utils.events]: \u001b[0m eta: 1:45:28  iter: 1779  total_loss: 0.7412  loss_cls: 0.4407  loss_box_reg: 0.2656  loss_rpn_cls: 0.01884  loss_rpn_loc: 0.01471    time: 0.4801  last_time: 0.4864  data_time: 0.0149  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:17:41 d2.utils.events]: \u001b[0m eta: 1:45:17  iter: 1799  total_loss: 0.6625  loss_cls: 0.3778  loss_box_reg: 0.2726  loss_rpn_cls: 0.01573  loss_rpn_loc: 0.02219    time: 0.4800  last_time: 0.4778  data_time: 0.0145  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:17:51 d2.utils.events]: \u001b[0m eta: 1:45:08  iter: 1819  total_loss: 0.6399  loss_cls: 0.3532  loss_box_reg: 0.2638  loss_rpn_cls: 0.01496  loss_rpn_loc: 0.01173    time: 0.4801  last_time: 0.4771  data_time: 0.0167  last_data_time: 0.0136   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:18:00 d2.utils.events]: \u001b[0m eta: 1:44:58  iter: 1839  total_loss: 0.7692  loss_cls: 0.4221  loss_box_reg: 0.283  loss_rpn_cls: 0.02207  loss_rpn_loc: 0.02041    time: 0.4801  last_time: 0.4779  data_time: 0.0154  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:18:10 d2.utils.events]: \u001b[0m eta: 1:44:49  iter: 1859  total_loss: 0.858  loss_cls: 0.4703  loss_box_reg: 0.305  loss_rpn_cls: 0.03039  loss_rpn_loc: 0.03446    time: 0.4801  last_time: 0.4793  data_time: 0.0154  last_data_time: 0.0163   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:18:20 d2.utils.events]: \u001b[0m eta: 1:44:39  iter: 1879  total_loss: 0.82  loss_cls: 0.3987  loss_box_reg: 0.329  loss_rpn_cls: 0.01865  loss_rpn_loc: 0.02743    time: 0.4801  last_time: 0.4776  data_time: 0.0160  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:18:29 d2.utils.events]: \u001b[0m eta: 1:44:29  iter: 1899  total_loss: 0.8125  loss_cls: 0.4676  loss_box_reg: 0.2782  loss_rpn_cls: 0.01719  loss_rpn_loc: 0.01976    time: 0.4801  last_time: 0.4832  data_time: 0.0146  last_data_time: 0.0198   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:18:39 d2.utils.events]: \u001b[0m eta: 1:44:20  iter: 1919  total_loss: 0.8301  loss_cls: 0.4397  loss_box_reg: 0.3136  loss_rpn_cls: 0.02078  loss_rpn_loc: 0.02248    time: 0.4801  last_time: 0.4793  data_time: 0.0146  last_data_time: 0.0162   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:18:49 d2.utils.events]: \u001b[0m eta: 1:44:10  iter: 1939  total_loss: 0.6304  loss_cls: 0.3621  loss_box_reg: 0.2314  loss_rpn_cls: 0.01573  loss_rpn_loc: 0.02679    time: 0.4801  last_time: 0.4781  data_time: 0.0154  last_data_time: 0.0138   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:18:58 d2.utils.events]: \u001b[0m eta: 1:44:01  iter: 1959  total_loss: 0.7219  loss_cls: 0.4262  loss_box_reg: 0.258  loss_rpn_cls: 0.01462  loss_rpn_loc: 0.02513    time: 0.4801  last_time: 0.4885  data_time: 0.0158  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:19:08 d2.utils.events]: \u001b[0m eta: 1:43:51  iter: 1979  total_loss: 0.7213  loss_cls: 0.3786  loss_box_reg: 0.2746  loss_rpn_cls: 0.02417  loss_rpn_loc: 0.0254    time: 0.4801  last_time: 0.4768  data_time: 0.0151  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:19:18 d2.utils.events]: \u001b[0m eta: 1:43:42  iter: 1999  total_loss: 0.7524  loss_cls: 0.4253  loss_box_reg: 0.2442  loss_rpn_cls: 0.02444  loss_rpn_loc: 0.03472    time: 0.4802  last_time: 0.4766  data_time: 0.0161  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:19:27 d2.utils.events]: \u001b[0m eta: 1:43:33  iter: 2019  total_loss: 0.8982  loss_cls: 0.5094  loss_box_reg: 0.3283  loss_rpn_cls: 0.03367  loss_rpn_loc: 0.04137    time: 0.4802  last_time: 0.4786  data_time: 0.0142  last_data_time: 0.0136   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:19:37 d2.utils.events]: \u001b[0m eta: 1:43:24  iter: 2039  total_loss: 0.7712  loss_cls: 0.4134  loss_box_reg: 0.2982  loss_rpn_cls: 0.02495  loss_rpn_loc: 0.02256    time: 0.4802  last_time: 0.4788  data_time: 0.0163  last_data_time: 0.0155   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:19:46 d2.utils.events]: \u001b[0m eta: 1:43:14  iter: 2059  total_loss: 0.7876  loss_cls: 0.4404  loss_box_reg: 0.3053  loss_rpn_cls: 0.0223  loss_rpn_loc: 0.03028    time: 0.4802  last_time: 0.4767  data_time: 0.0139  last_data_time: 0.0138   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:19:56 d2.utils.events]: \u001b[0m eta: 1:43:04  iter: 2079  total_loss: 0.8698  loss_cls: 0.4659  loss_box_reg: 0.3033  loss_rpn_cls: 0.02046  loss_rpn_loc: 0.02209    time: 0.4801  last_time: 0.4805  data_time: 0.0144  last_data_time: 0.0175   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:20:06 d2.utils.events]: \u001b[0m eta: 1:42:55  iter: 2099  total_loss: 0.8217  loss_cls: 0.4717  loss_box_reg: 0.3428  loss_rpn_cls: 0.01946  loss_rpn_loc: 0.02704    time: 0.4801  last_time: 0.4790  data_time: 0.0155  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:20:15 d2.utils.events]: \u001b[0m eta: 1:42:46  iter: 2119  total_loss: 0.7624  loss_cls: 0.4392  loss_box_reg: 0.2942  loss_rpn_cls: 0.02095  loss_rpn_loc: 0.0211    time: 0.4801  last_time: 0.4767  data_time: 0.0147  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:20:25 d2.utils.events]: \u001b[0m eta: 1:42:36  iter: 2139  total_loss: 0.8797  loss_cls: 0.4476  loss_box_reg: 0.3211  loss_rpn_cls: 0.02341  loss_rpn_loc: 0.04058    time: 0.4801  last_time: 0.4888  data_time: 0.0148  last_data_time: 0.0146   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:20:35 d2.utils.events]: \u001b[0m eta: 1:42:28  iter: 2159  total_loss: 0.7627  loss_cls: 0.4798  loss_box_reg: 0.2466  loss_rpn_cls: 0.02932  loss_rpn_loc: 0.02762    time: 0.4802  last_time: 0.4821  data_time: 0.0159  last_data_time: 0.0179   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:20:44 d2.utils.events]: \u001b[0m eta: 1:42:17  iter: 2179  total_loss: 0.8597  loss_cls: 0.4487  loss_box_reg: 0.3212  loss_rpn_cls: 0.038  loss_rpn_loc: 0.04316    time: 0.4802  last_time: 0.4912  data_time: 0.0146  last_data_time: 0.0173   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:20:54 d2.utils.events]: \u001b[0m eta: 1:42:07  iter: 2199  total_loss: 0.8097  loss_cls: 0.4149  loss_box_reg: 0.3035  loss_rpn_cls: 0.0362  loss_rpn_loc: 0.03343    time: 0.4802  last_time: 0.4872  data_time: 0.0147  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:21:03 d2.utils.events]: \u001b[0m eta: 1:41:59  iter: 2219  total_loss: 0.7583  loss_cls: 0.4479  loss_box_reg: 0.2605  loss_rpn_cls: 0.02804  loss_rpn_loc: 0.03129    time: 0.4802  last_time: 0.4784  data_time: 0.0159  last_data_time: 0.0175   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:21:13 d2.utils.events]: \u001b[0m eta: 1:41:49  iter: 2239  total_loss: 0.79  loss_cls: 0.4129  loss_box_reg: 0.2795  loss_rpn_cls: 0.02683  loss_rpn_loc: 0.03406    time: 0.4802  last_time: 0.4733  data_time: 0.0154  last_data_time: 0.0135   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:21:23 d2.utils.events]: \u001b[0m eta: 1:41:39  iter: 2259  total_loss: 0.7235  loss_cls: 0.3649  loss_box_reg: 0.272  loss_rpn_cls: 0.02543  loss_rpn_loc: 0.02056    time: 0.4802  last_time: 0.4766  data_time: 0.0149  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:21:32 d2.utils.events]: \u001b[0m eta: 1:41:29  iter: 2279  total_loss: 0.7758  loss_cls: 0.4342  loss_box_reg: 0.3076  loss_rpn_cls: 0.01431  loss_rpn_loc: 0.02623    time: 0.4802  last_time: 0.4811  data_time: 0.0153  last_data_time: 0.0178   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:21:42 d2.utils.events]: \u001b[0m eta: 1:41:20  iter: 2299  total_loss: 0.7498  loss_cls: 0.4262  loss_box_reg: 0.2545  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.02367    time: 0.4802  last_time: 0.4786  data_time: 0.0154  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:21:52 d2.utils.events]: \u001b[0m eta: 1:41:11  iter: 2319  total_loss: 0.6  loss_cls: 0.3549  loss_box_reg: 0.219  loss_rpn_cls: 0.01194  loss_rpn_loc: 0.01743    time: 0.4803  last_time: 0.4838  data_time: 0.0158  last_data_time: 0.0160   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:22:01 d2.utils.events]: \u001b[0m eta: 1:41:02  iter: 2339  total_loss: 0.7239  loss_cls: 0.3981  loss_box_reg: 0.2344  loss_rpn_cls: 0.01998  loss_rpn_loc: 0.01628    time: 0.4803  last_time: 0.4797  data_time: 0.0159  last_data_time: 0.0163   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:22:11 d2.utils.events]: \u001b[0m eta: 1:40:52  iter: 2359  total_loss: 0.6635  loss_cls: 0.3776  loss_box_reg: 0.2239  loss_rpn_cls: 0.01991  loss_rpn_loc: 0.03842    time: 0.4803  last_time: 0.4784  data_time: 0.0157  last_data_time: 0.0152   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:22:21 d2.utils.events]: \u001b[0m eta: 1:40:43  iter: 2379  total_loss: 0.6442  loss_cls: 0.3357  loss_box_reg: 0.2523  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.02029    time: 0.4803  last_time: 0.4807  data_time: 0.0153  last_data_time: 0.0154   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:22:30 d2.utils.events]: \u001b[0m eta: 1:40:34  iter: 2399  total_loss: 0.8663  loss_cls: 0.4613  loss_box_reg: 0.3223  loss_rpn_cls: 0.02859  loss_rpn_loc: 0.04018    time: 0.4803  last_time: 0.4791  data_time: 0.0148  last_data_time: 0.0152   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:22:40 d2.utils.events]: \u001b[0m eta: 1:40:24  iter: 2419  total_loss: 0.8141  loss_cls: 0.4502  loss_box_reg: 0.3  loss_rpn_cls: 0.02573  loss_rpn_loc: 0.02791    time: 0.4803  last_time: 0.4741  data_time: 0.0145  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:22:49 d2.utils.events]: \u001b[0m eta: 1:40:14  iter: 2439  total_loss: 0.673  loss_cls: 0.3862  loss_box_reg: 0.2447  loss_rpn_cls: 0.01492  loss_rpn_loc: 0.01506    time: 0.4803  last_time: 0.4728  data_time: 0.0163  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:22:59 d2.utils.events]: \u001b[0m eta: 1:40:04  iter: 2459  total_loss: 0.6476  loss_cls: 0.385  loss_box_reg: 0.2188  loss_rpn_cls: 0.0177  loss_rpn_loc: 0.0267    time: 0.4802  last_time: 0.4780  data_time: 0.0148  last_data_time: 0.0138   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:23:08 d2.utils.events]: \u001b[0m eta: 1:39:54  iter: 2479  total_loss: 0.7186  loss_cls: 0.3888  loss_box_reg: 0.2639  loss_rpn_cls: 0.02648  loss_rpn_loc: 0.03349    time: 0.4802  last_time: 0.4843  data_time: 0.0144  last_data_time: 0.0176   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:23:18 d2.utils.events]: \u001b[0m eta: 1:39:45  iter: 2499  total_loss: 0.8027  loss_cls: 0.4277  loss_box_reg: 0.2861  loss_rpn_cls: 0.02527  loss_rpn_loc: 0.02843    time: 0.4802  last_time: 0.4801  data_time: 0.0154  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:23:28 d2.utils.events]: \u001b[0m eta: 1:39:36  iter: 2519  total_loss: 0.7991  loss_cls: 0.3998  loss_box_reg: 0.2721  loss_rpn_cls: 0.02817  loss_rpn_loc: 0.03012    time: 0.4802  last_time: 0.4761  data_time: 0.0153  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:23:37 d2.utils.events]: \u001b[0m eta: 1:39:26  iter: 2539  total_loss: 0.6957  loss_cls: 0.3509  loss_box_reg: 0.2554  loss_rpn_cls: 0.02529  loss_rpn_loc: 0.05443    time: 0.4802  last_time: 0.4808  data_time: 0.0156  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:23:47 d2.utils.events]: \u001b[0m eta: 1:39:17  iter: 2559  total_loss: 0.6659  loss_cls: 0.3707  loss_box_reg: 0.2627  loss_rpn_cls: 0.02051  loss_rpn_loc: 0.02468    time: 0.4802  last_time: 0.4743  data_time: 0.0157  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:23:57 d2.utils.events]: \u001b[0m eta: 1:39:08  iter: 2579  total_loss: 0.6764  loss_cls: 0.3576  loss_box_reg: 0.2696  loss_rpn_cls: 0.02101  loss_rpn_loc: 0.02289    time: 0.4802  last_time: 0.4741  data_time: 0.0154  last_data_time: 0.0138   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:24:06 d2.utils.events]: \u001b[0m eta: 1:38:59  iter: 2599  total_loss: 0.8082  loss_cls: 0.3932  loss_box_reg: 0.317  loss_rpn_cls: 0.02303  loss_rpn_loc: 0.02936    time: 0.4802  last_time: 0.4775  data_time: 0.0143  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:24:16 d2.utils.events]: \u001b[0m eta: 1:38:48  iter: 2619  total_loss: 0.6827  loss_cls: 0.339  loss_box_reg: 0.239  loss_rpn_cls: 0.01727  loss_rpn_loc: 0.03123    time: 0.4802  last_time: 0.4760  data_time: 0.0146  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:24:25 d2.utils.events]: \u001b[0m eta: 1:38:39  iter: 2639  total_loss: 0.7169  loss_cls: 0.404  loss_box_reg: 0.2799  loss_rpn_cls: 0.01275  loss_rpn_loc: 0.0185    time: 0.4802  last_time: 0.4826  data_time: 0.0151  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:24:35 d2.utils.events]: \u001b[0m eta: 1:38:31  iter: 2659  total_loss: 0.7045  loss_cls: 0.3901  loss_box_reg: 0.2663  loss_rpn_cls: 0.01457  loss_rpn_loc: 0.02844    time: 0.4802  last_time: 0.4817  data_time: 0.0159  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:24:45 d2.utils.events]: \u001b[0m eta: 1:38:23  iter: 2679  total_loss: 0.8342  loss_cls: 0.4595  loss_box_reg: 0.2964  loss_rpn_cls: 0.01848  loss_rpn_loc: 0.02943    time: 0.4803  last_time: 0.4766  data_time: 0.0161  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:24:54 d2.utils.events]: \u001b[0m eta: 1:38:13  iter: 2699  total_loss: 0.7755  loss_cls: 0.3917  loss_box_reg: 0.3319  loss_rpn_cls: 0.02109  loss_rpn_loc: 0.02597    time: 0.4803  last_time: 0.4763  data_time: 0.0161  last_data_time: 0.0138   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:25:04 d2.utils.events]: \u001b[0m eta: 1:38:03  iter: 2719  total_loss: 0.5423  loss_cls: 0.2971  loss_box_reg: 0.1922  loss_rpn_cls: 0.008276  loss_rpn_loc: 0.01428    time: 0.4803  last_time: 0.4788  data_time: 0.0151  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:25:14 d2.utils.events]: \u001b[0m eta: 1:37:53  iter: 2739  total_loss: 0.7179  loss_cls: 0.378  loss_box_reg: 0.2802  loss_rpn_cls: 0.02101  loss_rpn_loc: 0.02785    time: 0.4803  last_time: 0.4861  data_time: 0.0152  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:25:23 d2.utils.events]: \u001b[0m eta: 1:37:42  iter: 2759  total_loss: 0.8542  loss_cls: 0.4871  loss_box_reg: 0.307  loss_rpn_cls: 0.02385  loss_rpn_loc: 0.04403    time: 0.4803  last_time: 0.4944  data_time: 0.0155  last_data_time: 0.0197   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:25:33 d2.utils.events]: \u001b[0m eta: 1:37:32  iter: 2779  total_loss: 0.6847  loss_cls: 0.385  loss_box_reg: 0.2546  loss_rpn_cls: 0.01909  loss_rpn_loc: 0.01968    time: 0.4803  last_time: 0.4751  data_time: 0.0156  last_data_time: 0.0137   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:25:42 d2.utils.events]: \u001b[0m eta: 1:37:23  iter: 2799  total_loss: 0.6907  loss_cls: 0.3727  loss_box_reg: 0.2669  loss_rpn_cls: 0.02258  loss_rpn_loc: 0.02452    time: 0.4803  last_time: 0.4756  data_time: 0.0147  last_data_time: 0.0138   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:25:52 d2.utils.events]: \u001b[0m eta: 1:37:13  iter: 2819  total_loss: 0.81  loss_cls: 0.4452  loss_box_reg: 0.3188  loss_rpn_cls: 0.0195  loss_rpn_loc: 0.02567    time: 0.4803  last_time: 0.4760  data_time: 0.0144  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:26:02 d2.utils.events]: \u001b[0m eta: 1:37:03  iter: 2839  total_loss: 0.7481  loss_cls: 0.4161  loss_box_reg: 0.2971  loss_rpn_cls: 0.01923  loss_rpn_loc: 0.02494    time: 0.4802  last_time: 0.4780  data_time: 0.0139  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:26:11 d2.utils.events]: \u001b[0m eta: 1:36:53  iter: 2859  total_loss: 0.5754  loss_cls: 0.298  loss_box_reg: 0.2301  loss_rpn_cls: 0.01729  loss_rpn_loc: 0.0123    time: 0.4802  last_time: 0.4800  data_time: 0.0159  last_data_time: 0.0170   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:26:21 d2.utils.events]: \u001b[0m eta: 1:36:44  iter: 2879  total_loss: 0.6157  loss_cls: 0.3722  loss_box_reg: 0.2146  loss_rpn_cls: 0.01454  loss_rpn_loc: 0.02738    time: 0.4802  last_time: 0.4820  data_time: 0.0159  last_data_time: 0.0169   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:26:30 d2.utils.events]: \u001b[0m eta: 1:36:34  iter: 2899  total_loss: 0.7963  loss_cls: 0.4145  loss_box_reg: 0.2972  loss_rpn_cls: 0.0289  loss_rpn_loc: 0.04274    time: 0.4802  last_time: 0.4800  data_time: 0.0148  last_data_time: 0.0163   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:26:40 d2.utils.events]: \u001b[0m eta: 1:36:25  iter: 2919  total_loss: 0.7701  loss_cls: 0.3793  loss_box_reg: 0.3203  loss_rpn_cls: 0.02189  loss_rpn_loc: 0.02993    time: 0.4803  last_time: 0.4875  data_time: 0.0166  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:26:50 d2.utils.events]: \u001b[0m eta: 1:36:16  iter: 2939  total_loss: 0.6986  loss_cls: 0.3406  loss_box_reg: 0.2499  loss_rpn_cls: 0.018  loss_rpn_loc: 0.02414    time: 0.4803  last_time: 0.4791  data_time: 0.0151  last_data_time: 0.0163   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:26:59 d2.utils.events]: \u001b[0m eta: 1:36:07  iter: 2959  total_loss: 0.6534  loss_cls: 0.38  loss_box_reg: 0.249  loss_rpn_cls: 0.01891  loss_rpn_loc: 0.0303    time: 0.4803  last_time: 0.4917  data_time: 0.0157  last_data_time: 0.0180   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:27:09 d2.utils.events]: \u001b[0m eta: 1:35:57  iter: 2979  total_loss: 0.7633  loss_cls: 0.398  loss_box_reg: 0.2916  loss_rpn_cls: 0.01909  loss_rpn_loc: 0.0224    time: 0.4803  last_time: 0.4734  data_time: 0.0147  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:27:19 d2.data.datasets.coco]: \u001b[0mLoaded 4871 images in COCO format from ../../dataset/test.json\n",
      "\u001b[32m[10/06 00:27:20 d2.data.build]: \u001b[0mDistribution of instances among all 10 categories:\n",
      "\u001b[36m|   category    | #instances   |  category   | #instances   |  category  | #instances   |\n",
      "|:-------------:|:-------------|:-----------:|:-------------|:----------:|:-------------|\n",
      "| General trash | 0            |    Paper    | 0            | Paper pack | 0            |\n",
      "|     Metal     | 0            |    Glass    | 0            |  Plastic   | 0            |\n",
      "|   Styrofoam   | 0            | Plastic bag | 0            |  Battery   | 0            |\n",
      "|   Clothing    | 0            |             |              |            |              |\n",
      "|     total     | 0            |             |              |            |              |\u001b[0m\n",
      "\u001b[32m[10/06 00:27:20 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[10/06 00:27:20 d2.data.common]: \u001b[0mSerializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>\n",
      "\u001b[32m[10/06 00:27:20 d2.data.common]: \u001b[0mSerializing 4871 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[10/06 00:27:20 d2.data.common]: \u001b[0mSerialized dataset takes 0.52 MiB\n",
      "\u001b[5m\u001b[31mWARNING\u001b[0m \u001b[32m[10/06 00:27:20 d2.evaluation.coco_evaluation]: \u001b[0mCOCO Evaluator instantiated using config, this is deprecated behavior. Please pass in explicit arguments instead.\n",
      "\u001b[32m[10/06 00:27:20 d2.evaluation.evaluator]: \u001b[0mStart inference on 4871 batches\n",
      "\u001b[32m[10/06 00:27:20 d2.evaluation.evaluator]: \u001b[0mInference done 11/4871. Dataloading: 0.0014 s/iter. Inference: 0.0440 s/iter. Eval: 0.0003 s/iter. Total: 0.0456 s/iter. ETA=0:03:41\n",
      "\u001b[32m[10/06 00:27:25 d2.evaluation.evaluator]: \u001b[0mInference done 127/4871. Dataloading: 0.0013 s/iter. Inference: 0.0418 s/iter. Eval: 0.0002 s/iter. Total: 0.0434 s/iter. ETA=0:03:25\n",
      "\u001b[32m[10/06 00:27:30 d2.evaluation.evaluator]: \u001b[0mInference done 237/4871. Dataloading: 0.0013 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0445 s/iter. ETA=0:03:26\n",
      "\u001b[32m[10/06 00:27:35 d2.evaluation.evaluator]: \u001b[0mInference done 349/4871. Dataloading: 0.0013 s/iter. Inference: 0.0429 s/iter. Eval: 0.0002 s/iter. Total: 0.0446 s/iter. ETA=0:03:21\n",
      "\u001b[32m[10/06 00:27:40 d2.evaluation.evaluator]: \u001b[0mInference done 461/4871. Dataloading: 0.0014 s/iter. Inference: 0.0430 s/iter. Eval: 0.0002 s/iter. Total: 0.0447 s/iter. ETA=0:03:16\n",
      "\u001b[32m[10/06 00:27:45 d2.evaluation.evaluator]: \u001b[0mInference done 570/4871. Dataloading: 0.0014 s/iter. Inference: 0.0433 s/iter. Eval: 0.0002 s/iter. Total: 0.0449 s/iter. ETA=0:03:13\n",
      "\u001b[32m[10/06 00:27:50 d2.evaluation.evaluator]: \u001b[0mInference done 683/4871. Dataloading: 0.0014 s/iter. Inference: 0.0431 s/iter. Eval: 0.0002 s/iter. Total: 0.0448 s/iter. ETA=0:03:07\n",
      "\u001b[32m[10/06 00:27:55 d2.evaluation.evaluator]: \u001b[0mInference done 798/4871. Dataloading: 0.0014 s/iter. Inference: 0.0430 s/iter. Eval: 0.0002 s/iter. Total: 0.0447 s/iter. ETA=0:03:01\n",
      "\u001b[32m[10/06 00:28:00 d2.evaluation.evaluator]: \u001b[0mInference done 914/4871. Dataloading: 0.0014 s/iter. Inference: 0.0428 s/iter. Eval: 0.0002 s/iter. Total: 0.0445 s/iter. ETA=0:02:55\n",
      "\u001b[32m[10/06 00:28:05 d2.evaluation.evaluator]: \u001b[0mInference done 1024/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0002 s/iter. Total: 0.0446 s/iter. ETA=0:02:51\n",
      "\u001b[32m[10/06 00:28:10 d2.evaluation.evaluator]: \u001b[0mInference done 1134/4871. Dataloading: 0.0014 s/iter. Inference: 0.0430 s/iter. Eval: 0.0002 s/iter. Total: 0.0447 s/iter. ETA=0:02:47\n",
      "\u001b[32m[10/06 00:28:16 d2.evaluation.evaluator]: \u001b[0mInference done 1245/4871. Dataloading: 0.0014 s/iter. Inference: 0.0431 s/iter. Eval: 0.0002 s/iter. Total: 0.0448 s/iter. ETA=0:02:42\n",
      "\u001b[32m[10/06 00:28:21 d2.evaluation.evaluator]: \u001b[0mInference done 1354/4871. Dataloading: 0.0014 s/iter. Inference: 0.0432 s/iter. Eval: 0.0002 s/iter. Total: 0.0449 s/iter. ETA=0:02:37\n",
      "\u001b[32m[10/06 00:28:26 d2.evaluation.evaluator]: \u001b[0mInference done 1463/4871. Dataloading: 0.0014 s/iter. Inference: 0.0433 s/iter. Eval: 0.0002 s/iter. Total: 0.0449 s/iter. ETA=0:02:33\n",
      "\u001b[32m[10/06 00:28:31 d2.evaluation.evaluator]: \u001b[0mInference done 1577/4871. Dataloading: 0.0014 s/iter. Inference: 0.0432 s/iter. Eval: 0.0002 s/iter. Total: 0.0449 s/iter. ETA=0:02:27\n",
      "\u001b[32m[10/06 00:28:36 d2.evaluation.evaluator]: \u001b[0mInference done 1690/4871. Dataloading: 0.0014 s/iter. Inference: 0.0431 s/iter. Eval: 0.0002 s/iter. Total: 0.0448 s/iter. ETA=0:02:22\n",
      "\u001b[32m[10/06 00:28:41 d2.evaluation.evaluator]: \u001b[0mInference done 1804/4871. Dataloading: 0.0014 s/iter. Inference: 0.0431 s/iter. Eval: 0.0002 s/iter. Total: 0.0448 s/iter. ETA=0:02:17\n",
      "\u001b[32m[10/06 00:28:46 d2.evaluation.evaluator]: \u001b[0mInference done 1915/4871. Dataloading: 0.0014 s/iter. Inference: 0.0431 s/iter. Eval: 0.0002 s/iter. Total: 0.0448 s/iter. ETA=0:02:12\n",
      "\u001b[32m[10/06 00:28:51 d2.evaluation.evaluator]: \u001b[0mInference done 2028/4871. Dataloading: 0.0014 s/iter. Inference: 0.0431 s/iter. Eval: 0.0002 s/iter. Total: 0.0448 s/iter. ETA=0:02:07\n",
      "\u001b[32m[10/06 00:28:56 d2.evaluation.evaluator]: \u001b[0mInference done 2137/4871. Dataloading: 0.0014 s/iter. Inference: 0.0431 s/iter. Eval: 0.0002 s/iter. Total: 0.0448 s/iter. ETA=0:02:02\n",
      "\u001b[32m[10/06 00:29:01 d2.evaluation.evaluator]: \u001b[0mInference done 2249/4871. Dataloading: 0.0014 s/iter. Inference: 0.0432 s/iter. Eval: 0.0002 s/iter. Total: 0.0448 s/iter. ETA=0:01:57\n",
      "\u001b[32m[10/06 00:29:06 d2.evaluation.evaluator]: \u001b[0mInference done 2360/4871. Dataloading: 0.0014 s/iter. Inference: 0.0432 s/iter. Eval: 0.0002 s/iter. Total: 0.0449 s/iter. ETA=0:01:52\n",
      "\u001b[32m[10/06 00:29:11 d2.evaluation.evaluator]: \u001b[0mInference done 2472/4871. Dataloading: 0.0014 s/iter. Inference: 0.0432 s/iter. Eval: 0.0002 s/iter. Total: 0.0449 s/iter. ETA=0:01:47\n",
      "\u001b[32m[10/06 00:29:16 d2.evaluation.evaluator]: \u001b[0mInference done 2584/4871. Dataloading: 0.0014 s/iter. Inference: 0.0432 s/iter. Eval: 0.0002 s/iter. Total: 0.0449 s/iter. ETA=0:01:42\n",
      "\u001b[32m[10/06 00:29:21 d2.evaluation.evaluator]: \u001b[0mInference done 2695/4871. Dataloading: 0.0014 s/iter. Inference: 0.0432 s/iter. Eval: 0.0002 s/iter. Total: 0.0449 s/iter. ETA=0:01:37\n",
      "\u001b[32m[10/06 00:29:26 d2.evaluation.evaluator]: \u001b[0mInference done 2811/4871. Dataloading: 0.0014 s/iter. Inference: 0.0431 s/iter. Eval: 0.0002 s/iter. Total: 0.0448 s/iter. ETA=0:01:32\n",
      "\u001b[32m[10/06 00:29:31 d2.evaluation.evaluator]: \u001b[0mInference done 2927/4871. Dataloading: 0.0014 s/iter. Inference: 0.0430 s/iter. Eval: 0.0002 s/iter. Total: 0.0447 s/iter. ETA=0:01:26\n",
      "\u001b[32m[10/06 00:29:36 d2.evaluation.evaluator]: \u001b[0mInference done 3042/4871. Dataloading: 0.0014 s/iter. Inference: 0.0430 s/iter. Eval: 0.0002 s/iter. Total: 0.0447 s/iter. ETA=0:01:21\n",
      "\u001b[32m[10/06 00:29:41 d2.evaluation.evaluator]: \u001b[0mInference done 3160/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0002 s/iter. Total: 0.0446 s/iter. ETA=0:01:16\n",
      "\u001b[32m[10/06 00:29:46 d2.evaluation.evaluator]: \u001b[0mInference done 3276/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0002 s/iter. Total: 0.0446 s/iter. ETA=0:01:11\n",
      "\u001b[32m[10/06 00:29:51 d2.evaluation.evaluator]: \u001b[0mInference done 3389/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:01:06\n",
      "\u001b[32m[10/06 00:29:56 d2.evaluation.evaluator]: \u001b[0mInference done 3502/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:01:01\n",
      "\u001b[32m[10/06 00:30:01 d2.evaluation.evaluator]: \u001b[0mInference done 3612/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:00:56\n",
      "\u001b[32m[10/06 00:30:06 d2.evaluation.evaluator]: \u001b[0mInference done 3728/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:00:50\n",
      "\u001b[32m[10/06 00:30:11 d2.evaluation.evaluator]: \u001b[0mInference done 3840/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:00:45\n",
      "\u001b[32m[10/06 00:30:16 d2.evaluation.evaluator]: \u001b[0mInference done 3953/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:00:40\n",
      "\u001b[32m[10/06 00:30:21 d2.evaluation.evaluator]: \u001b[0mInference done 4067/4871. Dataloading: 0.0014 s/iter. Inference: 0.0428 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:00:35\n",
      "\u001b[32m[10/06 00:30:26 d2.evaluation.evaluator]: \u001b[0mInference done 4174/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:00:31\n",
      "\u001b[32m[10/06 00:30:31 d2.evaluation.evaluator]: \u001b[0mInference done 4284/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:00:26\n",
      "\u001b[32m[10/06 00:30:36 d2.evaluation.evaluator]: \u001b[0mInference done 4396/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:00:21\n",
      "\u001b[32m[10/06 00:30:41 d2.evaluation.evaluator]: \u001b[0mInference done 4511/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:00:16\n",
      "\u001b[32m[10/06 00:30:46 d2.evaluation.evaluator]: \u001b[0mInference done 4624/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:00:11\n",
      "\u001b[32m[10/06 00:30:51 d2.evaluation.evaluator]: \u001b[0mInference done 4736/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:00:06\n",
      "\u001b[32m[10/06 00:30:56 d2.evaluation.evaluator]: \u001b[0mInference done 4845/4871. Dataloading: 0.0014 s/iter. Inference: 0.0429 s/iter. Eval: 0.0003 s/iter. Total: 0.0446 s/iter. ETA=0:00:01\n",
      "\u001b[32m[10/06 00:30:57 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:03:37.366587 (0.044670 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/06 00:30:57 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:03:29 (0.042959 s / iter per device, on 1 devices)\n",
      "\u001b[32m[10/06 00:30:58 d2.evaluation.coco_evaluation]: \u001b[0mPreparing results for COCO format ...\n",
      "\u001b[32m[10/06 00:30:58 d2.evaluation.coco_evaluation]: \u001b[0mSaving results to ./output_eval/coco_instances_results.json\n",
      "\u001b[32m[10/06 00:30:59 d2.evaluation.coco_evaluation]: \u001b[0mEvaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.52s)\n",
      "creating index...\n",
      "index created!\n",
      "\u001b[32m[10/06 00:31:00 d2.evaluation.fast_eval_api]: \u001b[0mEvaluate annotation type *bbox*\n",
      "\u001b[32m[10/06 00:31:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.evaluate() finished in 2.15 seconds.\n",
      "\u001b[32m[10/06 00:31:02 d2.evaluation.fast_eval_api]: \u001b[0mAccumulating evaluation results...\n",
      "\u001b[32m[10/06 00:31:02 d2.evaluation.fast_eval_api]: \u001b[0mCOCOeval_opt.accumulate() finished in 0.26 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "\u001b[32m[10/06 00:31:02 d2.evaluation.coco_evaluation]: \u001b[0mEvaluation results for bbox: \n",
      "|  AP  |  AP50  |  AP75  |  APs  |  APm  |  APl  |\n",
      "|:----:|:------:|:------:|:-----:|:-----:|:-----:|\n",
      "| nan  |  nan   |  nan   |  nan  |  nan  |  nan  |\n",
      "\u001b[32m[10/06 00:31:02 d2.evaluation.coco_evaluation]: \u001b[0mSome metrics cannot be computed and is shown as NaN.\n",
      "\u001b[32m[10/06 00:31:02 d2.evaluation.coco_evaluation]: \u001b[0mPer-category bbox AP: \n",
      "| category      | AP   | category    | AP   | category   | AP   |\n",
      "|:--------------|:-----|:------------|:-----|:-----------|:-----|\n",
      "| General trash | nan  | Paper       | nan  | Paper pack | nan  |\n",
      "| Metal         | nan  | Glass       | nan  | Plastic    | nan  |\n",
      "| Styrofoam     | nan  | Plastic bag | nan  | Battery    | nan  |\n",
      "| Clothing      | nan  |             |      |            |      |\n",
      "\u001b[32m[10/06 00:31:02 d2.engine.defaults]: \u001b[0mEvaluation results for coco_trash_test in csv format:\n",
      "\u001b[32m[10/06 00:31:02 d2.evaluation.testing]: \u001b[0mcopypaste: Task: bbox\n",
      "\u001b[32m[10/06 00:31:02 d2.evaluation.testing]: \u001b[0mcopypaste: AP,AP50,AP75,APs,APm,APl\n",
      "\u001b[32m[10/06 00:31:02 d2.evaluation.testing]: \u001b[0mcopypaste: nan,nan,nan,nan,nan,nan\n",
      "\u001b[32m[10/06 00:31:02 d2.utils.events]: \u001b[0m eta: 1:35:46  iter: 2999  total_loss: 0.785  loss_cls: 0.4296  loss_box_reg: 0.2902  loss_rpn_cls: 0.02136  loss_rpn_loc: 0.02848    time: 0.4803  last_time: 0.4798  data_time: 0.0161  last_data_time: 0.0152   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:31:12 d2.utils.events]: \u001b[0m eta: 1:35:38  iter: 3019  total_loss: 0.7714  loss_cls: 0.4119  loss_box_reg: 0.2926  loss_rpn_cls: 0.01606  loss_rpn_loc: 0.0188    time: 0.4803  last_time: 0.4774  data_time: 0.0158  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:31:22 d2.utils.events]: \u001b[0m eta: 1:35:28  iter: 3039  total_loss: 0.7257  loss_cls: 0.406  loss_box_reg: 0.2553  loss_rpn_cls: 0.0102  loss_rpn_loc: 0.02884    time: 0.4803  last_time: 0.4863  data_time: 0.0152  last_data_time: 0.0246   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:31:31 d2.utils.events]: \u001b[0m eta: 1:35:19  iter: 3059  total_loss: 0.6802  loss_cls: 0.382  loss_box_reg: 0.3171  loss_rpn_cls: 0.01293  loss_rpn_loc: 0.01392    time: 0.4803  last_time: 0.4876  data_time: 0.0151  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:31:41 d2.utils.events]: \u001b[0m eta: 1:35:10  iter: 3079  total_loss: 0.8079  loss_cls: 0.4297  loss_box_reg: 0.2923  loss_rpn_cls: 0.014  loss_rpn_loc: 0.017    time: 0.4803  last_time: 0.4785  data_time: 0.0143  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:31:51 d2.utils.events]: \u001b[0m eta: 1:35:01  iter: 3099  total_loss: 0.7712  loss_cls: 0.4172  loss_box_reg: 0.2726  loss_rpn_cls: 0.02384  loss_rpn_loc: 0.02548    time: 0.4803  last_time: 0.4770  data_time: 0.0155  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:32:00 d2.utils.events]: \u001b[0m eta: 1:34:51  iter: 3119  total_loss: 0.7436  loss_cls: 0.4423  loss_box_reg: 0.2753  loss_rpn_cls: 0.02829  loss_rpn_loc: 0.02434    time: 0.4803  last_time: 0.4763  data_time: 0.0155  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:32:10 d2.utils.events]: \u001b[0m eta: 1:34:41  iter: 3139  total_loss: 0.7312  loss_cls: 0.3683  loss_box_reg: 0.268  loss_rpn_cls: 0.01866  loss_rpn_loc: 0.02924    time: 0.4803  last_time: 0.4773  data_time: 0.0153  last_data_time: 0.0154   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:32:19 d2.utils.events]: \u001b[0m eta: 1:34:31  iter: 3159  total_loss: 0.6575  loss_cls: 0.3449  loss_box_reg: 0.2059  loss_rpn_cls: 0.01765  loss_rpn_loc: 0.01851    time: 0.4803  last_time: 0.4875  data_time: 0.0163  last_data_time: 0.0217   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:32:29 d2.utils.events]: \u001b[0m eta: 1:34:22  iter: 3179  total_loss: 0.7143  loss_cls: 0.3918  loss_box_reg: 0.2777  loss_rpn_cls: 0.02113  loss_rpn_loc: 0.02651    time: 0.4803  last_time: 0.4877  data_time: 0.0163  last_data_time: 0.0175   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:32:39 d2.utils.events]: \u001b[0m eta: 1:34:12  iter: 3199  total_loss: 0.873  loss_cls: 0.4781  loss_box_reg: 0.3085  loss_rpn_cls: 0.02467  loss_rpn_loc: 0.03275    time: 0.4803  last_time: 0.4817  data_time: 0.0144  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:32:48 d2.utils.events]: \u001b[0m eta: 1:34:02  iter: 3219  total_loss: 0.5807  loss_cls: 0.3414  loss_box_reg: 0.2288  loss_rpn_cls: 0.0106  loss_rpn_loc: 0.01582    time: 0.4803  last_time: 0.4729  data_time: 0.0145  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:32:58 d2.utils.events]: \u001b[0m eta: 1:33:52  iter: 3239  total_loss: 0.5602  loss_cls: 0.2936  loss_box_reg: 0.2021  loss_rpn_cls: 0.02031  loss_rpn_loc: 0.0241    time: 0.4802  last_time: 0.4742  data_time: 0.0151  last_data_time: 0.0137   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:33:07 d2.utils.events]: \u001b[0m eta: 1:33:43  iter: 3259  total_loss: 0.6168  loss_cls: 0.3361  loss_box_reg: 0.2264  loss_rpn_cls: 0.01648  loss_rpn_loc: 0.01561    time: 0.4802  last_time: 0.4731  data_time: 0.0156  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:33:17 d2.utils.events]: \u001b[0m eta: 1:33:34  iter: 3279  total_loss: 0.6788  loss_cls: 0.3668  loss_box_reg: 0.2541  loss_rpn_cls: 0.01967  loss_rpn_loc: 0.02794    time: 0.4802  last_time: 0.4787  data_time: 0.0158  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:33:26 d2.utils.events]: \u001b[0m eta: 1:33:24  iter: 3299  total_loss: 0.733  loss_cls: 0.3834  loss_box_reg: 0.2608  loss_rpn_cls: 0.02128  loss_rpn_loc: 0.02459    time: 0.4802  last_time: 0.4755  data_time: 0.0148  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:33:36 d2.utils.events]: \u001b[0m eta: 1:33:13  iter: 3319  total_loss: 0.6283  loss_cls: 0.3537  loss_box_reg: 0.2163  loss_rpn_cls: 0.01981  loss_rpn_loc: 0.01768    time: 0.4802  last_time: 0.4754  data_time: 0.0150  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:33:46 d2.utils.events]: \u001b[0m eta: 1:33:04  iter: 3339  total_loss: 0.7337  loss_cls: 0.4071  loss_box_reg: 0.2649  loss_rpn_cls: 0.01648  loss_rpn_loc: 0.03231    time: 0.4802  last_time: 0.4813  data_time: 0.0165  last_data_time: 0.0167   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:33:55 d2.utils.events]: \u001b[0m eta: 1:32:55  iter: 3359  total_loss: 0.7815  loss_cls: 0.433  loss_box_reg: 0.3296  loss_rpn_cls: 0.02516  loss_rpn_loc: 0.03986    time: 0.4803  last_time: 0.4769  data_time: 0.0162  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:34:05 d2.utils.events]: \u001b[0m eta: 1:32:46  iter: 3379  total_loss: 0.6737  loss_cls: 0.3531  loss_box_reg: 0.2378  loss_rpn_cls: 0.01043  loss_rpn_loc: 0.01382    time: 0.4803  last_time: 0.4824  data_time: 0.0150  last_data_time: 0.0159   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:34:15 d2.utils.events]: \u001b[0m eta: 1:32:36  iter: 3399  total_loss: 0.6228  loss_cls: 0.3584  loss_box_reg: 0.2245  loss_rpn_cls: 0.01703  loss_rpn_loc: 0.02713    time: 0.4803  last_time: 0.4791  data_time: 0.0158  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:34:24 d2.utils.events]: \u001b[0m eta: 1:32:28  iter: 3419  total_loss: 0.6494  loss_cls: 0.3349  loss_box_reg: 0.2821  loss_rpn_cls: 0.01682  loss_rpn_loc: 0.02518    time: 0.4803  last_time: 0.4760  data_time: 0.0159  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:34:34 d2.utils.events]: \u001b[0m eta: 1:32:18  iter: 3439  total_loss: 0.653  loss_cls: 0.3855  loss_box_reg: 0.2533  loss_rpn_cls: 0.01701  loss_rpn_loc: 0.01107    time: 0.4803  last_time: 0.4789  data_time: 0.0150  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:34:44 d2.utils.events]: \u001b[0m eta: 1:32:09  iter: 3459  total_loss: 0.7149  loss_cls: 0.3696  loss_box_reg: 0.2607  loss_rpn_cls: 0.0207  loss_rpn_loc: 0.03143    time: 0.4803  last_time: 0.4801  data_time: 0.0171  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:34:53 d2.utils.events]: \u001b[0m eta: 1:32:00  iter: 3479  total_loss: 0.6159  loss_cls: 0.344  loss_box_reg: 0.2249  loss_rpn_cls: 0.01563  loss_rpn_loc: 0.01226    time: 0.4803  last_time: 0.4775  data_time: 0.0150  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:35:03 d2.utils.events]: \u001b[0m eta: 1:31:50  iter: 3499  total_loss: 0.5818  loss_cls: 0.3673  loss_box_reg: 0.2515  loss_rpn_cls: 0.0136  loss_rpn_loc: 0.01383    time: 0.4803  last_time: 0.4750  data_time: 0.0150  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:35:13 d2.utils.events]: \u001b[0m eta: 1:31:40  iter: 3519  total_loss: 0.67  loss_cls: 0.3717  loss_box_reg: 0.2872  loss_rpn_cls: 0.01984  loss_rpn_loc: 0.01555    time: 0.4803  last_time: 0.4793  data_time: 0.0158  last_data_time: 0.0138   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:35:22 d2.utils.events]: \u001b[0m eta: 1:31:30  iter: 3539  total_loss: 0.7509  loss_cls: 0.3977  loss_box_reg: 0.3057  loss_rpn_cls: 0.01634  loss_rpn_loc: 0.02359    time: 0.4803  last_time: 0.4802  data_time: 0.0145  last_data_time: 0.0154   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:35:32 d2.utils.events]: \u001b[0m eta: 1:31:21  iter: 3559  total_loss: 0.7699  loss_cls: 0.412  loss_box_reg: 0.2402  loss_rpn_cls: 0.01775  loss_rpn_loc: 0.02382    time: 0.4803  last_time: 0.4783  data_time: 0.0161  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:35:42 d2.utils.events]: \u001b[0m eta: 1:31:12  iter: 3579  total_loss: 0.8418  loss_cls: 0.4234  loss_box_reg: 0.328  loss_rpn_cls: 0.02531  loss_rpn_loc: 0.03648    time: 0.4804  last_time: 0.4776  data_time: 0.0158  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:35:51 d2.utils.events]: \u001b[0m eta: 1:31:03  iter: 3599  total_loss: 0.7587  loss_cls: 0.4233  loss_box_reg: 0.2783  loss_rpn_cls: 0.0202  loss_rpn_loc: 0.02677    time: 0.4804  last_time: 0.4812  data_time: 0.0150  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:36:01 d2.utils.events]: \u001b[0m eta: 1:30:55  iter: 3619  total_loss: 0.5777  loss_cls: 0.3255  loss_box_reg: 0.2395  loss_rpn_cls: 0.01763  loss_rpn_loc: 0.03611    time: 0.4804  last_time: 0.4816  data_time: 0.0147  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:36:11 d2.utils.events]: \u001b[0m eta: 1:30:46  iter: 3639  total_loss: 0.7981  loss_cls: 0.3935  loss_box_reg: 0.2758  loss_rpn_cls: 0.02114  loss_rpn_loc: 0.02455    time: 0.4804  last_time: 0.4783  data_time: 0.0157  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:36:20 d2.utils.events]: \u001b[0m eta: 1:30:36  iter: 3659  total_loss: 0.697  loss_cls: 0.3648  loss_box_reg: 0.2744  loss_rpn_cls: 0.01908  loss_rpn_loc: 0.02909    time: 0.4804  last_time: 0.4822  data_time: 0.0163  last_data_time: 0.0159   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:36:30 d2.utils.events]: \u001b[0m eta: 1:30:25  iter: 3679  total_loss: 0.7735  loss_cls: 0.3885  loss_box_reg: 0.3105  loss_rpn_cls: 0.01746  loss_rpn_loc: 0.04053    time: 0.4804  last_time: 0.4744  data_time: 0.0157  last_data_time: 0.0146   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:36:39 d2.utils.events]: \u001b[0m eta: 1:30:15  iter: 3699  total_loss: 0.6507  loss_cls: 0.335  loss_box_reg: 0.2464  loss_rpn_cls: 0.0108  loss_rpn_loc: 0.01796    time: 0.4804  last_time: 0.4750  data_time: 0.0145  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:36:49 d2.utils.events]: \u001b[0m eta: 1:30:05  iter: 3719  total_loss: 0.5615  loss_cls: 0.3477  loss_box_reg: 0.1964  loss_rpn_cls: 0.006511  loss_rpn_loc: 0.01418    time: 0.4804  last_time: 0.4810  data_time: 0.0150  last_data_time: 0.0176   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:36:59 d2.utils.events]: \u001b[0m eta: 1:29:56  iter: 3739  total_loss: 0.6184  loss_cls: 0.3183  loss_box_reg: 0.2482  loss_rpn_cls: 0.01507  loss_rpn_loc: 0.0259    time: 0.4804  last_time: 0.4773  data_time: 0.0149  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:37:08 d2.utils.events]: \u001b[0m eta: 1:29:46  iter: 3759  total_loss: 0.6883  loss_cls: 0.3505  loss_box_reg: 0.2523  loss_rpn_cls: 0.02231  loss_rpn_loc: 0.02163    time: 0.4804  last_time: 0.4770  data_time: 0.0148  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:37:18 d2.utils.events]: \u001b[0m eta: 1:29:36  iter: 3779  total_loss: 0.6177  loss_cls: 0.351  loss_box_reg: 0.2401  loss_rpn_cls: 0.0224  loss_rpn_loc: 0.02724    time: 0.4804  last_time: 0.4781  data_time: 0.0155  last_data_time: 0.0138   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:37:27 d2.utils.events]: \u001b[0m eta: 1:29:27  iter: 3799  total_loss: 0.6848  loss_cls: 0.3587  loss_box_reg: 0.2481  loss_rpn_cls: 0.01363  loss_rpn_loc: 0.01914    time: 0.4804  last_time: 0.4780  data_time: 0.0153  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:37:37 d2.utils.events]: \u001b[0m eta: 1:29:17  iter: 3819  total_loss: 0.575  loss_cls: 0.3161  loss_box_reg: 0.2179  loss_rpn_cls: 0.01943  loss_rpn_loc: 0.02796    time: 0.4804  last_time: 0.4791  data_time: 0.0155  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:37:47 d2.utils.events]: \u001b[0m eta: 1:29:08  iter: 3839  total_loss: 0.5413  loss_cls: 0.2912  loss_box_reg: 0.2134  loss_rpn_cls: 0.009339  loss_rpn_loc: 0.0165    time: 0.4804  last_time: 0.4788  data_time: 0.0159  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:37:56 d2.utils.events]: \u001b[0m eta: 1:28:59  iter: 3859  total_loss: 0.6759  loss_cls: 0.3555  loss_box_reg: 0.2923  loss_rpn_cls: 0.0214  loss_rpn_loc: 0.02609    time: 0.4804  last_time: 0.4873  data_time: 0.0142  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:38:06 d2.utils.events]: \u001b[0m eta: 1:28:50  iter: 3879  total_loss: 0.5744  loss_cls: 0.3068  loss_box_reg: 0.2326  loss_rpn_cls: 0.01483  loss_rpn_loc: 0.01547    time: 0.4804  last_time: 0.4787  data_time: 0.0174  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:38:16 d2.utils.events]: \u001b[0m eta: 1:28:40  iter: 3899  total_loss: 0.707  loss_cls: 0.3594  loss_box_reg: 0.2757  loss_rpn_cls: 0.01403  loss_rpn_loc: 0.01956    time: 0.4804  last_time: 0.4740  data_time: 0.0149  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:38:25 d2.utils.events]: \u001b[0m eta: 1:28:30  iter: 3919  total_loss: 0.6018  loss_cls: 0.3388  loss_box_reg: 0.2215  loss_rpn_cls: 0.02219  loss_rpn_loc: 0.01944    time: 0.4804  last_time: 0.4789  data_time: 0.0153  last_data_time: 0.0154   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:38:35 d2.utils.events]: \u001b[0m eta: 1:28:20  iter: 3939  total_loss: 0.6738  loss_cls: 0.3171  loss_box_reg: 0.2623  loss_rpn_cls: 0.02157  loss_rpn_loc: 0.02937    time: 0.4804  last_time: 0.4811  data_time: 0.0150  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:38:44 d2.utils.events]: \u001b[0m eta: 1:28:11  iter: 3959  total_loss: 0.6565  loss_cls: 0.3658  loss_box_reg: 0.2344  loss_rpn_cls: 0.01807  loss_rpn_loc: 0.02648    time: 0.4804  last_time: 0.4805  data_time: 0.0147  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:38:54 d2.utils.events]: \u001b[0m eta: 1:28:02  iter: 3979  total_loss: 0.5877  loss_cls: 0.29  loss_box_reg: 0.229  loss_rpn_cls: 0.0157  loss_rpn_loc: 0.027    time: 0.4804  last_time: 0.4929  data_time: 0.0150  last_data_time: 0.0175   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:39:04 d2.utils.events]: \u001b[0m eta: 1:27:53  iter: 3999  total_loss: 0.5208  loss_cls: 0.2693  loss_box_reg: 0.1637  loss_rpn_cls: 0.01164  loss_rpn_loc: 0.02115    time: 0.4804  last_time: 0.4794  data_time: 0.0150  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:39:13 d2.utils.events]: \u001b[0m eta: 1:27:44  iter: 4019  total_loss: 0.572  loss_cls: 0.3332  loss_box_reg: 0.2124  loss_rpn_cls: 0.01672  loss_rpn_loc: 0.02383    time: 0.4805  last_time: 0.4880  data_time: 0.0156  last_data_time: 0.0145   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:39:23 d2.utils.events]: \u001b[0m eta: 1:27:34  iter: 4039  total_loss: 0.5795  loss_cls: 0.3912  loss_box_reg: 0.2168  loss_rpn_cls: 0.01129  loss_rpn_loc: 0.01121    time: 0.4805  last_time: 0.4933  data_time: 0.0161  last_data_time: 0.0289   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:39:33 d2.utils.events]: \u001b[0m eta: 1:27:25  iter: 4059  total_loss: 0.7643  loss_cls: 0.3844  loss_box_reg: 0.2756  loss_rpn_cls: 0.02115  loss_rpn_loc: 0.0289    time: 0.4805  last_time: 0.4902  data_time: 0.0148  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:39:42 d2.utils.events]: \u001b[0m eta: 1:27:16  iter: 4079  total_loss: 0.5889  loss_cls: 0.3278  loss_box_reg: 0.2236  loss_rpn_cls: 0.01557  loss_rpn_loc: 0.01705    time: 0.4805  last_time: 0.4876  data_time: 0.0151  last_data_time: 0.0143   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:39:52 d2.utils.events]: \u001b[0m eta: 1:27:06  iter: 4099  total_loss: 0.7216  loss_cls: 0.3628  loss_box_reg: 0.2776  loss_rpn_cls: 0.01475  loss_rpn_loc: 0.019    time: 0.4805  last_time: 0.4785  data_time: 0.0152  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:40:02 d2.utils.events]: \u001b[0m eta: 1:26:57  iter: 4119  total_loss: 0.77  loss_cls: 0.4124  loss_box_reg: 0.3117  loss_rpn_cls: 0.01404  loss_rpn_loc: 0.0343    time: 0.4805  last_time: 0.4817  data_time: 0.0153  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:40:11 d2.utils.events]: \u001b[0m eta: 1:26:47  iter: 4139  total_loss: 0.728  loss_cls: 0.3643  loss_box_reg: 0.2631  loss_rpn_cls: 0.01494  loss_rpn_loc: 0.02588    time: 0.4805  last_time: 0.4856  data_time: 0.0150  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:40:21 d2.utils.events]: \u001b[0m eta: 1:26:38  iter: 4159  total_loss: 0.6472  loss_cls: 0.3601  loss_box_reg: 0.2666  loss_rpn_cls: 0.01857  loss_rpn_loc: 0.02181    time: 0.4805  last_time: 0.4882  data_time: 0.0161  last_data_time: 0.0200   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:40:31 d2.utils.events]: \u001b[0m eta: 1:26:30  iter: 4179  total_loss: 0.6572  loss_cls: 0.358  loss_box_reg: 0.2793  loss_rpn_cls: 0.02089  loss_rpn_loc: 0.01724    time: 0.4805  last_time: 0.4801  data_time: 0.0163  last_data_time: 0.0147   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:40:40 d2.utils.events]: \u001b[0m eta: 1:26:20  iter: 4199  total_loss: 0.7741  loss_cls: 0.3871  loss_box_reg: 0.2623  loss_rpn_cls: 0.02508  loss_rpn_loc: 0.0319    time: 0.4805  last_time: 0.4818  data_time: 0.0153  last_data_time: 0.0152   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:40:50 d2.utils.events]: \u001b[0m eta: 1:26:13  iter: 4219  total_loss: 0.5583  loss_cls: 0.3175  loss_box_reg: 0.2238  loss_rpn_cls: 0.01296  loss_rpn_loc: 0.02343    time: 0.4805  last_time: 0.4827  data_time: 0.0162  last_data_time: 0.0150   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:41:00 d2.utils.events]: \u001b[0m eta: 1:26:04  iter: 4239  total_loss: 0.6674  loss_cls: 0.3762  loss_box_reg: 0.2573  loss_rpn_cls: 0.01887  loss_rpn_loc: 0.02832    time: 0.4805  last_time: 0.4875  data_time: 0.0162  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:41:09 d2.utils.events]: \u001b[0m eta: 1:25:55  iter: 4259  total_loss: 0.6615  loss_cls: 0.3384  loss_box_reg: 0.2624  loss_rpn_cls: 0.01892  loss_rpn_loc: 0.02177    time: 0.4806  last_time: 0.4847  data_time: 0.0160  last_data_time: 0.0234   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:41:19 d2.utils.events]: \u001b[0m eta: 1:25:45  iter: 4279  total_loss: 0.6764  loss_cls: 0.3681  loss_box_reg: 0.266  loss_rpn_cls: 0.01749  loss_rpn_loc: 0.02526    time: 0.4806  last_time: 0.4796  data_time: 0.0153  last_data_time: 0.0166   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:41:29 d2.utils.events]: \u001b[0m eta: 1:25:36  iter: 4299  total_loss: 0.5241  loss_cls: 0.2828  loss_box_reg: 0.2142  loss_rpn_cls: 0.01865  loss_rpn_loc: 0.02844    time: 0.4806  last_time: 0.4806  data_time: 0.0155  last_data_time: 0.0175   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:41:38 d2.utils.events]: \u001b[0m eta: 1:25:27  iter: 4319  total_loss: 0.5643  loss_cls: 0.3216  loss_box_reg: 0.2372  loss_rpn_cls: 0.01593  loss_rpn_loc: 0.03459    time: 0.4806  last_time: 0.4807  data_time: 0.0170  last_data_time: 0.0178   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:41:48 d2.utils.events]: \u001b[0m eta: 1:25:17  iter: 4339  total_loss: 0.6646  loss_cls: 0.3373  loss_box_reg: 0.228  loss_rpn_cls: 0.01561  loss_rpn_loc: 0.01897    time: 0.4806  last_time: 0.4812  data_time: 0.0163  last_data_time: 0.0164   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:41:58 d2.utils.events]: \u001b[0m eta: 1:25:07  iter: 4359  total_loss: 0.6402  loss_cls: 0.3641  loss_box_reg: 0.2421  loss_rpn_cls: 0.009745  loss_rpn_loc: 0.01217    time: 0.4806  last_time: 0.4754  data_time: 0.0175  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:42:07 d2.utils.events]: \u001b[0m eta: 1:24:57  iter: 4379  total_loss: 0.6286  loss_cls: 0.3284  loss_box_reg: 0.2662  loss_rpn_cls: 0.01673  loss_rpn_loc: 0.02145    time: 0.4806  last_time: 0.4861  data_time: 0.0155  last_data_time: 0.0138   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:42:17 d2.utils.events]: \u001b[0m eta: 1:24:47  iter: 4399  total_loss: 0.7963  loss_cls: 0.4023  loss_box_reg: 0.2899  loss_rpn_cls: 0.02029  loss_rpn_loc: 0.04406    time: 0.4806  last_time: 0.4787  data_time: 0.0145  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:42:26 d2.utils.events]: \u001b[0m eta: 1:24:37  iter: 4419  total_loss: 0.6712  loss_cls: 0.3261  loss_box_reg: 0.2902  loss_rpn_cls: 0.02462  loss_rpn_loc: 0.04263    time: 0.4806  last_time: 0.4766  data_time: 0.0143  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:42:36 d2.utils.events]: \u001b[0m eta: 1:24:28  iter: 4439  total_loss: 0.6846  loss_cls: 0.4025  loss_box_reg: 0.2315  loss_rpn_cls: 0.01513  loss_rpn_loc: 0.016    time: 0.4806  last_time: 0.4778  data_time: 0.0158  last_data_time: 0.0140   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:42:46 d2.utils.events]: \u001b[0m eta: 1:24:18  iter: 4459  total_loss: 0.8227  loss_cls: 0.409  loss_box_reg: 0.3221  loss_rpn_cls: 0.02154  loss_rpn_loc: 0.0339    time: 0.4806  last_time: 0.4807  data_time: 0.0157  last_data_time: 0.0176   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:42:55 d2.utils.events]: \u001b[0m eta: 1:24:08  iter: 4479  total_loss: 0.6113  loss_cls: 0.3774  loss_box_reg: 0.2319  loss_rpn_cls: 0.01496  loss_rpn_loc: 0.01845    time: 0.4806  last_time: 0.4781  data_time: 0.0154  last_data_time: 0.0139   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:43:05 d2.utils.events]: \u001b[0m eta: 1:23:59  iter: 4499  total_loss: 0.6318  loss_cls: 0.3315  loss_box_reg: 0.2553  loss_rpn_cls: 0.01817  loss_rpn_loc: 0.02556    time: 0.4806  last_time: 0.4854  data_time: 0.0147  last_data_time: 0.0207   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:43:15 d2.utils.events]: \u001b[0m eta: 1:23:49  iter: 4519  total_loss: 0.6448  loss_cls: 0.3452  loss_box_reg: 0.2539  loss_rpn_cls: 0.01354  loss_rpn_loc: 0.01339    time: 0.4806  last_time: 0.4781  data_time: 0.0156  last_data_time: 0.0149   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:43:24 d2.utils.events]: \u001b[0m eta: 1:23:40  iter: 4539  total_loss: 0.7112  loss_cls: 0.4193  loss_box_reg: 0.2678  loss_rpn_cls: 0.0177  loss_rpn_loc: 0.03264    time: 0.4806  last_time: 0.4892  data_time: 0.0161  last_data_time: 0.0144   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:43:34 d2.utils.events]: \u001b[0m eta: 1:23:30  iter: 4559  total_loss: 0.7515  loss_cls: 0.4106  loss_box_reg: 0.2829  loss_rpn_cls: 0.01839  loss_rpn_loc: 0.03311    time: 0.4806  last_time: 0.4776  data_time: 0.0162  last_data_time: 0.0141   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:43:43 d2.utils.events]: \u001b[0m eta: 1:23:20  iter: 4579  total_loss: 0.6306  loss_cls: 0.3422  loss_box_reg: 0.2371  loss_rpn_cls: 0.01588  loss_rpn_loc: 0.02997    time: 0.4806  last_time: 0.4766  data_time: 0.0145  last_data_time: 0.0137   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:43:53 d2.utils.events]: \u001b[0m eta: 1:23:10  iter: 4599  total_loss: 0.7527  loss_cls: 0.4108  loss_box_reg: 0.2844  loss_rpn_cls: 0.0277  loss_rpn_loc: 0.03313    time: 0.4806  last_time: 0.4851  data_time: 0.0148  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:44:03 d2.utils.events]: \u001b[0m eta: 1:22:59  iter: 4619  total_loss: 0.7656  loss_cls: 0.4143  loss_box_reg: 0.3108  loss_rpn_cls: 0.01816  loss_rpn_loc: 0.02155    time: 0.4806  last_time: 0.4815  data_time: 0.0147  last_data_time: 0.0161   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:44:12 d2.utils.events]: \u001b[0m eta: 1:22:49  iter: 4639  total_loss: 0.7487  loss_cls: 0.389  loss_box_reg: 0.288  loss_rpn_cls: 0.02009  loss_rpn_loc: 0.03989    time: 0.4806  last_time: 0.4850  data_time: 0.0154  last_data_time: 0.0211   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:44:22 d2.utils.events]: \u001b[0m eta: 1:22:39  iter: 4659  total_loss: 0.7132  loss_cls: 0.3972  loss_box_reg: 0.2848  loss_rpn_cls: 0.01582  loss_rpn_loc: 0.02424    time: 0.4806  last_time: 0.4923  data_time: 0.0148  last_data_time: 0.0179   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:44:32 d2.utils.events]: \u001b[0m eta: 1:22:29  iter: 4679  total_loss: 0.653  loss_cls: 0.3634  loss_box_reg: 0.2351  loss_rpn_cls: 0.01479  loss_rpn_loc: 0.02862    time: 0.4806  last_time: 0.4761  data_time: 0.0157  last_data_time: 0.0142   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:44:41 d2.utils.events]: \u001b[0m eta: 1:22:21  iter: 4699  total_loss: 0.6465  loss_cls: 0.3387  loss_box_reg: 0.2521  loss_rpn_cls: 0.01017  loss_rpn_loc: 0.02137    time: 0.4806  last_time: 0.4853  data_time: 0.0152  last_data_time: 0.0202   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:44:51 d2.utils.events]: \u001b[0m eta: 1:22:11  iter: 4719  total_loss: 0.5882  loss_cls: 0.3403  loss_box_reg: 0.2209  loss_rpn_cls: 0.01614  loss_rpn_loc: 0.0165    time: 0.4806  last_time: 0.4777  data_time: 0.0159  last_data_time: 0.0151   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:45:00 d2.utils.events]: \u001b[0m eta: 1:22:02  iter: 4739  total_loss: 0.5644  loss_cls: 0.3151  loss_box_reg: 0.2108  loss_rpn_cls: 0.01654  loss_rpn_loc: 0.01283    time: 0.4806  last_time: 0.4872  data_time: 0.0150  last_data_time: 0.0241   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:45:10 d2.utils.events]: \u001b[0m eta: 1:21:52  iter: 4759  total_loss: 0.6462  loss_cls: 0.3599  loss_box_reg: 0.2256  loss_rpn_cls: 0.01477  loss_rpn_loc: 0.0164    time: 0.4806  last_time: 0.4815  data_time: 0.0156  last_data_time: 0.0164   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:45:20 d2.utils.events]: \u001b[0m eta: 1:21:43  iter: 4779  total_loss: 0.6063  loss_cls: 0.3063  loss_box_reg: 0.2586  loss_rpn_cls: 0.01664  loss_rpn_loc: 0.01538    time: 0.4806  last_time: 0.4912  data_time: 0.0148  last_data_time: 0.0163   lr: 0.001  max_mem: 6696M\n",
      "\u001b[32m[10/06 00:45:25 d2.engine.hooks]: \u001b[0mOverall training speed: 4788 iterations in 0:38:21 (0.4807 s / it)\n",
      "\u001b[32m[10/06 00:45:25 d2.engine.hooks]: \u001b[0mTotal training time: 0:42:07 (0:03:46 on hooks)\n",
      "\u001b[32m[10/06 00:45:25 d2.utils.events]: \u001b[0m eta: 1:21:37  iter: 4790  total_loss: 0.6343  loss_cls: 0.3168  loss_box_reg: 0.2648  loss_rpn_cls: 0.02061  loss_rpn_loc: 0.02351    time: 0.4806  last_time: 0.4793  data_time: 0.0147  last_data_time: 0.0153   lr: 0.001  max_mem: 6696M\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m trainer \u001b[38;5;241m=\u001b[39m MyTrainer(cfg)\n\u001b[1;32m      5\u001b[0m trainer\u001b[38;5;241m.\u001b[39mresume_or_load(resume\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Lv2.Object_Detection/baseline/detectron2/detectron2/engine/defaults.py:520\u001b[0m, in \u001b[0;36mDefaultTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    514\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;124;03m    Run training.\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \n\u001b[1;32m    517\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    518\u001b[0m \u001b[38;5;124;03m        OrderedDict of results, if evaluation is enabled. Otherwise None.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mTEST\u001b[38;5;241m.\u001b[39mEXPECTED_RESULTS) \u001b[38;5;129;01mand\u001b[39;00m comm\u001b[38;5;241m.\u001b[39mis_main_process():\n\u001b[1;32m    522\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\n\u001b[1;32m    523\u001b[0m             \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_last_eval_results\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    524\u001b[0m         ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo evaluation results obtained during training!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/Lv2.Object_Detection/baseline/detectron2/detectron2/engine/train_loop.py:155\u001b[0m, in \u001b[0;36mTrainerBase.train\u001b[0;34m(self, start_iter, max_iter)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_iter, max_iter):\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbefore_step()\n\u001b[0;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mafter_step()\n\u001b[1;32m    157\u001b[0m \u001b[38;5;66;03m# self.iter == max_iter can be used by `after_train` to\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# tell whether the training successfully finished or failed\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# due to exceptions.\u001b[39;00m\n",
      "File \u001b[0;32m~/Lv2.Object_Detection/baseline/detectron2/detectron2/engine/defaults.py:530\u001b[0m, in \u001b[0;36mDefaultTrainer.run_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trainer\u001b[38;5;241m.\u001b[39miter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter\n\u001b[0;32m--> 530\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Lv2.Object_Detection/baseline/detectron2/detectron2/engine/train_loop.py:332\u001b[0m, in \u001b[0;36mSimpleTrainer.run_step\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconcurrent_executor\u001b[38;5;241m.\u001b[39msubmit(\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_metrics, loss_dict, data_time, \u001b[38;5;28miter\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter\n\u001b[1;32m    330\u001b[0m     )\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \u001b[38;5;124;03mIf you need gradient clipping/scaling or other processing, you can\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03mwrap the optimizer with your custom `step()` method. But it is\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;124;03msuboptimal as explained in https://arxiv.org/abs/2006.15704 Sec 3.2.4\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Lv2.Object_Detection/baseline/detectron2/detectron2/engine/train_loop.py:370\u001b[0m, in \u001b[0;36mSimpleTrainer._write_metrics\u001b[0;34m(self, loss_dict, data_time, prefix, iter)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28miter\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather_metric_period \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 370\u001b[0m         \u001b[43mSimpleTrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43miter\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    372\u001b[0m         logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mException in writing metrics: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Lv2.Object_Detection/baseline/detectron2/detectron2/engine/train_loop.py:388\u001b[0m, in \u001b[0;36mSimpleTrainer.write_metrics\u001b[0;34m(loss_dict, data_time, cur_iter, prefix)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_metrics\u001b[39m(\n\u001b[1;32m    377\u001b[0m     loss_dict: Mapping[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m     prefix: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    381\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03m        loss_dict (dict): dict of scalar losses\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m        data_time (float): time taken by the dataloader iteration\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m        prefix (str): prefix for logging keys\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 388\u001b[0m     metrics_dict \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m loss_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    389\u001b[0m     metrics_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data_time\n\u001b[1;32m    391\u001b[0m     storage \u001b[38;5;241m=\u001b[39m get_event_storage()\n",
      "File \u001b[0;32m~/Lv2.Object_Detection/baseline/detectron2/detectron2/engine/train_loop.py:388\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrite_metrics\u001b[39m(\n\u001b[1;32m    377\u001b[0m     loss_dict: Mapping[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    380\u001b[0m     prefix: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    381\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    382\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;124;03m        loss_dict (dict): dict of scalar losses\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m        data_time (float): time taken by the dataloader iteration\u001b[39;00m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m        prefix (str): prefix for logging keys\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 388\u001b[0m     metrics_dict \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m loss_dict\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    389\u001b[0m     metrics_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m data_time\n\u001b[1;32m    391\u001b[0m     storage \u001b[38;5;241m=\u001b[39m get_event_storage()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)\n",
    "\n",
    "trainer = MyTrainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
